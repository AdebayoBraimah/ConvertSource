{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "import yaml\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = \"C:/Users/smart/Desktop/GitProjects/convsauce/ConvertSource/cfg.test.yml\"\n",
    "cfg = \"/Users/brac4g/Desktop/convsauce/ConvertSource/cfg.test.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_file, verbose = False):\n",
    "    '''\n",
    "    Reads configuration file and creates a dictionary of search terms for \n",
    "    certain modalities provided that BIDS modalities are used as keys. If\n",
    "    exclusions are provided (via the key 'exclude') then an exclusion list is \n",
    "    created. Otherwise, 'exclusion_list' is returned as an empty list. If \n",
    "    additional settings are specified, they should be done so via the key\n",
    "    'settings' to enable writing of additional metadata.\n",
    "    \n",
    "    Arguments:\n",
    "        config_file (string): file path to yaml configuration file.\n",
    "        verbose (boolean): Prints additional information to screen.\n",
    "    \n",
    "    Returns: \n",
    "        data_map (dict): Nested dictionary of search terms for BIDS modalities\n",
    "        exclusion_list (list): List of exclusion terms\n",
    "        settings_dict (dict): Nested dictionary of metadata terms to write to JSON file(s)\n",
    "    '''\n",
    "    \n",
    "    with open(config_file) as file:\n",
    "        data_map = yaml.safe_load(file)\n",
    "        if verbose:\n",
    "            print(\"Initialized parameters from configuration file\")\n",
    "        \n",
    "    if any(\"exclude\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"exclusion option implemented\")\n",
    "        exclusion_list = data_map[\"exclude\"]\n",
    "        del data_map[\"exclude\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"exclusion option not implemented\")\n",
    "        exclusion_list = list()\n",
    "        \n",
    "    if any(\"settings\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"implementing additional settings\")\n",
    "        settings_dict = data_map[\"settings\"]\n",
    "        del data_map[\"settings\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"no additional settings implemented\")\n",
    "        settings_dict = dict()\n",
    "        \n",
    "    return data_map,exclusion_list,settings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameters from configuration file\n",
      "exclusion option implemented\n",
      "implementing additional settings\n"
     ]
    }
   ],
   "source": [
    "search_dict, exclusion_list, param_dict = read_config(cfg,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anat': {'T1w': ['T1', 'T1w', 'TFE'], 'T2w': ['T2', 'T2w', 'TSE']},\n",
       " 'func': {'bold': {'rest': ['rsfMR', 'rest', 'FFE', 'FEEPI'],\n",
       "   'visualstrobe': ['vis', 'visual']}},\n",
       " 'fmap': {'fmap': ['map']},\n",
       " 'swi': {'swi': ['swi']},\n",
       " 'dwi': {'dwi': ['diffusion', 'DTI', 'DWI', '6_DIR']}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SURVEY',\n",
       " 'Reg',\n",
       " 'SHORT',\n",
       " 'LONG',\n",
       " 'MRS',\n",
       " 'PRESS',\n",
       " 'DEFAULT',\n",
       " 'ScreenCapture',\n",
       " 'PD',\n",
       " 'ALL',\n",
       " 'SPECTRO']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'metadata': {'Manufacturer': 'Philips',\n",
       "   'ManufacturersModelName': 'Ingenia',\n",
       "   'InstitutionName': \"Cincinnati Children's Hospital Medical Center\",\n",
       "   'ParallelAcquisitionTechnique': 'SENSE'}},\n",
       " 'func': {'metadata': {'PhaseEncodingDirection': 'j'}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_par = \"C:/Users/smart/Desktop/GitProjects/convsauce/287H_C10/PAR REC\"\n",
    "data_dir_par = \"/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_dcm = \"C:/Users/smart/Desktop/GitProjects/convsauce/IRC287H-8/20171003\"\n",
    "data_dir_dcm = \"/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_nii = \"/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dcm_files(dcm_dir):\n",
    "    '''\n",
    "    Creates a file list consisting of the first DICOM file in a parent DICOM directory. \n",
    "    A file list is then returned.\n",
    "    \n",
    "    Arguments:\n",
    "        dcm_dir (string): Absolute path to parent DICOM data directory\n",
    "\n",
    "    Returns: \n",
    "        dcm_files (list): List of DICOM filenames, complete with their absolute paths.\n",
    "    '''\n",
    "    \n",
    "    # Create directory list\n",
    "    dcm_dir = os.path.abspath(dcm_dir)\n",
    "    parent_dcm_dir = os.path.join(dcm_dir,'*')\n",
    "    dcm_dir_list = glob.glob(parent_dcm_dir, recursive=True)\n",
    "\n",
    "    # Initilized dcm_file list\n",
    "    dcm_files = list()\n",
    "    \n",
    "    # Iterate through files in the dicom directory list\n",
    "    for dir_ in dcm_dir_list:\n",
    "        # print(dir_)\n",
    "        for root, dirs, files in os.walk(dir_):\n",
    "            # print(files[0])\n",
    "            tmp_dcm_file = files[0] # only need the first dicom file\n",
    "            tmp_dcm_dir = root\n",
    "            tmp_file = os.path.join(tmp_dcm_dir, tmp_dcm_file)\n",
    "\n",
    "            dcm_files.append(tmp_file)\n",
    "            break\n",
    "\n",
    "    return dcm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(data_dir, file_ext=\"\", order=\"size\"):\n",
    "    '''\n",
    "    Creates a file list by globbing a directory for a specific file\n",
    "    extension and sorting by some determined order. A file list is \n",
    "    then returned\n",
    "    \n",
    "    Arguments:\n",
    "        data_dir (string): Absolute path to data directory (must be a directory dump of image data)\n",
    "        file_ext (string): File extension to glob. Built-in options include:\n",
    "            - 'par' or 'PAR': Searches for PAR headers\n",
    "            - 'dcm' or 'DICOM': Searches for DICOM directories, then searches for one file from each DICOM directory\n",
    "            - 'nii', or 'Nifti': Searches for nifti files (including gzipped nifti files)\n",
    "        order (string): Order to sort the list. Valid options are: 'size' and 'time':\n",
    "            - 'size': sorts by file size in ascending order (default)\n",
    "            - 'time': sorts by file modification time in ascending order\n",
    "            - 'none': no sorting is applied and the list is generated as the system finds the files\n",
    "    \n",
    "    Returns: \n",
    "        file_list (list): List of filenames, complete with their absolute paths.\n",
    "    '''\n",
    "    \n",
    "    # Check file extension\n",
    "    if file_ext != \"\":\n",
    "        if file_ext.upper() == \"PAR\" or file_ext.upper() == \"REC\":\n",
    "            file_ext = \"PAR\"\n",
    "            file_ext = f\".{file_ext.upper()}\"\n",
    "        elif file_ext.lower() == \"dcm\" or file_ext.upper() == \"DICOM\":\n",
    "            file_ext = \"dcm\"\n",
    "            file_ext = f\".{file_ext.lower()}\"\n",
    "        elif file_ext.lower() == \"nii\" or file_ext.lower() == \"nifti\":\n",
    "            file_ext = \"nii\"\n",
    "            file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "        else:\n",
    "            file_ext = f\".{file_ext}\"\n",
    "    \n",
    "    # Check sort order\n",
    "    if order.lower() == \"size\":\n",
    "        order_key = os.path.getsize\n",
    "    elif order.lower() == \"time\":\n",
    "        order_key = os.path.getmtime\n",
    "    elif order.lower() == \"none\":\n",
    "        order_key=None\n",
    "    else:\n",
    "        order_key = os.path.getsize\n",
    "        print(\"Unrecognized keyword option. Using default.\")\n",
    "    \n",
    "    # Create file list\n",
    "    if file_ext == \".dcm\":\n",
    "        file_list = sorted(get_dcm_files(data_dir), key=order_key, reverse=False)\n",
    "    elif file_ext != \".dcm\":\n",
    "        file_names = os.path.join(data_dir, f\"*{file_ext}\")\n",
    "        file_list = sorted(glob.glob(file_names, recursive=True), key=order_key, reverse=False)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_file_list = create_file_list(data_dir=data_dir_par,file_ext=\"par\")\n",
    "dcm_file_list = create_file_list(data_dir=data_dir_dcm,file_ext=\"dcm\")\n",
    "nii_file_list = create_file_list(data_dir=data_dir_nii,file_ext=\"nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exclude(file_list, data_dir, exclusion_list = [], verbose = False):\n",
    "    '''\n",
    "    Excludes files from the conversion process by removing filenames\n",
    "    that contain words that match those found in the 'exclusion_list'\n",
    "    from the 'read_config' function - should any files need/want to be \n",
    "    excluded.\n",
    "    \n",
    "    If 'exclusion_list' is empty, then the original 'file_list' is returned.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames\n",
    "        data_dir (string): Absolute path to parent directory that contains the image data\n",
    "        exclusion_list (list): List of words to be matched. Filenames that contain these words will be excluded.\n",
    "        verbose (bool): Boolean - True or False.\n",
    "    \n",
    "    Returns: \n",
    "        currated_list (list): Currated list of filenames, with unwanted filenames removed.\n",
    "    '''\n",
    "            \n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file_list[0]:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'PAR' in file_list[0]:\n",
    "        file_ext = \"PAR\"\n",
    "        file_ext = f\".{file_ext.upper()}\"\n",
    "    elif 'nii' in file_list[0]:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    \n",
    "    # create set of lists\n",
    "    file_set = set(file_list)\n",
    "    \n",
    "    # create empty sets\n",
    "    currated_set = set()\n",
    "    exclusion_set = set()\n",
    "    \n",
    "    if len(exclusion_list) == 0:\n",
    "        currated_set = file_set\n",
    "    else:\n",
    "        for file in exclusion_list:\n",
    "            if file_ext == '.dcm':\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*\",f\"*{file_ext}\")\n",
    "            else:\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*{file_ext}\")\n",
    "            f_names = glob.glob(dir_, recursive=True)        \n",
    "            f_names_set = set(f_names)\n",
    "            exclusion_set.update(f_names_set)\n",
    "            \n",
    "        currated_set = file_set.difference(exclusion_set)\n",
    "\n",
    "    currated_list = list(currated_set)\n",
    "    \n",
    "    return currated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par_file_list_currated = file_exclude(par_file_list,data_dir_par,exclusion_list)\n",
    "dcm_file_list_currated = file_exclude(dcm_file_list,data_dir_dcm,exclusion_list)\n",
    "nii_file_list_currated = file_exclude(nii_file_list,data_dir_nii,exclusion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_in_substr(sub_str_,str_):\n",
    "    '''\n",
    "    DEPRECATED: Should only be used if config_file uses comma separated\n",
    "        lists to denote search terms.\n",
    "    \n",
    "    Searches a (longer) string using a comma separated string \n",
    "    consisting of substrings. Returns 'True' or 'False' if any part\n",
    "    of the substring is found within the larger string.\n",
    "    \n",
    "    Example:\n",
    "        str_in_substr('T1,TFE','sub_T1_image_file') would return True.\n",
    "        str_in_substr('T2,TSE','sub_T1_image_file') would return False.\n",
    "    \n",
    "    Arguments:\n",
    "        sub_str_ (string): Substring used for matching.\n",
    "        str_ (string): Larger string to be searched for matches within substring.\n",
    "    \n",
    "    Returns: \n",
    "        bool_var (bool): Boolean - True or False\n",
    "    '''\n",
    "    \n",
    "    bool_var = False\n",
    "    \n",
    "    for word in sub_str_.split(\",\"):\n",
    "        if any(word in str_ for element in str_):\n",
    "            bool_var = True\n",
    "            \n",
    "    return bool_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_in_substr(list_,str_):\n",
    "    '''\n",
    "    Searches a string using a list that contains substrings. \n",
    "    Returns 'True' or 'False' if any elements of the list are \n",
    "    found within the string.\n",
    "    \n",
    "    Example:\n",
    "        list_in_substr('['T1','TFE']','sub_T1_image_file') would return True.\n",
    "        list_in_substr('['T2','TSE']','sub_T1_image_file') would return False.\n",
    "    \n",
    "    Arguments:\n",
    "        list_ (string): list containing strings used for matching.\n",
    "        str_ (string): Larger string to be searched for matches within substring.\n",
    "    \n",
    "    Returns: \n",
    "        bool_var (bool): Boolean - True or False\n",
    "    '''\n",
    "    \n",
    "    bool_var = False\n",
    "    \n",
    "    for word in list_:\n",
    "        if any(word.lower() in str_.lower() for element in str_.lower()):\n",
    "            bool_var = True\n",
    "            \n",
    "    return bool_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_mr(dcm_file, verbose=False):\n",
    "    '''\n",
    "    Checks for a valid DICOM file by inspecting the conversion type label in the DICOM file header.\n",
    "    This field should be blank. If this label is populated, then it is likely a secondary capture image \n",
    "    and thus is not likely to contain meaningful image information.\n",
    "    \n",
    "    Arguments:\n",
    "        dcm_file (string): DICOM filename with absolute filepath\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        is_valid (boolean): True if DICOM file is not a secondary capture (or does not have text in the conversion type label field)\n",
    "    '''\n",
    "    \n",
    "    # Read DICOM file header\n",
    "    ds = pydicom.dcmread(dcm_file)\n",
    "    \n",
    "    # Invalid files include secondary image captures, and are not suitable for \n",
    "    # nifti conversion as they are often not converted and cause problems.\n",
    "    # This string should be empty. If it is populated, then its likely a secondary capture.\n",
    "    conv_type = ds.ConversionType\n",
    "    \n",
    "    if conv_type in '':\n",
    "        is_valid = True\n",
    "    else:\n",
    "        is_valid = False\n",
    "        if verbose:\n",
    "            print(f\"Please check Conversion Type (0008, 0064) in dicom header. The presented DICOM file is not a valid file: {dcm_file}.\")\n",
    "    \n",
    "    return is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_modality(dictionary, file, verbose=False):\n",
    "    '''\n",
    "    Converts an image file and extracts information from the filename\n",
    "    (such as the modality). \n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        file (string): Filename with absolute filepath\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Check file type\n",
    "    if 'nii' in file:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'dcm' in file:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "        if not is_valid_mr(file,verbose):\n",
    "            sys.exit(f\"Invalid DICOM file. Please check {file}\")\n",
    "    \n",
    "    for key,item in dictionary.items():\n",
    "        for dict_key,dict_item in dictionary[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if list_in_substr(dict_item,file):\n",
    "                    mod_found = True\n",
    "                    print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = dictionary[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if list_in_substr(d_item,file):\n",
    "                        mod_found = True\n",
    "                        print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                        \n",
    "    if not mod_found:\n",
    "        get_scan_tech(dictionary,file)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert(file_list, dictionary, verbose=False):\n",
    "    '''\n",
    "    Batch conversion function for image files. \n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames with absolute filepaths\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        Nones\n",
    "    '''\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            convert_modality(dictionary,file,verbose)\n",
    "        except SystemExit:\n",
    "            pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_tech(dictionary, file, json_file=\"\"):\n",
    "    '''\n",
    "    Searches DICOM or PAR file header for scan technique/MR modality used in accordance with the search terms provided\n",
    "    by the nested dictionary.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        dcm_file (string): Source image filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'PAR' in file:\n",
    "        file_ext = \"PAR\"\n",
    "        file_ext = f\".{file_ext.upper()}\"\n",
    "    elif 'nii' in file:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    \n",
    "    # Perform Scanning Techniqe Search\n",
    "    if file_ext == '.dcm':\n",
    "        get_dcm_scan_tech(dictionary,file)\n",
    "    elif file_ext == '.PAR':\n",
    "        get_par_scan_tech(dictionary,file)\n",
    "    else:\n",
    "        print(\"unknown modality\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dcm_scan_tech(dictionary, dcm_file):\n",
    "    '''\n",
    "    Searches DICOM file header for scan technique/MR modality used in accordance with the search terms provided by the\n",
    "    nested dictionary. The DICOM header field searched is a Philips DICOM private tag (2001,1020) [Scanning Technique \n",
    "    Description MR]. In the case that field is does not match, is empty, or does not exist, then more common DICOM tags\n",
    "    are searched - and they include: Series Description, Protocol Name, and Image Type.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        dcm_file (string): DICOM filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Load DICOM data and read header\n",
    "    ds = pydicom.dcmread(dcm_file)\n",
    "    \n",
    "    # Search DICOM header for Scan Technique used\n",
    "    dcm_scan_tech_str = str(ds[0x2001,0x1020])\n",
    "    \n",
    "    for key,item in dictionary.items():\n",
    "        for dict_key,dict_item in dictionary[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if list_in_substr(dict_item,dcm_scan_tech_str):\n",
    "                    mod_found = True\n",
    "                    print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = dictionary[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if list_in_substr(d_item,dcm_scan_tech_str):\n",
    "                        mod_found = True\n",
    "                        print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                            \n",
    "        if mod_found:\n",
    "            break\n",
    "    \n",
    "    # Secondary look in the case Private Field (2001, 1020) [Scanning Technique Description MR] is empty\n",
    "    if not mod_found:\n",
    "        # Define list of DICOM header fields\n",
    "        dcm_fields = ['SeriesDescription', 'ImageType', 'ProtocolName']\n",
    "        \n",
    "        for dcm_field in dcm_fields:\n",
    "            dcm_scan_tech_str = str(eval(f\"ds.{dcm_field}\"))\n",
    "            \n",
    "            for key,item in dictionary.items():\n",
    "                for dict_key,dict_item in dictionary[key].items():\n",
    "                    if isinstance(dict_item,list):\n",
    "                        if list_in_substr(dict_item,dcm_scan_tech_str):\n",
    "                            mod_found = True\n",
    "                            print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                            if mod_found:\n",
    "                                break\n",
    "                    elif isinstance(dict_item,dict):\n",
    "                        tmp_dict = dictionary[key]\n",
    "                        for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                            if list_in_substr(d_item,dcm_scan_tech_str):\n",
    "                                mod_found = True\n",
    "                                print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                                if mod_found:\n",
    "                                    break\n",
    "\n",
    "            if mod_found:\n",
    "                break\n",
    "                \n",
    "    if not mod_found:\n",
    "        print(\"unknown modality\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_par_scan_tech(dictionary, par_file):\n",
    "    '''\n",
    "    Searches PAR file header for scan technique/MR modality used in accordance with the search terms provided by the\n",
    "    nested dictionary. A regular expression (regEx) search string is defined and searched for conventional PAR headers.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        par_file (string): PAR filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Define regEx search string\n",
    "    regexp = re.compile(r'.    Technique                          :  .*', re.M | re.I)\n",
    "    \n",
    "    # Open and search PAR header file\n",
    "    with open(par_file) as f:\n",
    "        for line in f:\n",
    "            match_ = regexp.match(line)\n",
    "            if match_:\n",
    "                par_scan_tech_str = match_.group()\n",
    "    \n",
    "    # Search Scan Technique with search terms\n",
    "    for key,item in dictionary.items():\n",
    "        for dict_key,dict_item in dictionary[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if list_in_substr(dict_item,par_scan_tech_str):\n",
    "                    mod_found = True\n",
    "                    print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = dictionary[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if list_in_substr(d_item,par_scan_tech_str):\n",
    "                        mod_found = True\n",
    "                        print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                            \n",
    "        if mod_found:\n",
    "            break\n",
    "            \n",
    "    if not mod_found:\n",
    "        print(\"unknown modality\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TaskName` JSON file appending funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_name = \"\"\n",
    "task_name = \"visualstrobe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name is: visualstrobe\n"
     ]
    }
   ],
   "source": [
    "if task_name == \"\":\n",
    "    print(\"task_name is empty\")\n",
    "else:\n",
    "    print(f\"task_name is: {task_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_file = \"c:/Users/smart/Desktop/GitProjects/convsauce/BIDS/rawdata/sub-C10/ses-001/func/sub-C10_ses-001_task-rest_acq-PA_run-01_bold.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(nii_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(nii_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x22eb4b28470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 45, 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.header.get_data_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.header.get_data_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = img.header.get_data_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 45, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(frames[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
