{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "import yaml\n",
    "import nibabel as nib\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = \"C:/Users/smart/Desktop/GitProjects/convsauce/ConvertSource/cfg.test.yml\"\n",
    "cfg = \"/Users/brac4g/Desktop/convsauce/ConvertSource/cfg.test.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_file, verbose = False):\n",
    "    '''\n",
    "    Reads configuration file and creates a dictionary of search terms for \n",
    "    certain modalities provided that BIDS modalities are used as keys. If\n",
    "    exclusions are provided (via the key 'exclude') then an exclusion list is \n",
    "    created. Otherwise, 'exclusion_list' is returned as an empty list. If \n",
    "    additional settings are specified, they should be done so via the key\n",
    "    'metadata' to enable writing of additional metadata.\n",
    "    \n",
    "    Arguments:\n",
    "        config_file (string): file path to yaml configuration file.\n",
    "        verbose (boolean): Prints additional information to screen.\n",
    "    \n",
    "    Returns: \n",
    "        data_map (dict): Nested dictionary of search terms for BIDS modalities\n",
    "        exclusion_list (list): List of exclusion terms\n",
    "        settings_dict (dict): Nested dictionary of metadata terms to write to JSON file(s)\n",
    "    '''\n",
    "    \n",
    "    with open(config_file) as file:\n",
    "        data_map = yaml.safe_load(file)\n",
    "        if verbose:\n",
    "            print(\"Initialized parameters from configuration file\")\n",
    "        \n",
    "    if any(\"exclude\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"exclusion option implemented\")\n",
    "        exclusion_list = data_map[\"exclude\"]\n",
    "        del data_map[\"exclude\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"exclusion option not implemented\")\n",
    "        exclusion_list = list()\n",
    "        \n",
    "    if any(\"metadata\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"implementing additional settings for metadata\")\n",
    "        settings_dict = data_map[\"metadata\"]\n",
    "        del data_map[\"metadata\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"no metadata settings\")\n",
    "        settings_dict = dict()\n",
    "        \n",
    "    return data_map,exclusion_list,settings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameters from configuration file\n",
      "exclusion option implemented\n",
      "implementing additional settings for metadata\n"
     ]
    }
   ],
   "source": [
    "search_dict, exclusion_list, param_dict = read_config(cfg,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anat': {'T1w': ['T1', 'T1w', 'TFE'], 'T2w': ['T2', 'T2w', 'TSE']},\n",
       " 'func': {'bold': {'rest': ['rsfMR', 'rest', 'FFE', 'FEEPI'],\n",
       "   'visualstrobe': ['vis', 'visual']}},\n",
       " 'fmap': {'fmap': ['map']},\n",
       " 'swi': {'swi': ['swi']},\n",
       " 'dwi': {'dwi': ['diffusion', 'DTI', 'DWI', '6_DIR']}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SURVEY',\n",
       " 'Reg',\n",
       " 'SHORT',\n",
       " 'LONG',\n",
       " 'MRS',\n",
       " 'PRESS',\n",
       " 'DEFAULT',\n",
       " 'ScreenCapture',\n",
       " 'PD',\n",
       " 'ALL',\n",
       " 'SPECTRO']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'common': {'Manufacturer': 'Philips',\n",
       "  'ManufacturersModelName': 'Ingenia',\n",
       "  'MagneticFieldStrength': 3,\n",
       "  'InstitutionName': \"Cincinnati Children's Hospital Medical Center\"},\n",
       " 'func': {'rest': {'ParallelAcquisitionTechnique': 'SENSE',\n",
       "   'PhaseEncodingDirection': 'j',\n",
       "   'MultibandAccelerationFactor': 6,\n",
       "   'TaskName': 'Rest'},\n",
       "  'visualstrobe': {'PhaseEncodingDirection': 'j',\n",
       "   'TaskName': 'Visual (Strobe) Task'}},\n",
       " 'dwi': {'PhaseEncodingDirection': 'j'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_par = \"C:/Users/smart/Desktop/GitProjects/convsauce/287H_C10/PAR REC\"\n",
    "data_dir_par = \"/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_dcm = \"C:/Users/smart/Desktop/GitProjects/convsauce/IRC287H-8/20171003\"\n",
    "data_dir_dcm = \"/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_nii = \"/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dcm_files(dcm_dir):\n",
    "    '''\n",
    "    Creates a file list consisting of the first DICOM file in a parent DICOM directory. \n",
    "    A file list is then returned.\n",
    "    \n",
    "    Arguments:\n",
    "        dcm_dir (string): Absolute path to parent DICOM data directory\n",
    "\n",
    "    Returns: \n",
    "        dcm_files (list): List of DICOM filenames, complete with their absolute paths.\n",
    "    '''\n",
    "    \n",
    "    # Create directory list\n",
    "    dcm_dir = os.path.abspath(dcm_dir)\n",
    "    parent_dcm_dir = os.path.join(dcm_dir,'*')\n",
    "    dcm_dir_list = glob.glob(parent_dcm_dir, recursive=True)\n",
    "\n",
    "    # Initilized dcm_file list\n",
    "    dcm_files = list()\n",
    "    \n",
    "    # Iterate through files in the dicom directory list\n",
    "    for dir_ in dcm_dir_list:\n",
    "        # print(dir_)\n",
    "        for root, dirs, files in os.walk(dir_):\n",
    "            # print(files[0])\n",
    "            tmp_dcm_file = files[0] # only need the first dicom file\n",
    "            tmp_dcm_dir = root\n",
    "            tmp_file = os.path.join(tmp_dcm_dir, tmp_dcm_file)\n",
    "\n",
    "            dcm_files.append(tmp_file)\n",
    "            break\n",
    "\n",
    "    return dcm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(data_dir, file_ext=\"\", order=\"size\"):\n",
    "    '''\n",
    "    Creates a file list by globbing a directory for a specific file\n",
    "    extension and sorting by some determined order. A file list is \n",
    "    then returned\n",
    "    \n",
    "    Arguments:\n",
    "        data_dir (string): Absolute path to data directory (must be a directory dump of image data)\n",
    "        file_ext (string): File extension to glob. Built-in options include:\n",
    "            - 'par' or 'PAR': Searches for PAR headers\n",
    "            - 'dcm' or 'DICOM': Searches for DICOM directories, then searches for one file from each DICOM directory\n",
    "            - 'nii', or 'Nifti': Searches for nifti files (including gzipped nifti files)\n",
    "        order (string): Order to sort the list. Valid options are: 'size' and 'time':\n",
    "            - 'size': sorts by file size in ascending order (default)\n",
    "            - 'time': sorts by file modification time in ascending order\n",
    "            - 'none': no sorting is applied and the list is generated as the system finds the files\n",
    "    \n",
    "    Returns: \n",
    "        file_list (list): List of filenames, complete with their absolute paths.\n",
    "    '''\n",
    "    \n",
    "    # Check file extension\n",
    "    if file_ext != \"\":\n",
    "        if file_ext.upper() == \"PAR\" or file_ext.upper() == \"REC\":\n",
    "            file_ext = \"PAR\"\n",
    "            file_ext = f\".{file_ext.upper()}\"\n",
    "        elif file_ext.lower() == \"dcm\" or file_ext.upper() == \"DICOM\":\n",
    "            file_ext = \"dcm\"\n",
    "            file_ext = f\".{file_ext.lower()}\"\n",
    "        elif file_ext.lower() == \"nii\" or file_ext.lower() == \"nifti\":\n",
    "            file_ext = \"nii\"\n",
    "            file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "        else:\n",
    "            file_ext = f\".{file_ext}\"\n",
    "    \n",
    "    # Check sort order\n",
    "    if order.lower() == \"size\":\n",
    "        order_key = os.path.getsize\n",
    "    elif order.lower() == \"time\":\n",
    "        order_key = os.path.getmtime\n",
    "    elif order.lower() == \"none\":\n",
    "        order_key=None\n",
    "    else:\n",
    "        order_key = os.path.getsize\n",
    "        print(\"Unrecognized keyword option. Using default.\")\n",
    "    \n",
    "    # Create file list\n",
    "    if file_ext == \".dcm\":\n",
    "        file_list = sorted(get_dcm_files(data_dir), key=order_key, reverse=False)\n",
    "    elif file_ext != \".dcm\":\n",
    "        file_names = os.path.join(data_dir, f\"*{file_ext}\")\n",
    "        file_list = sorted(glob.glob(file_names, recursive=True), key=order_key, reverse=False)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_file_list = create_file_list(data_dir=data_dir_par,file_ext=\"par\")\n",
    "dcm_file_list = create_file_list(data_dir=data_dir_dcm,file_ext=\"dcm\")\n",
    "nii_file_list = create_file_list(data_dir=data_dir_nii,file_ext=\"nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exclude(file_list, data_dir, exclusion_list = [], verbose = False):\n",
    "    '''\n",
    "    Excludes files from the conversion process by removing filenames\n",
    "    that contain words that match those found in the 'exclusion_list'\n",
    "    from the 'read_config' function - should any files need/want to be \n",
    "    excluded.\n",
    "    \n",
    "    If 'exclusion_list' is empty, then the original 'file_list' is returned.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames\n",
    "        data_dir (string): Absolute path to parent directory that contains the image data\n",
    "        exclusion_list (list): List of words to be matched. Filenames that contain these words will be excluded.\n",
    "        verbose (bool): Boolean - True or False.\n",
    "    \n",
    "    Returns: \n",
    "        currated_list (list): Currated list of filenames, with unwanted filenames removed.\n",
    "    '''\n",
    "            \n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file_list[0]:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'PAR' in file_list[0]:\n",
    "        file_ext = \"PAR\"\n",
    "        file_ext = f\".{file_ext.upper()}\"\n",
    "    elif 'nii' in file_list[0]:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    \n",
    "    # create set of lists\n",
    "    file_set = set(file_list)\n",
    "    \n",
    "    # create empty sets\n",
    "    currated_set = set()\n",
    "    exclusion_set = set()\n",
    "    \n",
    "    if len(exclusion_list) == 0:\n",
    "        currated_set = file_set\n",
    "    else:\n",
    "        for file in exclusion_list:\n",
    "            if file_ext == '.dcm':\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*\",f\"*{file_ext}\")\n",
    "            else:\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*{file_ext}\")\n",
    "            f_names = glob.glob(dir_, recursive=True)        \n",
    "            f_names_set = set(f_names)\n",
    "            exclusion_set.update(f_names_set)\n",
    "            \n",
    "        currated_set = file_set.difference(exclusion_set)\n",
    "\n",
    "    currated_list = list(currated_set)\n",
    "    \n",
    "    return currated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par_file_list_currated = file_exclude(par_file_list,data_dir_par,exclusion_list)\n",
    "dcm_file_list_currated = file_exclude(dcm_file_list,data_dir_dcm,exclusion_list)\n",
    "nii_file_list_currated = file_exclude(nii_file_list,data_dir_nii,exclusion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_in_substr(sub_str_,str_):\n",
    "    '''\n",
    "    DEPRECATED: Should only be used if config_file uses comma separated\n",
    "        lists to denote search terms.\n",
    "    \n",
    "    Searches a (longer) string using a comma separated string \n",
    "    consisting of substrings. Returns 'True' or 'False' if any part\n",
    "    of the substring is found within the larger string.\n",
    "    \n",
    "    Example:\n",
    "        str_in_substr('T1,TFE','sub_T1_image_file') would return True.\n",
    "        str_in_substr('T2,TSE','sub_T1_image_file') would return False.\n",
    "    \n",
    "    Arguments:\n",
    "        sub_str_ (string): Substring used for matching.\n",
    "        str_ (string): Larger string to be searched for matches within substring.\n",
    "    \n",
    "    Returns: \n",
    "        bool_var (bool): Boolean - True or False\n",
    "    '''\n",
    "    \n",
    "    bool_var = False\n",
    "    \n",
    "    for word in sub_str_.split(\",\"):\n",
    "        if any(word in str_ for element in str_):\n",
    "            bool_var = True\n",
    "            \n",
    "    return bool_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_in_substr(list_,str_):\n",
    "    '''\n",
    "    Searches a string using a list that contains substrings. \n",
    "    Returns 'True' or 'False' if any elements of the list are \n",
    "    found within the string.\n",
    "    \n",
    "    Example:\n",
    "        list_in_substr('['T1','TFE']','sub_T1_image_file') would return True.\n",
    "        list_in_substr('['T2','TSE']','sub_T1_image_file') would return False.\n",
    "    \n",
    "    Arguments:\n",
    "        list_ (string): list containing strings used for matching.\n",
    "        str_ (string): Larger string to be searched for matches within substring.\n",
    "    \n",
    "    Returns: \n",
    "        bool_var (bool): Boolean - True or False\n",
    "    '''\n",
    "    \n",
    "    bool_var = False\n",
    "    \n",
    "    for word in list_:\n",
    "        if any(word.lower() in str_.lower() for element in str_.lower()):\n",
    "            bool_var = True\n",
    "            \n",
    "    return bool_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_mr(dcm_file, verbose=False):\n",
    "    '''\n",
    "    Checks for a valid DICOM file by inspecting the conversion type label in the DICOM file header.\n",
    "    This field should be blank. If this label is populated, then it is likely a secondary capture image \n",
    "    and thus is not likely to contain meaningful image information.\n",
    "    \n",
    "    Arguments:\n",
    "        dcm_file (string): DICOM filename with absolute filepath\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        is_valid (boolean): True if DICOM file is not a secondary capture (or does not have text in the conversion type label field)\n",
    "    '''\n",
    "    \n",
    "    # Read DICOM file header\n",
    "    ds = pydicom.dcmread(dcm_file)\n",
    "    \n",
    "    # Invalid files include secondary image captures, and are not suitable for \n",
    "    # nifti conversion as they are often not converted and cause problems.\n",
    "    # This string should be empty. If it is populated, then its likely a secondary capture.\n",
    "    conv_type = ds.ConversionType\n",
    "    \n",
    "    if conv_type in '':\n",
    "        is_valid = True\n",
    "    else:\n",
    "        is_valid = False\n",
    "        if verbose:\n",
    "            print(f\"Please check Conversion Type (0008, 0064) in dicom header. The presented DICOM file is not a valid file: {dcm_file}.\")\n",
    "    \n",
    "    return is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_tech(dictionary, file, json_file=\"\"):\n",
    "    '''\n",
    "    Searches DICOM or PAR file header for scan technique/MR modality used in accordance with the search terms provided\n",
    "    by the nested dictionary.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        dcm_file (string): Source image filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'PAR' in file:\n",
    "        file_ext = \"PAR\"\n",
    "        file_ext = f\".{file_ext.upper()}\"\n",
    "    elif 'nii' in file:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    \n",
    "    # Perform Scanning Techniqe Search\n",
    "    if file_ext == '.dcm':\n",
    "        get_dcm_scan_tech(dictionary,file)\n",
    "    elif file_ext == '.PAR':\n",
    "        get_par_scan_tech(dictionary,file)\n",
    "    else:\n",
    "        print(\"unknown modality\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dcm_scan_tech(dictionary, dcm_file):\n",
    "    '''\n",
    "    Searches DICOM file header for scan technique/MR modality used in accordance with the search terms provided by the\n",
    "    nested dictionary. The DICOM header field searched is a Philips DICOM private tag (2001,1020) [Scanning Technique \n",
    "    Description MR]. In the case that field does not match, is empty, or does not exist, then more common DICOM tags\n",
    "    are searched - and they include: Series Description, Protocol Name, and Image Type.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        dcm_file (string): DICOM filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Load DICOM data and read header\n",
    "    ds = pydicom.dcmread(dcm_file)\n",
    "    \n",
    "    # Search DICOM header for Scan Technique used\n",
    "    dcm_scan_tech_str = str(ds[0x2001,0x1020])\n",
    "    \n",
    "    for key,item in dictionary.items():\n",
    "        for dict_key,dict_item in dictionary[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if list_in_substr(dict_item,dcm_scan_tech_str):\n",
    "                    mod_found = True\n",
    "                    print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = dictionary[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if list_in_substr(d_item,dcm_scan_tech_str):\n",
    "                        mod_found = True\n",
    "                        print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                            \n",
    "        if mod_found:\n",
    "            break\n",
    "    \n",
    "    # Secondary look in the case Private Field (2001, 1020) [Scanning Technique Description MR] is empty\n",
    "    if not mod_found:\n",
    "        # Define list of DICOM header fields\n",
    "        dcm_fields = ['SeriesDescription', 'ImageType', 'ProtocolName']\n",
    "        \n",
    "        for dcm_field in dcm_fields:\n",
    "            dcm_scan_tech_str = str(eval(f\"ds.{dcm_field}\")) # This makes me dangerously uncomfortable\n",
    "            \n",
    "            for key,item in dictionary.items():\n",
    "                for dict_key,dict_item in dictionary[key].items():\n",
    "                    if isinstance(dict_item,list):\n",
    "                        if list_in_substr(dict_item,dcm_scan_tech_str):\n",
    "                            mod_found = True\n",
    "                            print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                            if mod_found:\n",
    "                                break\n",
    "                    elif isinstance(dict_item,dict):\n",
    "                        tmp_dict = dictionary[key]\n",
    "                        for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                            if list_in_substr(d_item,dcm_scan_tech_str):\n",
    "                                mod_found = True\n",
    "                                print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                                if mod_found:\n",
    "                                    break\n",
    "\n",
    "            if mod_found:\n",
    "                break\n",
    "                \n",
    "    if not mod_found:\n",
    "        print(\"unknown modality\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_par_scan_tech(dictionary, par_file):\n",
    "    '''\n",
    "    Searches PAR file header for scan technique/MR modality used in accordance with the search terms provided by the\n",
    "    nested dictionary. A regular expression (regEx) search string is defined and searched for conventional PAR headers.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        par_file (string): PAR filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Define regEx search string\n",
    "    regexp = re.compile(r'.    Technique                          :  .*', re.M | re.I)\n",
    "    \n",
    "    # Open and search PAR header file\n",
    "    with open(par_file) as f:\n",
    "        for line in f:\n",
    "            match_ = regexp.match(line)\n",
    "            if match_:\n",
    "                par_scan_tech_str = match_.group()\n",
    "    \n",
    "    # Search Scan Technique with search terms\n",
    "    for key,item in dictionary.items():\n",
    "        for dict_key,dict_item in dictionary[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if list_in_substr(dict_item,par_scan_tech_str):\n",
    "                    mod_found = True\n",
    "                    print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = dictionary[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if list_in_substr(d_item,par_scan_tech_str):\n",
    "                        mod_found = True\n",
    "                        print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                            \n",
    "        if mod_found:\n",
    "            break\n",
    "            \n",
    "    if not mod_found:\n",
    "        print(\"unknown modality\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_modality(dictionary, file, verbose=False):\n",
    "    '''\n",
    "    Converts an image file and extracts information from the filename\n",
    "    (such as the modality). \n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        file (string): Filename with absolute filepath\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Check file type\n",
    "    if 'nii' in file:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'dcm' in file:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "        if not is_valid_mr(file,verbose):\n",
    "            sys.exit(f\"Invalid DICOM file. Please check {file}\")\n",
    "    \n",
    "    for key,item in dictionary.items():\n",
    "        for dict_key,dict_item in dictionary[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if list_in_substr(dict_item,file):\n",
    "                    mod_found = True\n",
    "                    print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = dictionary[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if list_in_substr(d_item,file):\n",
    "                        mod_found = True\n",
    "                        print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                        \n",
    "    if not mod_found:\n",
    "        get_scan_tech(dictionary,file)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert(file_list, dictionary, verbose=False):\n",
    "    '''\n",
    "    Batch conversion function for image files. \n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames with absolute filepaths\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            convert_modality(dictionary,file,verbose)\n",
    "        except SystemExit:\n",
    "            pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TaskName` JSON file appending funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_name = \"\"\n",
    "task_name = \"visualstrobe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name is: visualstrobe\n"
     ]
    }
   ],
   "source": [
    "if task_name == \"\":\n",
    "    print(\"task_name is empty\")\n",
    "else:\n",
    "    print(f\"task_name is: {task_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_file = \"c:/Users/smart/Desktop/GitProjects/convsauce/BIDS/rawdata/sub-C10/ses-001/func/sub-C10_ses-001_task-rest_acq-PA_run-01_bold.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(nii_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(nii_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x22eb4b28470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 45, 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.header.get_data_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.header.get_data_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = img.header.get_data_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 45, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(frames[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `NifTi` File Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bids_anat(bids_out_dir, file, sub, scan, ses=1, scan_type='anat'):\n",
    "    '''\n",
    "    Renames converted nifti files to conform with BIDS format\n",
    "    (in the case of anatomical files).\n",
    "    NB: out_dir refers to the parent or RawData directory.\n",
    "    '''\n",
    "\n",
    "    # Create Output Directory Variables\n",
    "    # Zeropad subject ID if possible\n",
    "    try:\n",
    "        ses = '{:03}'.format(int(ses))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # Zeropad session ID if possible\n",
    "    try:\n",
    "        ses = '{:03}'.format(int(ses))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    bids_out_dir = os.path.abspath(bids_out_dir)\n",
    "    outdir = os.path.join(out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "    # Make output directory\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    # Create temporary output names/directories\n",
    "    tmp_out_dir = os.path.join(out_dir, f\"sub-{sub}\", 'tmp_dir' + str(random.randint(0, n)))\n",
    "    tmp_basename = 'tmp_basename' + str(random.randint(0, n))\n",
    "\n",
    "    # Convert image file\n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file:\n",
    "        [nii_file, json_file] = convert_dcm_file(file, tmp_out_dir, tmp_basename)\n",
    "    elif 'PAR' in file:\n",
    "        [nii_file, json_file] = convert_par_file(file, tmp_out_dir, tmp_basename)\n",
    "    elif 'nii.gz' in file:\n",
    "        file_ext = \"nii.gz\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'nii' in file:\n",
    "        file_ext = \"nii.gz\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "        \n",
    "    [nii_file, json_file] = convert_par_file(par_file, tmp_out_dir, tmp_basename)\n",
    "\n",
    "    nii_file = os.path.abspath(nii_file)\n",
    "    json_file = os.path.abspath(json_file)\n",
    "\n",
    "    # Append w to T1/T2 if not already done\n",
    "    if scan in 'T1' or scan in 'T2':\n",
    "        scan = scan + 'w'\n",
    "    else:\n",
    "        scan = scan\n",
    "\n",
    "    # Get Run number\n",
    "    run = get_num_runs(outdir, scan=scan)\n",
    "    run = '{:02}'.format(run)\n",
    "\n",
    "    # Additional sequence/modality parameters\n",
    "#     epi_factor = get_epi_factor(par_file)\n",
    "#     wfs = get_wfs(par_file)\n",
    "#     bval = get_bval(par_file)\n",
    "#     acc = get_acc(par_file)\n",
    "#     mb = get_mb(par_file)\n",
    "#     sct = get_scan_time(par_file)\n",
    "\n",
    "#     # update JSON file with additional parameters\n",
    "#     json_file = update_json(json_file, bval, wfs, epi_factor, acc, mb, sct)\n",
    "\n",
    "    # Create output filenames\n",
    "    out_name = f\"sub-{sub}_ses-{ses}_run-{run}_{scan}\"\n",
    "    out_nii = os.path.join(outdir, out_name + '.nii.gz')\n",
    "    out_json = os.path.join(outdir, out_name + '.json')\n",
    "\n",
    "    os.rename(nii_file, out_nii)\n",
    "    os.rename(json_file, out_json)\n",
    "\n",
    "    # remove temporary directory and leftover files\n",
    "    shutil.rmtree(tmp_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nii_tr(nii_file):\n",
    "    '''\n",
    "    Reads the NifTi file header and returns the repetition time (TR, sec) as a value if it is not zero, otherwise this \n",
    "    function returns the string 'unknown'.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file (string): NifTi image filename with absolute filepath\n",
    "        \n",
    "    Returns: \n",
    "        tr (float or string): Repetition time (TR, sec), if not zero, otherwise 'unknown' is returned.\n",
    "    '''\n",
    "    \n",
    "    # Load nifti file\n",
    "    img = nib.load(nii_file)\n",
    "    \n",
    "    # Store nifti image TR\n",
    "    tr = float(img.header['pixdim'][4])\n",
    "    \n",
    "    # Check if TR is likely\n",
    "    if tr != 0:\n",
    "        pass\n",
    "    else:\n",
    "        tr = \"unknown\"\n",
    "    \n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_parts(file):\n",
    "    '''\n",
    "    Divides file with file path into: path, filename, extension.\n",
    "    \n",
    "    Arguments:\n",
    "        file (string): File with absolute filepath\n",
    "        \n",
    "    Returns: \n",
    "        path (string): Path of input file\n",
    "        filename (string): Filename of input file, without the extension\n",
    "        ext (string): Extension of input file\n",
    "    '''\n",
    "    \n",
    "    [path, file_with_ext] = os.path.split(file)\n",
    "    [filename,ext] = os.path.splitext(file_with_ext)\n",
    "    \n",
    "    path = str(path)\n",
    "    filename = str(filename)\n",
    "    ext = str(ext)\n",
    "    \n",
    "    return path,filename,ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gzip_file(file,rm_orig=True):\n",
    "    '''\n",
    "    Gzips file.\n",
    "    \n",
    "    Arguments:\n",
    "        file (string): Input file\n",
    "        rm_orig (boolean): If true (default), removes original file\n",
    "        \n",
    "    Returns: \n",
    "        out_file (string): Gzipped file\n",
    "    '''\n",
    "    \n",
    "    # Define tempory file for I/O buffer stream\n",
    "    tmp_file = file\n",
    "    path,f_name_,ext_ = file_parts(tmp_file)\n",
    "    f_name = f_name_ + ext_ + \".gz\"\n",
    "    out_file = os.path.join(path,f_name)\n",
    "    \n",
    "    # Gzip file\n",
    "    with open(file,\"rb\") as in_file:\n",
    "        data = in_file.read(); in_file.close()\n",
    "        with gzip.GzipFile(out_file,\"wb\") as tmp_out:\n",
    "            tmp_out.write(data)\n",
    "            tmp_out.close()\n",
    "            \n",
    "    if rm_orig:\n",
    "        os.remove(file)\n",
    "            \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gunzip_file(file,rm_orig=True):\n",
    "    '''\n",
    "    Gunzips file.\n",
    "    \n",
    "    Arguments:\n",
    "        file (string): Input file\n",
    "        rm_orig (boolean): If true (default), removes original file\n",
    "        \n",
    "    Returns: \n",
    "        out_file (string): Gunzipped file\n",
    "    '''\n",
    "    \n",
    "    # Define tempory file for I/O buffer stream\n",
    "    tmp_file = file\n",
    "    path,f_name_,ext_ = file_parts(tmp_file)\n",
    "    f_name = f_name_ # + ext_[:-3]\n",
    "    out_file = os.path.join(path,f_name)\n",
    "    \n",
    "    with gzip.GzipFile(file,\"rb\") as in_file:\n",
    "        data = in_file.read(); in_file.close()\n",
    "        with open(out_file,\"wb\") as tmp_out:\n",
    "            tmp_out.write(data)\n",
    "            tmp_out.close()\n",
    "            \n",
    "    if rm_orig:\n",
    "        os.remove(file)\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json(json_file,dictionary):\n",
    "    '''\n",
    "    Updates JavaScript Object Notation (JSON) file. If the file does not exist, it is created once\n",
    "    this function is invoked.\n",
    "    \n",
    "    Arguments:\n",
    "        json_file (string): Input file\n",
    "        dictionary (dict): Dictionary of key mapped items to write to JSON file\n",
    "        \n",
    "    Returns: \n",
    "        json_file (string): Updated JSON file\n",
    "    '''\n",
    "    \n",
    "    # Check if JSON file exists, if not, then create JSON file\n",
    "    if not os.path.exists(json_file):\n",
    "        with open(json_file,\"w\"): pass\n",
    "        \n",
    "    # Read JSON file\n",
    "    # Try-Except statement has empty exception as JSONDecodeError is not a valid exception to pass, \n",
    "    # thus throwing a name error\n",
    "    try:\n",
    "        with open(json_file) as file:\n",
    "            data_orig = json.load(file)\n",
    "    except:\n",
    "        pass\n",
    "        data_orig = dict()\n",
    "        \n",
    "    # Update original data from JSON file\n",
    "    data_orig.update(dictionary)\n",
    "    \n",
    "    # Write updated JSON file\n",
    "    with open(json_file,\"w\") as file:\n",
    "        json.dump(data_orig,file,indent=4)\n",
    "        \n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_multi_update(dictionary,**kwargs):\n",
    "    '''\n",
    "    Updates a dictionary multiple times depending on the number key word mapped pairs that are provided and \n",
    "    returns a separate updated dictionary. The dictionary passed as an argument must exist prior to this \n",
    "    function being invoked.\n",
    "    \n",
    "    Example usage:\n",
    "    \n",
    "        new_dict = dict_multi_update(old_dict,\n",
    "                                    Manufacturer=\"Philips\",\n",
    "                                    ManufacturersModelName=\"Ingenia\",\n",
    "                                    MagneticFieldStrength=3,\n",
    "                                    InstitutionName=\"CCHMC\")\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Dictionary of key mapped items to write to JSON file\n",
    "        **kwargs (string, key,value pairs): key=value pairs\n",
    "        \n",
    "    Returns: \n",
    "        new_dict (dict): New updated dictionary\n",
    "    '''\n",
    "    \n",
    "    # Create new dictionary\n",
    "    new_dict = dictionary.copy()\n",
    "    \n",
    "    for key,item in kwargs.items():\n",
    "        tmp_dict = {key:item}\n",
    "        new_dict.update(tmp_dict)\n",
    "        \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(dictionary,scan_type=\"\",task=\"\"):\n",
    "    '''\n",
    "    Reads the metadata dictionary and looks for keywords to indicate what metadata should be written to which\n",
    "    dictionary. For example, the keyword 'common' is used to indicate the common information for the imaging\n",
    "    protocol and may contain information such as: field strength, phase encoding direction, institution name, etc.\n",
    "    Additional keywords that are BIDS sub-directories names (e.g. anat, func, dwi) will return an additional\n",
    "    dictionary which contains metadata specific for those modalities. Func also has additional keywords based on\n",
    "    the task specified.\n",
    "    \n",
    "    Arguments:\n",
    "        dictionary (dict): Nest dictionary of key mapped items from the 'read_config' function\n",
    "        scan_type (string): BIDS scan type (e.g. anat, func, dwi, etc., default=\"\")\n",
    "        task (string): Task name to search in the key mapped dictionary\n",
    "        \n",
    "    Returns: \n",
    "        com_param_dict (dict): Common parameters dictionary\n",
    "        scan_param_dict (dict): Scan/modality type parameters dictionary\n",
    "    '''\n",
    "    \n",
    "    # Create empty dictionaries\n",
    "    com_param_dict = dict()\n",
    "    scan_param_dict = dict()\n",
    "    scan_task_dict = dict()\n",
    "    \n",
    "    # Iterate through, looking for key words (e.g. common and scan_type)\n",
    "    for key,item in dictionary.items():\n",
    "        if key.lower() in 'common':\n",
    "            com_param_dict = dictionary[key]\n",
    "\n",
    "        if key.lower() in scan_type:\n",
    "            scan_param_dict = dictionary[key]\n",
    "            if task.lower() in scan_param_dict:\n",
    "                for dict_key,dict_item in scan_param_dict.items():\n",
    "                    if task.lower() in dict_key:\n",
    "                        scan_task_dict = scan_param_dict[dict_key]\n",
    "                        \n",
    "        if len(scan_task_dict) != 0:\n",
    "            scan_param_dict = scan_task_dict\n",
    "    \n",
    "    return com_param_dict, scan_param_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Manufacturer': 'Philips',\n",
       "  'ManufacturersModelName': 'Ingenia',\n",
       "  'MagneticFieldStrength': 3,\n",
       "  'InstitutionName': \"Cincinnati Children's Hospital Medical Center\"},\n",
       " {})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metadata(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anat\n",
    "\n",
    "# Required\n",
    "sub = '001'\n",
    "ses = '001'\n",
    "scan_type = 'anat'\n",
    "mod = 'T2w'\n",
    "run = '01'\n",
    "\n",
    "# optional\n",
    "# acq = 'NeonateAnat'\n",
    "# ce = ''\n",
    "# rec = 'NeonateRecon'\n",
    "\n",
    "acq = ''\n",
    "ce = ''\n",
    "rec = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_out_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = f\"sub-{sub}\" + f\"_ses-{sub}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub-001_ses-001'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Desktop\\GitProjects\\convsauce\\ConvertSource\\sub-001\\ses-001\\anat\n",
      "sub-001_ses-001_run-01_T2w\n"
     ]
    }
   ],
   "source": [
    "bids_out_dir = os.getcwd()\n",
    "outdir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "out_name = f\"sub-{sub}\" + f\"_ses-{sub}\"\n",
    "\n",
    "if acq:\n",
    "    out_name = out_name + f\"_acq-{acq}\"\n",
    "    \n",
    "if ce:\n",
    "    out_name = out_name + f\"_ce-{ce}\"\n",
    "    \n",
    "if rec:\n",
    "    out_name = out_name + f\"_rec-{rec}\"\n",
    "    \n",
    "if run:\n",
    "    out_name = out_name + f\"_run-{run}\"\n",
    "    \n",
    "out_name = out_name + f\"_{mod}\"\n",
    "\n",
    "print(outdir)\n",
    "print(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional\n",
    "\n",
    "# if num_frames is 1, mod = sbref ; if greater than 1, mod = bold\n",
    "\n",
    "# Required\n",
    "sub = '001'\n",
    "ses = '001'\n",
    "scan_type = 'func'\n",
    "mod = 'bold'\n",
    "task = 'rest'\n",
    "run = '01'\n",
    "\n",
    "# optional\n",
    "# acq = 'multiband'\n",
    "# ce = ''\n",
    "# rec = 'NeonateRecon'\n",
    "# direction = 'PA'\n",
    "# echo = '01'\n",
    "\n",
    "acq = ''\n",
    "ce = ''\n",
    "rec = ''\n",
    "direction = 'PA'\n",
    "echo = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Desktop\\GitProjects\\convsauce\\ConvertSource\\sub-001\\ses-001\\func\n",
      "sub-001_ses-001_task-rest_dir-PA_run-01_bold\n"
     ]
    }
   ],
   "source": [
    "bids_out_dir = os.getcwd()\n",
    "outdir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "out_name = f\"sub-{sub}\" + f\"_ses-{ses}_task-{task}\"\n",
    "\n",
    "if acq:\n",
    "    out_name = out_name + f\"_acq-{acq}\"\n",
    "    \n",
    "if ce:\n",
    "    out_name = out_name + f\"_ce-{ce}\"\n",
    "    \n",
    "if direction:\n",
    "    out_name = out_name + f\"_dir-{direction}\"\n",
    "    \n",
    "if rec:\n",
    "    out_name = out_name + f\"_rec-{rec}\"\n",
    "    \n",
    "if run:\n",
    "    out_name = out_name + f\"_run-{run}\"\n",
    "    \n",
    "if echo:\n",
    "    out_name = out_name + f\"_echo-{echo}\"\n",
    "    \n",
    "out_name = out_name + f\"_{mod}\"\n",
    "\n",
    "print(outdir)\n",
    "print(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion\n",
    "\n",
    "# if num_frames is 1, mod = sbref ; if greater than 1, mod = dwi\n",
    "\n",
    "# Required\n",
    "sub = '001'\n",
    "ses = '001'\n",
    "scan_type = 'dwi'\n",
    "mod = 'dwi'\n",
    "run = '01'\n",
    "\n",
    "# optional\n",
    "# acq = 'b2000'\n",
    "acq = \"b0\"\n",
    "direction = 'PA'\n",
    "te = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Desktop\\GitProjects\\convsauce\\ConvertSource\\sub-001\\ses-001\\dwi\n",
      "sub-001_ses-001_acq-b0TE88_dir-PA_run-01_dwi\n"
     ]
    }
   ],
   "source": [
    "bids_out_dir = os.getcwd()\n",
    "outdir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "out_name = f\"sub-{sub}\" + f\"_ses-{ses}\"\n",
    "\n",
    "if acq and te:\n",
    "    out_name = out_name + f\"_acq-{acq}TE{te}\"\n",
    "elif acq:\n",
    "    out_name = out_name + f\"_acq-{acq}\"\n",
    "elif te:\n",
    "    out_name = out_name + f\"_acq-TE{te}\"\n",
    "    \n",
    "if direction:\n",
    "    out_name = out_name + f\"_dir-{direction}\"\n",
    "    \n",
    "if run:\n",
    "    out_name = out_name + f\"_run-{run}\"\n",
    "    \n",
    "out_name = out_name + f\"_{mod}\"\n",
    "\n",
    "print(outdir)\n",
    "print(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fieldmap\n",
    "\n",
    "# Only handles case 3 for real fieldmap images: \n",
    "# https://github.com/bids-standard/bids-specification/blob/master/src/04-modality-specific-files/01-magnetic-resonance-imaging-data.md\n",
    "# Units for fieldmap should be Hz (I think)\n",
    "\n",
    "# mod not sufficient as two files are expected. \n",
    "# magnitude image should have different variable\n",
    "\n",
    "# Required\n",
    "sub = '001'\n",
    "ses = '001'\n",
    "scan_type = 'fmap'\n",
    "mod = 'fieldmap'\n",
    "run = '01'\n",
    "\n",
    "# optional\n",
    "# acq = 'multiband'\n",
    "\n",
    "acq = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smart\\Desktop\\GitProjects\\convsauce\\ConvertSource\\sub-001\\ses-001\\fmap\n",
      "sub-001_ses-001_run-01_fieldmap\n"
     ]
    }
   ],
   "source": [
    "bids_out_dir = os.getcwd()\n",
    "outdir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "out_name = f\"sub-{sub}\" + f\"_ses-{ses}\"\n",
    "\n",
    "if acq:\n",
    "    out_name = out_name + f\"_acq-{acq}\"\n",
    "    \n",
    "if run:\n",
    "    out_name = out_name + f\"_run-{run}\"\n",
    "    \n",
    "out_name = out_name + f\"_{mod}\"\n",
    "\n",
    "print(outdir)\n",
    "print(out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read `bvals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_0800 = \"C:/Users/smart/Desktop/GitProjects/convsauce/BIDS/rawdata/sub-C10/ses-001/dwi/sub-C10_ses-001_acq-PA_dirs-036_bval-b800_run-01_dwi.bval\"\n",
    "file_2000 = \"C:/Users/smart/Desktop/GitProjects/convsauce/BIDS/rawdata/sub-C10/ses-001/dwi/sub-C10_ses-001_acq-PA_dirs-068_bval-b2000_run-01_dwi.bval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>800</th>\n",
       "      <th>800.1</th>\n",
       "      <th>800.2</th>\n",
       "      <th>800.3</th>\n",
       "      <th>800.4</th>\n",
       "      <th>800.5</th>\n",
       "      <th>...</th>\n",
       "      <th>800.22</th>\n",
       "      <th>800.23</th>\n",
       "      <th>800.24</th>\n",
       "      <th>800.25</th>\n",
       "      <th>800.26</th>\n",
       "      <th>800.27</th>\n",
       "      <th>800.28</th>\n",
       "      <th>800.29</th>\n",
       "      <th>800.30</th>\n",
       "      <th>800.31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 0.1, 0.2, 0.3, 800, 800.1, 800.2, 800.3, 800.4, 800.5, 800.6, 800.7, 800.8, 800.9, 800.10, 800.11, 800.12, 800.13, 800.14, 800.15, 800.16, 800.17, 800.18, 800.19, 800.20, 800.21, 800.22, 800.23, 800.24, 800.25, 800.26, 800.27, 800.28, 800.29, 800.30, 800.31]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file_0800,header='infer',sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   0. 800. 800. 800. 800. 800. 800. 800. 800. 800. 800.\n",
      " 800. 800. 800. 800. 800. 800. 800. 800. 800. 800. 800. 800. 800. 800.\n",
      " 800. 800. 800. 800. 800. 800. 800. 800.]\n"
     ]
    }
   ],
   "source": [
    "with open(file_0800,\"r\") as file:\n",
    "    # vals = list(file.read().splitlines())\n",
    "    print(np.loadtxt(file_0800))\n",
    "    file.close()\n",
    "    # print(vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.loadtxt(file_0800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "        21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       "       dtype=int64),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([800., 800., 800., 800., 800., 800., 800., 800., 800., 800., 800.,\n",
       "       800., 800., 800., 800., 800., 800., 800., 800., 800., 800., 800.,\n",
       "       800., 800., 800., 800., 800., 800., 800., 800., 800., 800.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_nonzero = vals[vals.astype(bool)]\n",
    "vals_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[800.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.unique(vals_nonzero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "800.0\n"
     ]
    }
   ],
   "source": [
    "for v in np.unique(vals):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bvals(bval_file):\n",
    "    '''\n",
    "    Reads the bvals from the (FSL-style) bvalue file and returns a list of unique non-zero bvalues\n",
    "    \n",
    "    Arguments:\n",
    "        bval_file (string): Absolute filepath to bval (.bval) file\n",
    "        \n",
    "    Returns: \n",
    "        bvals_list (list): List of unique, non-zero bvalues.\n",
    "    '''\n",
    "    \n",
    "    vals = np.loadtxt(bval_file)\n",
    "    vals_nonzero = vals[vals.astype(bool)]\n",
    "    bvals_list = list(np.unique(vals_nonzero))\n",
    "    \n",
    "    return bvals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[800.0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bvals(file_0800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bvals(file_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate `EffectiveEchoSpacing` and `TotalReadoutTime`\n",
    "-----\n",
    "\n",
    "See this source for details:https://github.com/bids-standard/bids-specification/blob/master/src/04-modality-specific-files/01-magnetic-resonance-imaging-data.md\n",
    "\n",
    "-----\n",
    "Siemens:        \n",
    "\n",
    "`BWPPPE` = `BandwidthPerPixelPhaseEncode `           \n",
    "\n",
    "`EffectiveEchoSpacing` = 1 / [`BWPPPE` * `ReconMatrixPE`]          \n",
    "\n",
    "`TotalReadoutTime` = `EffectiveEchoSpacing * (ReconMatrixPE - 1)`\n",
    "\n",
    "Philips:\n",
    "\n",
    "`EffectiveEchoSpacing` = (((1000*`WFS`)/(434.215*(`EchoTrainLength`+1)))/`acceleration`)           \n",
    "\n",
    "`TotalReadoutTime` = 0.001 * `EffectiveEchoSpacing` * `EchoTrainLength`\n",
    "\n",
    "See these links for Philips specific details:                 \n",
    "\n",
    "https://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=fsl;162ab1a3.1308           \n",
    "\n",
    "https://support.brainvoyager.com/brainvoyager/functional-analysis-preparation/29-pre-processing/78-epi-distortion-correction-echo-spacing-and-bandwidth           \n",
    "\n",
    "https://neurostars.org/t/consolidating-epi-echo-spacing-and-readout-time-for-philips-scanner/4406            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = \"C:/Users/smart/Desktop/GitProjects/convsauce/IRC287H-8/20171003/1101_rsfMRI_MB6_SENSE_1_fat_shift_P_017100310465322437/MR1101000016.dcm\"\n",
    "f = \"/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/1101_rsfMRI_MB6_SENSE_1_fat_shift_P_017100310465322437/MR1101000016.dcm\"\n",
    "# f = \"/Users/brac4g/Downloads/MR.1.3.12.2.1107.5.2.19.45307.2017051015422162853047250.dcm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pydicom.dcmread(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0008, 0000) Group Length                        UL: 628\n",
       "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
       "(0008, 0008) Image Type                          CS: ['ORIGINAL', 'PRIMARY', 'M_FFE', 'M', 'FFE']\n",
       "(0008, 0012) Instance Creation Date              DA: '20171003'\n",
       "(0008, 0013) Instance Creation Time              TM: '113056.330'\n",
       "(0008, 0014) Instance Creator UID                UI: 1.3.46.670589.11.89.5\n",
       "(0008, 0016) SOP Class UID                       UI: MR Image Storage\n",
       "(0008, 0018) SOP Instance UID                    UI: 1.3.46.670589.11.71329.5.0.7904.2017100310544373441\n",
       "(0008, 0020) Study Date                          DA: '20171003'\n",
       "(0008, 0021) Series Date                         DA: '20171003'\n",
       "(0008, 0022) Acquisition Date                    DA: '20171003'\n",
       "(0008, 0023) Content Date                        DA: '20171003'\n",
       "(0008, 0030) Study Time                          TM: '095546'\n",
       "(0008, 0031) Series Time                         TM: '104653.20000'\n",
       "(0008, 0032) Acquisition Time                    TM: '104719.56'\n",
       "(0008, 0033) Content Time                        TM: '104719.56'\n",
       "(0008, 0050) Accession Number                    SH: ''\n",
       "(0008, 0060) Modality                            CS: 'MR'\n",
       "(0008, 0064) Conversion Type                     CS: ''\n",
       "(0008, 0070) Manufacturer                        LO: 'Philips Medical Systems'\n",
       "(0008, 0080) Institution Name                    LO: 'Cincinnati Childrens'\n",
       "(0008, 0081) Institution Address                 ST: '3333 Burnett Ave'\n",
       "(0008, 0090) Referring Physician's Name          PN: ''\n",
       "(0008, 0100) Code Value                          SH: ''\n",
       "(0008, 0102) Coding Scheme Designator            SH: ''\n",
       "(0008, 0104) Code Meaning                        LO: ''\n",
       "(0008, 1010) Station Name                        SH: 'CCMMRT'\n",
       "(0008, 1030) Study Description                   LO: 'IRC287H'\n",
       "(0008, 103e) Series Description                  LO: 'rsfMRI MB6 SENSE 1 fat shift P'\n",
       "(0008, 1040) Institutional Department Name       LO: 'Research'\n",
       "(0008, 1050) Performing Physician's Name         PN: ''\n",
       "(0008, 1070) Operators' Name                     PN: ''\n",
       "(0008, 1080) Admitting Diagnoses Description     LO: ''\n",
       "(0008, 1090) Manufacturer's Model Name           LO: 'Ingenia'\n",
       "(0008, 1111)  Referenced Performed Procedure Step Sequence   1 item(s) ---- \n",
       "   (0008, 0012) Instance Creation Date              DA: '20171003'\n",
       "   (0008, 0013) Instance Creation Time              TM: '095545.790'\n",
       "   (0008, 0014) Instance Creator UID                UI: 1.3.46.670589.11.89.5\n",
       "   (0008, 1150) Referenced SOP Class UID            UI: Modality Performed Procedure Step SOP Class\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71329.5.0.12064.2017100309554579001\n",
       "   (0020, 0013) Instance Number                     IS: \"0\"\n",
       "   (2005, 0014) Private Creator                     LO: 'Philips MR Imaging DD 005'\n",
       "   (2005, 1404) Private tag data                    UN: b'\\x01\\x00'\n",
       "   (2005, 1406) [Unknown]                           UN: b'\\x01\\x00'\n",
       "   ---------\n",
       "(0008, 1140)  Referenced Image Sequence   3 item(s) ---- \n",
       "   (0008, 1150) Referenced SOP Class UID            UI: MR Image Storage\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71329.5.0.7904.2017100310170767007\n",
       "   ---------\n",
       "   (0008, 1150) Referenced SOP Class UID            UI: MR Image Storage\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71329.5.0.7904.2017100310172040011\n",
       "   ---------\n",
       "   (0008, 1150) Referenced SOP Class UID            UI: MR Image Storage\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71329.5.0.7904.2017100310173633016\n",
       "   ---------\n",
       "(0010, 0000) Group Length                        UL: 142\n",
       "(0010, 0010) Patient's Name                      PN: 'IRC287H-8'\n",
       "(0010, 0020) Patient ID                          LO: 'IRC287H-8'\n",
       "(0010, 0030) Patient's Birth Date                DA: '20170928'\n",
       "(0010, 0040) Patient's Sex                       CS: 'M'\n",
       "(0010, 1010) Patient's Age                       AS: '005D'\n",
       "(0010, 1030) Patient's Weight                    DS: \"3\"\n",
       "(0010, 2000) Medical Alerts                      LO: ''\n",
       "(0010, 2110) Allergies                           LO: ''\n",
       "(0010, 2160) Ethnic Group                        SH: ''\n",
       "(0010, 2180) Occupation                          SH: ''\n",
       "(0010, 21b0) Additional Patient History          LT: ''\n",
       "(0010, 21c0) Pregnancy Status                    US: 1\n",
       "(0010, 4000) Patient Comments                    LT: ''\n",
       "(0018, 0000) Group Length                        UL: 632\n",
       "(0018, 0015) Body Part Examined                  CS: 'BRAIN'\n",
       "(0018, 0020) Scanning Sequence                   CS: 'GR'\n",
       "(0018, 0021) Sequence Variant                    CS: 'SK'\n",
       "(0018, 0022) Scan Options                        CS: 'FS'\n",
       "(0018, 0023) MR Acquisition Type                 CS: '2D'\n",
       "(0018, 0050) Slice Thickness                     DS: \"2.25\"\n",
       "(0018, 0080) Repetition Time                     DS: \"892.725158691406\"\n",
       "(0018, 0081) Echo Time                           DS: \"45\"\n",
       "(0018, 0083) Number of Averages                  DS: \"1\"\n",
       "(0018, 0084) Imaging Frequency                   DS: \"127.754163\"\n",
       "(0018, 0085) Imaged Nucleus                      SH: '1H'\n",
       "(0018, 0086) Echo Number(s)                      IS: \"1\"\n",
       "(0018, 0087) Magnetic Field Strength             DS: \"3\"\n",
       "(0018, 0088) Spacing Between Slices              DS: \"2.25\"\n",
       "(0018, 0089) Number of Phase Encoding Steps      IS: \"71\"\n",
       "(0018, 0091) Echo Train Length                   IS: \"71\"\n",
       "(0018, 0093) Percent Sampling                    DS: \"98.6111145019531\"\n",
       "(0018, 0094) Percent Phase Field of View         DS: \"100\"\n",
       "(0018, 0095) Pixel Bandwidth                     DS: \"1539\"\n",
       "(0018, 1000) Device Serial Number                LO: '71329'\n",
       "(0018, 1010) Secondary Capture Device ID         LO: ''\n",
       "(0018, 1016) Secondary Capture Device Manufactur LO: ''\n",
       "(0018, 1018) Secondary Capture Device Manufactur LO: ''\n",
       "(0018, 1019) Secondary Capture Device Software V LO: ''\n",
       "(0018, 1020) Software Version(s)                 LO: ['5.3.0', '5.3.0.3']\n",
       "(0018, 1022) Video Image Format Acquired         SH: ''\n",
       "(0018, 1023) Digital Image Format Acquired       LO: ''\n",
       "(0018, 1030) Protocol Name                       LO: 'WIP rsfMRI MB6 SENSE 1 fat shift P'\n",
       "(0018, 1060) Trigger Time                        DS: \"13391\"\n",
       "(0018, 1081) Low R-R Value                       IS: \"0\"\n",
       "(0018, 1082) High R-R Value                      IS: \"0\"\n",
       "(0018, 1083) Intervals Acquired                  IS: \"0\"\n",
       "(0018, 1084) Intervals Rejected                  IS: \"0\"\n",
       "(0018, 1088) Heart Rate                          IS: \"0\"\n",
       "(0018, 1100) Reconstruction Diameter             DS: \"160\"\n",
       "(0018, 1250) Receive Coil Name                   SH: 'MULTI COIL'\n",
       "(0018, 1310) Acquisition Matrix                  US: [72, 0, 0, 71]\n",
       "(0018, 1312) In-plane Phase Encoding Direction   CS: 'COL'\n",
       "(0018, 1314) Flip Angle                          DS: \"54\"\n",
       "(0018, 1316) SAR                                 DS: \"0.68542045354843\"\n",
       "(0018, 1318) dB/dt                               DS: \"124.831504821777\"\n",
       "(0018, 1320) B1rms                               FL: 1.0596280097961426\n",
       "(0018, 5100) Patient Position                    CS: 'HFS'\n",
       "(0018, 9073) Acquisition Duration                FD: 456.17901611328125\n",
       "(0018, 9087) Diffusion b-value                   FD: 0.0\n",
       "(0018, 9089) Diffusion Gradient Orientation      FD: [0.0, 0.0, 0.0]\n",
       "(0020, 0000) Group Length                        UL: 370\n",
       "(0020, 000d) Study Instance UID                  UI: 1.3.46.670589.11.71329.5.0.12064.2017100309554561000\n",
       "(0020, 000e) Series Instance UID                 UI: 1.3.46.670589.11.71329.5.0.7904.2017100310465322437\n",
       "(0020, 0010) Study ID                            SH: '536421345'\n",
       "(0020, 0011) Series Number                       IS: \"1101\"\n",
       "(0020, 0012) Acquisition Number                  IS: \"11\"\n",
       "(0020, 0013) Instance Number                     IS: \"16\"\n",
       "(0020, 0032) Image Position (Patient)            DS: ['-80.841443896293', '-100.59328460693', '-34.093502044677']\n",
       "(0020, 0037) Image Orientation (Patient)         DS: ['1', '0', '0', '0', '1', '0']\n",
       "(0020, 0052) Frame of Reference UID              UI: 1.3.46.670589.11.71329.5.0.12900.2017100310144697000\n",
       "(0020, 0060) Laterality                          CS: ''\n",
       "(0020, 0100) Temporal Position Identifier        IS: \"16\"\n",
       "(0020, 0105) Number of Temporal Positions        IS: \"500\"\n",
       "(0020, 1040) Position Reference Indicator        LO: ''\n",
       "(0020, 1041) Slice Location                      DS: \"34.0935020446777\"\n",
       "(0028, 0000) Group Length                        UL: 178\n",
       "(0028, 0002) Samples per Pixel                   US: 1\n",
       "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028, 0010) Rows                                US: 80\n",
       "(0028, 0011) Columns                             US: 80\n",
       "(0028, 0030) Pixel Spacing                       DS: ['2', '2']\n",
       "(0028, 0100) Bits Allocated                      US: 16\n",
       "(0028, 0101) Bits Stored                         US: 12\n",
       "(0028, 0102) High Bit                            US: 11\n",
       "(0028, 0103) Pixel Representation                US: 0\n",
       "(0028, 1050) Window Center                       DS: \"785\"\n",
       "(0028, 1051) Window Width                        DS: \"1364\"\n",
       "(0028, 1052) Rescale Intercept                   DS: \"0\"\n",
       "(0028, 1053) Rescale Slope                       DS: \"2.18144078144078\"\n",
       "(0028, 1054) Rescale Type                        LO: 'normalized'\n",
       "(0032, 0000) Group Length                        UL: 48\n",
       "(0032, 1032) Requesting Physician                PN: ''\n",
       "(0032, 1033) Requesting Service                  LO: ''\n",
       "(0032, 1060) Requested Procedure Description     LO: ''\n",
       "(0032, 1070) Requested Contrast Agent            LO: ''\n",
       "(0032, 4000) Study Comments                      LT: 'IRC287H'\n",
       "(0038, 0000) Group Length                        UL: 16\n",
       "(0038, 0050) Special Needs                       LO: ''\n",
       "(0038, 0500) Patient State                       LO: ''\n",
       "(0040, 0000) Group Length                        UL: 278\n",
       "(0040, 0006) Scheduled Performing Physician's Na PN: ''\n",
       "(0040, 0241) Performed Station AE Title          AE: 'CCMMRT'\n",
       "(0040, 0242) Performed Station Name              SH: ''\n",
       "(0040, 0243) Performed Location                  SH: ''\n",
       "(0040, 0244) Performed Procedure Step Start Date DA: '20171003'\n",
       "(0040, 0245) Performed Procedure Step Start Time TM: '095546'\n",
       "(0040, 0250) Performed Procedure Step End Date   DA: '20171003'\n",
       "(0040, 0251) Performed Procedure Step End Time   TM: '095546'\n",
       "(0040, 0252) Performed Procedure Step Status     CS: ''\n",
       "(0040, 0253) Performed Procedure Step ID         SH: '536421345'\n",
       "(0040, 0254) Performed Procedure Step Descriptio LO: 'IRC287H'\n",
       "(0040, 0255) Performed Procedure Type Descriptio LO: ''\n",
       "(0040, 0260)  Performed Protocol Code Sequence   1 item(s) ---- \n",
       "   (0008, 0100) Code Value                          SH: 'UNDEFINED'\n",
       "   (0008, 0102) Coding Scheme Designator            SH: 'UNDEFINED'\n",
       "   (0008, 0104) Code Meaning                        LO: 'UNDEFINED'\n",
       "   (0008, 010b) Context Group Extension Flag        CS: 'N'\n",
       "   ---------\n",
       "(0040, 0280) Comments on the Performed Procedure ST: ''\n",
       "(0040, 1001) Requested Procedure ID              SH: ''\n",
       "(0040, 1002) Reason for the Requested Procedure  LO: ''\n",
       "(0040, 1003) Requested Procedure Priority        SH: ''\n",
       "(0040, 1004) Patient Transport Arrangements      LO: ''\n",
       "(0040, 1005) Requested Procedure Location        LO: ''\n",
       "(0040, 1400) Requested Procedure Comments        LT: ''\n",
       "(0040, 2001) Reason for the Imaging Service Requ LO: ''\n",
       "(0040, 2004) Issue Date of Imaging Service Reque DA: '20171003'\n",
       "(0040, 2005) Issue Time of Imaging Service Reque TM: '095545.619'\n",
       "(0040, 2009) Order Enterer's Location            SH: ''\n",
       "(0040, 2010) Order Callback Phone Number         SH: ''\n",
       "(0040, 2400) Imaging Service Request Comments    LT: ''\n",
       "(2001, 0000) Private Creator                     UN: b'\\xf0\\x02\\x00\\x00'\n",
       "(2001, 0010) Private tag data                    LO: 'Philips Imaging DD 001'\n",
       "(2001, 0011) Private tag data                    LO: 'Philips Imaging DD 002'\n",
       "(2001, 1001) [Chemical Shift]                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2001, 1002) [Chemical Shift Number MR]          UN: b'0 '\n",
       "(2001, 1003) [Diffusion B-Factor]                UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2001, 1004) [Diffusion Direction]               UN: b''\n",
       "(2001, 1006) [Image Enhanced]                    UN: b'N '\n",
       "(2001, 1007) [Image Type ED ES]                  UN: b'U '\n",
       "(2001, 1008) [Phase Number]                      UN: b'1 '\n",
       "(2001, 1009) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2001, 100a) [Slice Number MR]                   UN: b'1 '\n",
       "(2001, 100b) [Slice Orientation]                 UN: b'TRANSVERSAL '\n",
       "(2001, 100c) [Unknown]                           UN: b'N '\n",
       "(2001, 100e) [Unknown]                           UN: b'N '\n",
       "(2001, 100f) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2001, 1010) [Cardiac Sync]                      UN: b'NO'\n",
       "(2001, 1011) [Diffusion Echo Time]               UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2001, 1012) [Dynamic Series]                    UN: b'Y '\n",
       "(2001, 1013) [EPI Factor]                        UN: b'G\\x00\\x00\\x00'\n",
       "(2001, 1014) [Number of Echoes]                  UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2001, 1015) [Number of Locations]               UN: b'\\x01\\x00'\n",
       "(2001, 1016) [Number of PC Directions]           UN: b'\\x00\\x00'\n",
       "(2001, 1017) [Number of Phases MR]               UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2001, 1018) [Number of Slices MR]               UN: b'<\\x00\\x00\\x00'\n",
       "(2001, 1019) [Partial Matrix Scanned]            UN: b'N '\n",
       "(2001, 101a) [PC Velocity]                       UN: b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
       "(2001, 101b) [Prepulse Delay]                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2001, 101c) [Prepulse Type]                     UN: b'NO'\n",
       "(2001, 101d) [Reconstruction Number MR]          UN: b'1 '\n",
       "(2001, 101e) [Unknown]                           UN: b''\n",
       "(2001, 101f) [Respiration Sync]                  UN: b'NO'\n",
       "(2001, 1020) [Scanning Technique Description MR] UN: b'FEEPI '\n",
       "(2001, 1021) [SPIR]                              UN: b'Y '\n",
       "(2001, 1022) [Water Fat Shift]                   UN: b'\\x91\\xa8\\xccA'\n",
       "(2001, 1023) [Flip Angle Philips]                UN: b'54'\n",
       "(2001, 1024) [Interactive]                       UN: b'N '\n",
       "(2001, 1025) [Echo Time Display MR]              UN: b'45'\n",
       "(2001, 105f)  Private tag data   1 item(s) ---- \n",
       "   (2001, 0010) Private Creator                     LO: 'Philips Imaging DD 001'\n",
       "   (2001, 102d) [Number of Stack Slices]            UN: b'<\\x00'\n",
       "   (2001, 1032) [Stack Radial Angle]                UN: b'\\x00\\x00\\x00\\x00'\n",
       "   (2001, 1033) [Stack Radial Axis]                 UN: b'AP'\n",
       "   (2001, 1035) [Stack Slice Number]                UN: b'\\x01\\x00'\n",
       "   (2001, 1036) [Stack Type]                        UN: b'PARALLEL'\n",
       "   (2005, 0010) Private Creator                     LO: 'Philips MR Imaging DD 001'\n",
       "   (2005, 0014) Private Creator                     LO: 'Philips MR Imaging DD 005'\n",
       "   (2005, 0015) Private Creator                     LO: 'Philips MR Imaging DD 006'\n",
       "   (2005, 1071) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "   (2005, 1072) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "   (2005, 1073) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "   (2005, 1074) [Unknown]                           UN: b'\\x00\\x00 C'\n",
       "   (2005, 1075) [Unknown]                           UN: b'\\x00\\x00\\x07C'\n",
       "   (2005, 1076) [Unknown]                           UN: b'\\x00\\x00 C'\n",
       "   (2005, 1078) [Unknown]                           UN: b'\\x0c\\xbf\\xac\\xc1'\n",
       "   (2005, 1079) [Unknown]                           UN: b'A \\x01B'\n",
       "   (2005, 107a) [Unknown]                           UN: b'o\\xb4\\xeb\\xbf'\n",
       "   (2005, 107b) [Unknown]                           UN: b'AP'\n",
       "   (2005, 107e) [Unknown]                           UN: b'\\x00\\x00\\x10@'\n",
       "   (2005, 1081) [Unknown]                           UN: b'FH'\n",
       "   (2005, 143c) [Unknown]                           UN: b'\\xcd\\xcc\\xcc\\xbd'\n",
       "   (2005, 143d) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "   (2005, 143e) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "   (2005, 1567) Private tag data                    UN: b'0 '\n",
       "   ---------\n",
       "(2001, 1060) [Number of Stacks]                  UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2001, 1061) [Unknown]                           UN: b'N '\n",
       "(2001, 1062) [Unknown]                           UN: b'N '\n",
       "(2001, 1063) [Examination Source]                UN: b'ELSEWHERE '\n",
       "(2001, 1077) [GL TrafoType]                      UN: b''\n",
       "(2001, 107b) [Acquisition Number]                UN: b'11'\n",
       "(2001, 1081) [Number of Dynamic Scans]           UN: b'500 '\n",
       "(2001, 1082) [Echo Train Length]                 UN: b'71'\n",
       "(2001, 1083) [Imaging Frequency]                 UN: b'127.754163'\n",
       "(2001, 1084) [Inversion Time]                    UN: b'0 '\n",
       "(2001, 1085) [Magnetic Field Strength]           UN: b'3 '\n",
       "(2001, 1086) [Unknown]                           UN: b'0 '\n",
       "(2001, 1087) [Imaged Nucleus]                    UN: b'1H'\n",
       "(2001, 1088) [Number of Averages]                UN: b'1 '\n",
       "(2001, 1089) [Phase FOV Percent]                 UN: b'0 '\n",
       "(2001, 108a) [Sampling Percent]                  UN: b'0 '\n",
       "(2001, 108b) [Unknown]                           UN: b'S '\n",
       "(2001, 10c8) Private tag data                    UN: Array of 18 elements\n",
       "(2001, 10cc) [Unknown]                           UN: b''\n",
       "(2001, 10f1) [Prospective Motion Correction]     UN: Array of 24 elements\n",
       "(2001, 10f2) [Retrospective Motion Correction]   UN: Array of 24 elements\n",
       "(2001, 116b) Private tag data                    UN: b''\n",
       "(2005, 0000) Private Creator                     UN: b'b\\x0b\\x00\\x00'\n",
       "(2005, 0010) Private tag data                    LO: 'Philips MR Imaging DD 001'\n",
       "(2005, 0011) Private tag data                    LO: 'Philips MR Imaging DD 002'\n",
       "(2005, 0012) Private tag data                    LO: 'Philips MR Imaging DD 003'\n",
       "(2005, 0013) Private tag data                    LO: 'Philips MR Imaging DD 004'\n",
       "(2005, 0014) Private tag data                    LO: 'Philips MR Imaging DD 005'\n",
       "(2005, 0015) Private tag data                    LO: 'Philips MR Imaging DD 006'\n",
       "(2005, 1000) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1001) [Unknown]                           UN: b'\\x00\\x00\\x00\\x80'\n",
       "(2005, 1002) [Unknown]                           UN: b'\\x00\\x00\\x00\\x80'\n",
       "(2005, 1008) [Unknown]                           UN: b'\\x0c\\xbf\\xac\\xc1'\n",
       "(2005, 1009) [Unknown]                           UN: b'\\xbf_\\x08\\xc2'\n",
       "(2005, 100a) [Unknown]                           UN: b'o\\xb4\\xeb\\xbf'\n",
       "(2005, 100b) [Unknown]                           UN: b'\\xfa\\xc0\\xedE'\n",
       "(2005, 100c) [Unknown]                           UN: b'T{\\x88<'\n",
       "(2005, 100d) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 100e) [Unknown]                           UN: b'aK\\xda='\n",
       "(2005, 100f) [Window Center]                     UN: b'785 '\n",
       "(2005, 1010) [Window Width]                      UN: b'1364'\n",
       "(2005, 1011) [Unknown]                           UN: b'M '\n",
       "(2005, 1012) [Unknown]                           UN: b'N '\n",
       "(2005, 1013) [Unknown]                           UN: b'PATCH '\n",
       "(2005, 1014) [Unknown]                           UN: b'N '\n",
       "(2005, 1015) [Unknown]                           UN: b'Y '\n",
       "(2005, 1016) [Unknown]                           UN: b'N '\n",
       "(2005, 1017) [Unknown]                           UN: b'N '\n",
       "(2005, 1018) [Unknown]                           UN: b''\n",
       "(2005, 1019) [Unknown]                           UN: b'N '\n",
       "(2005, 101a) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 101b) [Unknown]                           UN: b'N '\n",
       "(2005, 101c) [Unknown]                           UN: b'N '\n",
       "(2005, 101d) [Unknown]                           UN: b'H\\x00'\n",
       "(2005, 101e) [Unknown]                           UN: b'compose '\n",
       "(2005, 101f) [Unknown]                           UN: b'compose '\n",
       "(2005, 1020) [Number of Chemical Shift]          UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1021) [Unknown]                           UN: b'\\x01\\x00'\n",
       "(2005, 1022) [Unknown]                           UN: b'0 '\n",
       "(2005, 1023) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1025) [Unknown]                           UN: b'\\x01\\x00'\n",
       "(2005, 1026) [Unknown]                           UN: b'N '\n",
       "(2005, 1027) [Unknown]                           UN: b'MINIMUM '\n",
       "(2005, 1028) [Unknown]                           UN: b'N '\n",
       "(2005, 1029) [Unknown]                           UN: b'N '\n",
       "(2005, 102a) [Unknown]                           UN: b'573473696 '\n",
       "(2005, 102b) [Unknown]                           UN: b'd\\x00'\n",
       "(2005, 102c) [Unknown]                           UN: b'N '\n",
       "(2005, 102d) [Unknown]                           UN: b'0 '\n",
       "(2005, 102e) [Unknown]                           UN: b'N '\n",
       "(2005, 102f) [Unknown]                           UN: b'N '\n",
       "(2005, 1030) [Repetition Time]                   UN: b'i._D\\x00\\x00\\x00\\x00'\n",
       "(2005, 1031) [Unknown]                           UN: b'N '\n",
       "(2005, 1032) [Unknown]                           UN: b''\n",
       "(2005, 1033) [Acquisition Duration]              UN: b'\\xea\\x16\\xe4C'\n",
       "(2005, 1034) [Unknown]                           UN: b'Y '\n",
       "(2005, 1035) [Unknown]                           UN: b'PIXEL '\n",
       "(2005, 1036) [Unknown]                           UN: b'N '\n",
       "(2005, 1037) [Unknown]                           UN: b'N '\n",
       "(2005, 1038) [Unknown]                           UN: b'N '\n",
       "(2005, 1039) [Unknown]                           UN: b'N '\n",
       "(2005, 103a) [Unknown]                           UN: b''\n",
       "(2005, 103b) [Unknown]                           UN: b'N '\n",
       "(2005, 103c) [Unknown]                           UN: b'N '\n",
       "(2005, 103d) [Unknown]                           UN: b'\\x01\\x00'\n",
       "(2005, 103e) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 105f) [Unknown]                           UN: b'UNKNOWN '\n",
       "(2005, 1060) [Unknown]                           UN: b'-1'\n",
       "(2005, 1061) [Unknown]                           UN: b'NO'\n",
       "(2005, 1063) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 106e) [Unknown]                           UN: b'FFE '\n",
       "(2005, 106f) [Unknown]                           UN: b'MS'\n",
       "(2005, 1070) [Unknown]                           UN: b''\n",
       "(2005, 1081) [Unknown]                           UN: b''\n",
       "(2005, 1085)  Private tag data   1 item(s) ---- \n",
       "   (2005, 0010) Private Creator                     LO: 'Philips MR Imaging DD 001'\n",
       "   (2005, 1054) [Unknown]                           UN: b'\\xa7\\xf00>'\n",
       "   (2005, 1055) [Unknown]                           UN: b'L\\x8e\\x17A'\n",
       "   (2005, 1056) [Unknown]                           UN: b'\\x08\\x0b\\xaf@'\n",
       "   (2005, 1057) [Unknown]                           UN: b'v\\xed\\x82B'\n",
       "   (2005, 1058) [Unknown]                           UN: b'\\xba&cB'\n",
       "   (2005, 1059) [Unknown]                           UN: b'QihB'\n",
       "   (2005, 105a) [Unknown]                           UN: b'q\\x99\\x95\\xc1'\n",
       "   (2005, 105b) [Unknown]                           UN: b'=W.B'\n",
       "   (2005, 105c) [Unknown]                           UN: b'!\\x19\\xd8>'\n",
       "   (2005, 105d) [Unknown]                           UN: b'RECT_VOLUME '\n",
       "   (2005, 105e) [Unknown]                           UN: b'FH'\n",
       "   ---------\n",
       "(2005, 1086) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 109f) [Unknown]                           UN: b''\n",
       "(2005, 10a0) [Unknown]                           UN: b'\\x89AVA'\n",
       "(2005, 10a1) [Syncra Scan Type]                  UN: b'SENSE '\n",
       "(2005, 10a2) [Unknown]                           UN: b'N '\n",
       "(2005, 10a8) [Unknown]                           UN: b'0 '\n",
       "(2005, 10a9) [Unknown]                           UN: b'2D'\n",
       "(2005, 10b0) [Diffusion Direction RL]            UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 10b1) [Diffusion Direction AP]            UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 10b2) [Diffusion Direction FH]            UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 10c0) [Unknown]                           UN: b'GR'\n",
       "(2005, 1134) Private tag data                    UN: b''\n",
       "(2005, 1199) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1200) [Unknown]                           UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2005, 1201) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1213) [Unknown]                           UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2005, 1245) [Unknown]                           UN: b'\\x02\\x00'\n",
       "(2005, 1249) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1251) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1252) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1253) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1256) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1325) [Unknown]                           UN: b'N '\n",
       "(2005, 1326) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1327) [Unknown]                           UN: b'REAL'\n",
       "(2005, 1328) [Unknown]                           UN: b'ORIGINAL'\n",
       "(2005, 1329) [Unknown]                           UN: b'\\x00\\x00HB'\n",
       "(2005, 1331) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1334) [Unknown]                           UN: b'UNKNOWN '\n",
       "(2005, 1335) [Unknown]                           UN: b'UNKNOWN '\n",
       "(2005, 1336) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1337) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1338) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1340) [Unknown]                           UN: b'PRE_FT'\n",
       "(2005, 1341) [Unknown]                           UN: b'UNKNOWN '\n",
       "(2005, 1342) [Unknown]                           UN: b'FID '\n",
       "(2005, 1343) [Unknown]                           UN: b'Y '\n",
       "(2005, 1345) [Unknown]                           UN: b'NO'\n",
       "(2005, 1346) [Unknown]                           UN: b'HERTZ '\n",
       "(2005, 1347) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1348) [Unknown]                           UN: b'OFF '\n",
       "(2005, 1349) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1351) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1352) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1354) [Unknown]                           UN: b''\n",
       "(2005, 1355) [Unknown]                           UN: Array of 120 elements\n",
       "(2005, 1356) [Unknown]                           UN: b'NO'\n",
       "(2005, 1357) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1358) [Unknown]                           UN: b''\n",
       "(2005, 1359) [Unknown]                           UN: b'\\x00\\x00\\x80?'\n",
       "(2005, 1360) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1362) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1363) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1364) [Unknown]                           UN: b'NO'\n",
       "(2005, 1370) [Unknown]                           UN: b'\\x00\\x00'\n",
       "(2005, 1381) [Unknown]                           UN: b'3 '\n",
       "(2005, 1382) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1391) [Unknown]                           UN: b''\n",
       "(2005, 1392) [Unknown]                           UN: b'0 '\n",
       "(2005, 1393) [Unknown]                           UN: b'-1'\n",
       "(2005, 1395) [Unknown]                           UN: Array of 114 elements\n",
       "(2005, 1396) [Unknown]                           UN: b'NO'\n",
       "(2005, 1397) [Unknown]                           UN: Array of 18 elements\n",
       "(2005, 1398) [Unknown]                           UN: b'NO'\n",
       "(2005, 1399) [Unknown]                           UN: b'YES '\n",
       "(2005, 1400) [Unknown]                           UN: b'YES '\n",
       "(2005, 1401) [Unknown]                           UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2005, 1403) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1409) [Unknown]                           UN: b'0 '\n",
       "(2005, 140a) [Unknown]                           UN: b'2.18144078144078'\n",
       "(2005, 140b) [Unknown]                           UN: b'normalized'\n",
       "(2005, 140f)  Private tag data   1 item(s) ---- \n",
       "   (0008, 002a) Acquisition DateTime                DT: '20171003'\n",
       "   (0008, 9123) Creator-Version UID                 UI: 1.3.46.670589.11\n",
       "   (0008, 9205) Pixel Presentation                  CS: 'MONOCHROME'\n",
       "   (0008, 9206) Volumetric Properties               CS: 'VOLUME'\n",
       "   (0008, 9207) Volume Based Calculation Technique  CS: 'NONE'\n",
       "   (0008, 9209) Acquisition Contrast                CS: 'UNKNOWN'\n",
       "   (0018, 9005) Pulse Sequence Name                 SH: 'FEEPI'\n",
       "   (0018, 9008) Echo Pulse Sequence                 CS: 'GRADIENT'\n",
       "   (0018, 9009) Inversion Recovery                  CS: 'NO'\n",
       "   (0018, 9011) Multiple Spin Echo                  CS: 'NO'\n",
       "   (0018, 9012) Multi-planar Excitation             CS: 'NO'\n",
       "   (0018, 9014) Phase Contrast                      CS: 'NO'\n",
       "   (0018, 9015) Time of Flight Contrast             CS: 'NO'\n",
       "   (0018, 9016) Spoiling                            CS: 'NONE'\n",
       "   (0018, 9017) Steady State Pulse Sequence         CS: 'NONE'\n",
       "   (0018, 9018) Echo Planar Pulse Sequence          CS: 'YES'\n",
       "   (0018, 9019) Tag Angle First Axis                FD: 7.23e+75\n",
       "   (0018, 9020) Magnetization Transfer              CS: 'NONE'\n",
       "   (0018, 9021) T2 Preparation                      CS: 'NO'\n",
       "   (0018, 9022) Blood Signal Nulling                CS: 'NO'\n",
       "   (0018, 9024) Saturation Recovery                 CS: 'NO'\n",
       "   (0018, 9025) Spectrally Selected Suppression     CS: 'FAT'\n",
       "   (0018, 9026) Spectrally Selected Excitation      CS: 'NONE'\n",
       "   (0018, 9027) Spatial Pre-saturation              CS: 'NONE'\n",
       "   (0018, 9028) Tagging                             CS: 'NONE'\n",
       "   (0018, 9029) Oversampling Phase                  CS: 'NONE'\n",
       "   (0018, 9030) Tag Spacing First Dimension         FD: 7.23e+75\n",
       "   (0018, 9032) Geometry of k-Space Traversal       CS: 'RECTILINEAR'\n",
       "   (0018, 9033) Segmented k-Space Traversal         CS: 'PARTIAL'\n",
       "   (0018, 9034) Rectilinear Phase Encode Reordering CS: 'UNKNOWN'\n",
       "   (0018, 9035) Tag Thickness                       FD: 0.0\n",
       "   (0018, 9036) Partial Fourier Direction           CS: ''\n",
       "   (0018, 9037) Cardiac Synchronization Technique   CS: 'NONE'\n",
       "   (0018, 9043) Receive Coil Type                   CS: 'MULTICOIL'\n",
       "   (0018, 9044) Quadrature Receive Coil             CS: 'NO'\n",
       "   (0018, 9047) Multi-Coil Element Name             SH: 'MULTI ELEMENT'\n",
       "   (0018, 9050) Transmit Coil Manufacturer Name     LO: ''\n",
       "   (0018, 9051) Transmit Coil Type                  CS: 'SURFACE'\n",
       "   (0018, 9053) Chemical Shift Reference            FD: [4.68, 4.68]\n",
       "   (0018, 9058) MR Acquisition Frequency Encoding S US: 72\n",
       "   (0018, 9059) De-coupling                         CS: 'NO'\n",
       "   (0018, 9060) De-coupled Nucleus                  CS: ''\n",
       "   (0018, 9062) De-coupling Method                  CS: ''\n",
       "   (0018, 9064) k-space Filtering                   CS: 'RIESZ'\n",
       "   (0018, 9065) Time Domain Filtering               CS: ''\n",
       "   (0018, 9069) Parallel Reduction Factor In-plane  FD: 1.0\n",
       "   (0018, 9075) Diffusion Directionality            CS: 'NONE'\n",
       "   (0018, 9077) Parallel Acquisition                CS: 'YES'\n",
       "   (0018, 9078) Parallel Acquisition Technique      CS: 'SENSE'\n",
       "   (0018, 9079) Inversion Times                     FD: 0.0\n",
       "   (0018, 9080) Metabolite Map Description          ST: 'WATER'\n",
       "   (0018, 9081) Partial Fourier                     CS: 'NO'\n",
       "   (0018, 9085) Cardiac Signal Source               CS: ''\n",
       "   (0018, 9087) Diffusion b-value                   FD: 7.23e+75\n",
       "   (0018, 9089) Diffusion Gradient Orientation      FD: [7.23e+75, 7.23e+75, 7.23e+75]\n",
       "   (0018, 9090) Velocity Encoding Direction         FD: [0.0, 0.0, 0.0]\n",
       "   (0018, 9091) Velocity Encoding Minimum Value     FD: 0.0\n",
       "   (0018, 9093) Number of k-Space Trajectories      US: 1\n",
       "   (0018, 9094) Coverage of k-Space                 CS: ''\n",
       "   (0018, 9101) Frequency Correction                CS: 'NO'\n",
       "   (0018, 9147) Diffusion Anisotropy Type           CS: ''\n",
       "   (0018, 9155) Parallel Reduction Factor out-of-pl FD: 1.0\n",
       "   (0018, 9168) Parallel Reduction Factor Second In FD: 1.0\n",
       "   (0018, 9169) Cardiac Beat Rejection Technique    CS: ''\n",
       "   (0018, 9170) Respiratory Motion Compensation Tec CS: 'NONE'\n",
       "   (0018, 9171) Respiratory Signal Source           CS: 'NONE'\n",
       "   (0018, 9172) Bulk Motion Compensation Technique  CS: 'NONE'\n",
       "   (0018, 9174) Applicable Safety Standard Agency   CS: 'IEC'\n",
       "   (0018, 9176)  Operating Mode Sequence   3 item(s) ---- \n",
       "      (0018, 9177) Operating Mode Type                 CS: 'STATIC FIELD'\n",
       "      (0018, 9178) Operating Mode                      CS: 'IEC_FIRST_LEVEL'\n",
       "      ---------\n",
       "      (0018, 9177) Operating Mode Type                 CS: 'RF'\n",
       "      (0018, 9178) Operating Mode                      CS: 'IEC_NORMAL'\n",
       "      ---------\n",
       "      (0018, 9177) Operating Mode Type                 CS: 'GRADIENT'\n",
       "      (0018, 9178) Operating Mode                      CS: 'IEC_FIRST_LEVEL'\n",
       "      ---------\n",
       "   (0018, 9179) Specific Absorption Rate Definition CS: 'IEC_WHOLE_BODY'\n",
       "   (0018, 9180) Gradient Output Type                CS: 'DB_DT'\n",
       "   (0018, 9181) Specific Absorption Rate Value      FD: 0.6854204535484314\n",
       "   (0018, 9182) Gradient Output                     FD: 124.83150482177734\n",
       "   (0018, 9183) Flow Compensation Direction         CS: ''\n",
       "   (0018, 9199) Water Referenced Phase Correction   CS: 'NO'\n",
       "   (0018, 9200) MR Spectroscopy Acquisition Type    CS: ''\n",
       "   (0018, 9231) MR Acquisition Phase Encoding Steps US: 71\n",
       "   (0018, 9232) MR Acquisition Phase Encoding Steps US: 1\n",
       "   (0018, 9240) RF Echo Train Length                US: 0\n",
       "   (0018, 9241) Gradient Echo Train Length          US: 71\n",
       "   (0018, 9602) Diffusion b-value XX                FD: 7.23e+75\n",
       "   (0018, 9603) Diffusion b-value XY                FD: 7.23e+75\n",
       "   (0018, 9604) Diffusion b-value XZ                FD: 7.23e+75\n",
       "   (0018, 9605) Diffusion b-value YY                FD: 7.23e+75\n",
       "   (0018, 9606) Diffusion b-value YZ                FD: 7.23e+75\n",
       "   (0018, 9607) Diffusion b-value ZZ                FD: 7.23e+75\n",
       "   (0020, 9072) Frame Laterality                    CS: 'U'\n",
       "   (0020, 9254) Respiratory Interval Time           FD: 0.0\n",
       "   (0020, 9255) Nominal Respiratory Trigger Delay T FD: 0.0\n",
       "   (0020, 9256) Respiratory Trigger Delay Threshold FD: 7.23e+75\n",
       "   (0028, 9001) Data Point Rows                     UL: 1\n",
       "   (0028, 9002) Data Point Columns                  UL: 0\n",
       "   (0028, 9003) Signal Domain Columns               CS: ''\n",
       "   (0028, 9108) Data Representation                 CS: ''\n",
       "   (0040, 9210) LUT Label                           SH: 'Philips'\n",
       "   ---------\n",
       "(2005, 1410) [Unknown]                           UN: b'2147483647'\n",
       "(2005, 1412) [Unknown]                           UN: b'1 '\n",
       "(2005, 1413) [Unknown]                           UN: b'1 '\n",
       "(2005, 1414) [Unknown]                           UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2005, 1415) [Unknown]                           UN: b'\\x01\\x00\\x00\\x00'\n",
       "(2005, 1416) [Unknown]                           UN: b'MAN '\n",
       "(2005, 1418) [Unknown]                           UN: Array of 24 elements\n",
       "(2005, 1419) [Unknown]                           UN: Array of 42 elements\n",
       "(2005, 141a) [Unknown]                           UN: b'SPIR'\n",
       "(2005, 141b) [Unknown]                           UN: b'0 '\n",
       "(2005, 141c) [Unknown]                           UN: b'0 '\n",
       "(2005, 141d) [Unknown]                           UN: b'0 '\n",
       "(2005, 1426) [Unknown]                           UN: b'N '\n",
       "(2005, 1428) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1429) Private tag data                    UN: b''\n",
       "(2005, 142a) [Unknown]                           UN: b'INITIAL '\n",
       "(2005, 142b) [Unknown]                           UN: b'PARTLY_ACCEPTED '\n",
       "(2005, 142c) [Unknown]                           UN: b'INITIAL '\n",
       "(2005, 142d) [Unknown]                           UN: b'INITIAL '\n",
       "(2005, 142e) [Unknown]                           UN: b'\\x9e\\xc9\\xff~'\n",
       "(2005, 142f) [Unknown]                           UN: b'\\x9e\\xc9\\xff~'\n",
       "(2005, 1430) [Unknown]                           UN: b'\\x9e\\xc9\\xff~'\n",
       "(2005, 1431) [Unknown]                           UN: b'\\x9e\\xc9\\xff~'\n",
       "(2005, 1432) [Unknown]                           UN: b'N '\n",
       "(2005, 1435) [Unknown]                           UN: b'N '\n",
       "(2005, 1437) [Unknown]                           UN: b''\n",
       "(2005, 143a) [Unknown]                           UN: Array of 26 elements\n",
       "(2005, 143b) [Unknown]                           UN: b'N '\n",
       "(2005, 143f) [Unknown]                           UN: b'N '\n",
       "(2005, 1440) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1441) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1442) [Unknown]                           UN: b'7!\\x87?'\n",
       "(2005, 1443) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1444) [Unknown]                           UN: b'1 '\n",
       "(2005, 1445) [Unknown]                           UN: b'N '\n",
       "(2005, 1446) [Unknown]                           UN: b'\\x9e\\xc9\\xff~'\n",
       "(2005, 1447) [Unknown]                           UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1448) [Unknown]                           UN: b'\\x9e\\xc9\\xff~'\n",
       "(2005, 144d) [Unknown]                           UN: b'N '\n",
       "(2005, 144e) [Unknown]                           UN: b'N '\n",
       "(2005, 1492) Private tag data                    UN: b'N\\xb1\\x9c>'\n",
       "(2005, 1553) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1554) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1555) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1556) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1557) Private tag data                    UN: b'NONE'\n",
       "(2005, 1558) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1559) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1560) Private tag data                    UN: b'0 '\n",
       "(2005, 1561) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1562) Private tag data                    UN: b'N/A '\n",
       "(2005, 1563) Private tag data                    UN: b'LR'\n",
       "(2005, 1564) Private tag data                    UN: b'AP'\n",
       "(2005, 1565) Private tag data                    UN: b'FH'\n",
       "(2005, 1566) Private tag data                    UN: b'FH'\n",
       "(2005, 1568) Private tag data                    UN: b'1 '\n",
       "(2005, 1571) Private tag data                    UN: b'0 '\n",
       "(2005, 1572) Private tag data                    UN: b'\\x00\\x00\\x00\\x00'\n",
       "(2005, 1573) Private tag data                    UN: b'0 '\n",
       "(2005, 1574) Private tag data                    UN: b'0 '\n",
       "(2005, 1575) Private tag data                    UN: b'0 '\n",
       "(2005, 1576) Private tag data                    UN: b''\n",
       "(2005, 1578) Private tag data                    UN: b''\n",
       "(2005, 1579) Private tag data                    UN: Array of 44 elements\n",
       "(2005, 1581) Private tag data                    UN: b'FIRSTLEVEL'\n",
       "(2005, 1582) Private tag data                    UN: b'0 '\n",
       "(2005, 1583) Private tag data                    UN: b''\n",
       "(2005, 1585) Private tag data                    UN: b'0 '\n",
       "(2005, 1586) Private tag data                    UN: b''\n",
       "(2005, 1587) Private tag data                    UN: b'0 '\n",
       "(2050, 0000) Group Length                        UL: 16\n",
       "(2050, 0020) Presentation LUT Shape              CS: 'IDENTITY'\n",
       "(7fe0, 0000) Group Length                        UL: 12808\n",
       "(7fe0, 0010) Pixel Data                          OW: Array of 12800 elements"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004098360655737705"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Siemens\n",
    "1/2440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000649772579597141"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Philips\n",
    "1/1539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004575863236599585"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Effective Echo Spacing Philips dicom\n",
    "1/(1539*71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006406208531239419"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Readout time philips dicom\n",
    "((1/(1539*71))*(71-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04484345971867593"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Readout time philips dicom (acceptable?)\n",
    "(0.0006406208531239419)*(71-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005300023744106374"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Effective Echo Spacing Siemens\n",
    "1/(29.481*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033390149587870156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Readout time Siemens\n",
    "(1/(29.481*64))*(64-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_read_time():\n",
    "    '''\n",
    "    working doc-string: continue later\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dcm2niix` Wrapper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_data(file,basename,out_dir,cprss_lvl=6,bids=True,\n",
    "                       anon_bids=True,gzip=True,comment=True,\n",
    "                       adjacent=False,dir_search=5,nrrd=False,\n",
    "                       ignore_2D=True,merge_2D=True,text=False,\n",
    "                       progress=False,verbose=False,\n",
    "                       write_conflicts=\"suffix\",crop_3D=False,\n",
    "                       lossless=False,big_endian=\"optimal\",xml=False):\n",
    "    '''\n",
    "    Converts raw image data (DICOM, PAR REC, or Bruker) to NifTi (or NRRD) using dcm2niix.\n",
    "    This is a wrapper function for dcm2niix (v1.0.20190902+). This wrapper functions has no returns, \n",
    "    however output files are generated in a specified directory that must exist prior to the \n",
    "    invokation of this function.\n",
    "    \n",
    "    Note: Most of the defaults for dcm2niix have been preserved aside from those starred (*) in the\n",
    "    (optional) arguments section, in order to be BIDS compliant.\n",
    "\n",
    "    Arguments (Required):\n",
    "        file (string): Absolute path to raw image data file\n",
    "        basename (string): Output file(s) basename\n",
    "        out_dir (string): Absolute path to output directory (must exist at runtime)\n",
    "\n",
    "    Arguments (Optional):\n",
    "        cprss_lvl (int): Compression level [1 - 9] - 1 is fastest, 9 is smallest (default: 6)\n",
    "        bids (bool): BIDS (JSON) sidecar (default: True) * \n",
    "        anon_bids (bool): Anonymize BIDS (default: True) * \n",
    "        gzip (bool): Gzip compress images (default: True) *\n",
    "        comment (bool): Image comment(s) stored in NifTi header (default: True) *\n",
    "        adjacent (bool): Assumes adjacent DICOMs/Image data (images from same series always in same folder) for faster conversion (default: False)\n",
    "        dir_search (int): Directory search depth (default: 5)\n",
    "        nrrd (bool): Export as NRRD instead of NifTi, not recommended (default: False)\n",
    "        ignore_2D (bool): Ignore derived, localizer and 2D images (default: True)\n",
    "        merge_2D (bool): Merge 2D slices from same series regardless of echo, exposure, etc. (default: True)\n",
    "        text (bool): Text notes includes private patient details in separate text file (default: False)\n",
    "        progress (bool): Report progress, slicer format progress information (default: True)\n",
    "        verbose (bool): Enable verbosity (default: False)\n",
    "        write_conflicts (string): Write behavior for name conflicts:\n",
    "            - 'suffix' = Add suffix to name conflict (default)\n",
    "            - 'overwrite' = Overwrite name conflict\n",
    "            - 'skip' = Skip name conflict\n",
    "        crop_3D (bool): crop 3D acquisitions (default: False)\n",
    "        lossless (bool): Losslessly scale 16-bit integers to use dynamic range (default: True)\n",
    "        big_endian (string): Byte order:\n",
    "            - 'optimal' or 'native' = optimal/native byte order (default)\n",
    "            - 'little-end' = little endian\n",
    "            - 'big-end' = big endian\n",
    "        xml (bool): Slicer format features (default: False)\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "    '''\n",
    "\n",
    "    # Empty list\n",
    "    conv_cmd = list()\n",
    "\n",
    "    # Get OS platform\n",
    "    if platform.system().lower() == 'windows':\n",
    "        conv_cmd.append(\"dcm2niix.exe\")\n",
    "    else:\n",
    "        conv_cmd.append(\"dcm2niix\")\n",
    "\n",
    "    # Boolean True/False options arrays\n",
    "    bool_opts = [bids, anon_bids, gzip, comment, adjacent, nrrd, ignore_2D, merge_2D, text, verbose, lossless, progress, xml]\n",
    "    bool_vars = [\"-b\", \"-ba\", \"-z\", \"-c\", \"-a\", \"-e\", \"-i\", \"-m\", \"-t\", \"-v\", \"-l\", \"--progress\", \"--xml\"]\n",
    "\n",
    "    # Initial option(s)\n",
    "    if cprss_lvl:\n",
    "        conv_cmd.append(f\"-{cprss_lvl}\")\n",
    "\n",
    "    # Required option(s)\n",
    "    if basename:\n",
    "        conv_cmd.append(\"-f\")\n",
    "        conv_cmd.append(f\"{basename}\")\n",
    "\n",
    "    if basename:\n",
    "        conv_cmd.append(\"-f\")\n",
    "        conv_cmd.append(f\"{basename}\")\n",
    "\n",
    "    if out_dir:\n",
    "        conv_cmd.append(\"-o\")\n",
    "        conv_cmd.append(f\"{out_dir}\")\n",
    "\n",
    "    # Keyword option(s)\n",
    "    if write_conflicts.lower() == \"suffix\":\n",
    "        conv_cmd.append(\"-w\")\n",
    "        conv_cmd.append(\"2\")\n",
    "    elif write_conflicts.lower() == \"overwrite\":\n",
    "        conv_cmd.append(\"-w\")\n",
    "        conv_cmd.append(\"1\")\n",
    "    elif write_conflicts.lower() == \"skip\":\n",
    "        conv_cmd.append(\"-w\")\n",
    "        conv_cmd.append(\"0\")\n",
    "\n",
    "    if big_endian.lower() == \"optimal\" or big_endian.lower() == \"native\":\n",
    "        conv_cmd.append(\"--big_endian\")\n",
    "        conv_cmd.append(\"o\")\n",
    "    elif big_endian.lower() == \"little-end\":\n",
    "        conv_cmd.append(\"--big_endian\")\n",
    "        conv_cmd.append(\"n\")\n",
    "    elif big_endian.lower() == \"big-end\":\n",
    "        conv_cmd.append(\"--big_endian\")\n",
    "        conv_cmd.append(\"y\")\n",
    "\n",
    "\n",
    "    for idx,var in enumerate(bool_opts):\n",
    "        if var:\n",
    "            conv_cmd.append(bool_vars[idx])\n",
    "            conv_cmd.append(\"y\")\n",
    "\n",
    "    # Required arguments\n",
    "    # Filename\n",
    "    conv_cmd.append(\"-f\")\n",
    "    conv_cmd.append(f\"{basename}\")\n",
    "\n",
    "    # Output directory\n",
    "    conv_cmd.append(\"-o\")\n",
    "    conv_cmd.append(f\"{out_dir}\")\n",
    "\n",
    "    # Image file   \n",
    "    conv_cmd.append(f\"{file}\")\n",
    "\n",
    "    # System Call to dcm2niix (assumes dcm2niix is added to system path variable)\n",
    "    subprocess.call(conv_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"C:/Users/smart/Desktop/GitProjects/convsauce/IRC287H-8/20171003/303_CORONAL_2017100310262626000/MR0303000001.dcm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=\"test_tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_image_data(f,base,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
