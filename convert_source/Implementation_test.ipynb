{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: convert_source.py [-h] -s subject_ID -o Output_BIDS_Directory -d\r\n",
      "                         data_directory -c config.yml -f file_type\r\n",
      "                         [-ses session] [-k] [-v]\r\n",
      "\r\n",
      "Performs conversion of source DICOM, PAR REC, and Nifti data to BIDS directory\r\n",
      "layout.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "\r\n",
      "Required arguments:\r\n",
      "  -s subject_ID, -sub subject_ID, --sub subject_ID\r\n",
      "                        Unique subject identifier given to each participant.\r\n",
      "                        This indentifier CAN contain letters and numbers. This\r\n",
      "                        identifier CANNOT contain: underscores, hyphens,\r\n",
      "                        colons, semi-colons, spaces, or any other special\r\n",
      "                        characters.\r\n",
      "  -o Output_BIDS_Directory, -out Output_BIDS_Directory, --out Output_BIDS_Directory\r\n",
      "                        BIDS output directory. This directory does not need to\r\n",
      "                        exist at runtime. The resulting directory will be\r\n",
      "                        populated with BIDS named and structured data.\r\n",
      "  -d data_directory, -data data_directory, --data data_directory\r\n",
      "                        Parent directory that contains that subuject's\r\n",
      "                        unconverted source data. This directory can contain\r\n",
      "                        either all the PAR REC files, or all the directories\r\n",
      "                        of the DICOM files. NOTE: filepaths with spaces either\r\n",
      "                        need to replaced with underscores or placed in quotes.\r\n",
      "                        NOTE: The PAR REC directory is rename PAR_REC\r\n",
      "                        automaticaly.\r\n",
      "  -c config.yml, -config config.yml, --config config.yml\r\n",
      "                        YAML configuruation file that contains modality\r\n",
      "                        search, parameters, metadata, and exclusion list.\r\n",
      "  -f file_type, -file file_type, --file-type file_type\r\n",
      "                        File type that is to be used with the converter.\r\n",
      "                        Acceptable choices include: DCM, PAR, or, NII.\r\n",
      "\r\n",
      "Optional arguments:\r\n",
      "  -ses session, --ses session\r\n",
      "                        Session label for the acquired source data. [default:\r\n",
      "                        1]\r\n",
      "  -k, -keep, --keep-unknown\r\n",
      "                        Keep or remove unknown modalities [default: True].\r\n",
      "  -v, -verbose, --verbose\r\n",
      "                        Prints additional information to screen. [default:\r\n",
      "                        False]\r\n"
     ]
    }
   ],
   "source": [
    "! ./convert_source.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'C10'\n",
    "ddir = \"/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC\"\n",
    "bids = \"/Users/brac4g/Desktop/convsauce/BIDS.new\"\n",
    "conf = \"/Users/brac4g/Desktop/convsauce/convert_source/config.default.yml\"\n",
    "ses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 40 slices\n",
      "Philips Scaling Values RS:RI:SS = 5.85739:0:0.0663237 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir1339/tmp_basename4118 (512x512x40x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir1339/tmp_basename4118.nii\"\n",
      "Conversion required 0.340739 seconds (0.103620 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Reported TR=8975.84ms, measured TR=15940ms (prospect. motion corr.?)\n",
      "Warning: More volumes than described in header (ADC or isotropic?)\n",
      "Done reading PAR header version 4.2, with 216 slices\n",
      "Error: Bizarre b-vectors /Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_6_DIR_B0_A_TE88_SENSE_NO_MB_NO_4DYN_5_1.REC\n",
      "Philips Scaling Values RS:RI:SS = 2.01465:0:0.028553 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir8270/tmp_basename7184 (80x80x54x4)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir8270/tmp_basename7184.nii\"\n",
      "Conversion required 0.090144 seconds (0.018130 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Reported TR=6755ms, measured TR=13510ms (prospect. motion corr.?)\n",
      "Warning: More volumes than described in header (ADC or isotropic?)\n",
      "Done reading PAR header version 4.2, with 324 slices\n",
      "Error: Bizarre b-vectors /Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_6_DIR_B0_A_TE88_6DYN_20_1.REC\n",
      "Philips Scaling Values RS:RI:SS = 3.67106:0:0.0197391 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5690/tmp_basename642 (80x80x54x6)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5690/tmp_basename642.nii\"\n",
      "Conversion required 0.092681 seconds (0.023358 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 35 slices\n",
      "Philips Scaling Values RS:RI:SS = 6.3094:0:0.0784964 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4554/tmp_basename5628 (512x512x35x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4554/tmp_basename5628.nii\"\n",
      "Conversion required 0.181474 seconds (0.099395 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 110 slices\n",
      "Philips Scaling Values RS:RI:SS = 4.10281:0:0.00606359 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir2291/tmp_basename4466 (160x160x110x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir2291/tmp_basename4466.nii\"\n",
      "Conversion required 0.108387 seconds (0.027974 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 35 slices\n",
      "Philips Scaling Values RS:RI:SS = 6.3094:0:0.0784964 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir6366/tmp_basename5220 (512x512x35x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir6366/tmp_basename5220.nii\"\n",
      "Conversion required 0.163165 seconds (0.085217 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 35 slices\n",
      "Philips Scaling Values RS:RI:SS = 4.10281:0:0.00606359 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir2908/tmp_basename2656 (512x512x35x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir2908/tmp_basename2656.nii\"\n",
      "Conversion required 0.168772 seconds (0.083907 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Field map in Hz will be saved as the 'real' image.\n",
      "Warning: 'scanning sequence' column varies within a single file. This behavior is not described at the top of the header.\n",
      "Warning: Intensity slope/intercept varies between slices! [check resulting images]\n",
      "Done reading PAR header version 4.2, with 64 slices\n",
      "Philips Scaling Values RS:RI:SS = 0.81905:0:0.0788891 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4698/tmp_basename556 (144x144x32x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4698/tmp_basename556.nii\"\n",
      "Philips Scaling Values RS:RI:SS = 0.10598:-217:9.4185 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4698/tmp_basename556_real (144x144x32x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4698/tmp_basename556_real.nii\"\n",
      "Conversion required 0.340551 seconds (0.024508 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 35 slices\n",
      "Philips Scaling Values RS:RI:SS = 5.85739:0:0.0663237 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir3377/tmp_basename2790 (512x512x35x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir3377/tmp_basename2790.nii\"\n",
      "Conversion required 0.176556 seconds (0.089659 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 110 slices\n",
      "Philips Scaling Values RS:RI:SS = 5.85739:0:0.0663237 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir1085/tmp_basename6283 (160x160x110x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir1085/tmp_basename6283.nii\"\n",
      "Conversion required 0.089273 seconds (0.029172 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: More volumes than described in header (ADC or isotropic?)\n",
      "Done reading PAR header version 4.2, with 1944 slices\n",
      "Philips Scaling Values RS:RI:SS = 3.3663:0:0.0151075 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir9264/tmp_basename9688 (80x80x54x36)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir9264/tmp_basename9688.nii\"\n",
      "Conversion required 0.288567 seconds (0.133846 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 45 slices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philips Scaling Values RS:RI:SS = 4.10281:0:0.00606359 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir6674/tmp_basename8281 (512x512x45x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir6674/tmp_basename8281.nii\"\n",
      "Conversion required 0.250732 seconds (0.124745 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Distance between slices reported by slice gap+thick does not match estimate from slice positions (issue 273).\n",
      "Done reading PAR header version 4.2, with 45 slices\n",
      "Philips Scaling Values RS:RI:SS = 9.2105:0:0.0181626 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir2821/tmp_basename4596 (64x64x45x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir2821/tmp_basename4596.nii\"\n",
      "Conversion required 0.139813 seconds (0.003350 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Distance between slices reported by slice gap+thick does not match estimate from slice positions (issue 273).\n",
      "Done reading PAR header version 4.2, with 40 slices\n",
      "Philips Scaling Values RS:RI:SS = 6.3094:0:0.0784964 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4666/tmp_basename5950 (512x512x40x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir4666/tmp_basename5950.nii\"\n",
      "Conversion required 0.171791 seconds (0.095266 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: More volumes than described in header (ADC or isotropic?)\n",
      "Done reading PAR header version 4.2, with 3672 slices\n",
      "Philips Scaling Values RS:RI:SS = 40.4234:0:0.0104697 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5588/tmp_basename6972 (80x80x54x68)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5588/tmp_basename6972.nii\"\n",
      "Conversion required 0.617326 seconds (0.263199 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Distance between slices reported by slice gap+thick does not match estimate from slice positions (issue 273).\n",
      "Done reading PAR header version 4.2, with 45 slices\n",
      "Philips Scaling Values RS:RI:SS = 9.93871:0:0.0181626 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir9629/tmp_basename5005 (64x64x45x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir9629/tmp_basename5005.nii\"\n",
      "Conversion required 0.026466 seconds (0.003825 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: PAR/REC dataset includes derived (isotropic, ADC, etc) map(s) that could disrupt analysis. Please remove volume and ensure vectors are reported correctly\n",
      "Done reading PAR header version 4.2, with 272 slices\n",
      "Note: 1 volumes appear to be ADC or trace images that will be removed to allow processing\n",
      "Philips Scaling Values RS:RI:SS = 3.95214:0:0.080264 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir6235/tmp_basename2139 (160x160x34x8)\n",
      "Ignoring derived diffusion image(s). Better isotropic and ADC maps can be generated later processing.\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir6235/tmp_basename2139.nii\"\n",
      "Conversion required 0.186222 seconds (0.083579 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Error: Unknown type -1: not magnitude[0], real[1], imaginary[2] or phase[3].\n",
      "Error: Catastrophic error: found 110 but expected 220 slices. /Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SWIp_11_1.PAR\n",
      "  slices*grad*bval*cardiac*echo*dynamic*mix*labels = 110*1*1*1*4*1*1*1\n",
      "Warning: Intensity slope/intercept varies between slices! [check resulting images]\n",
      "Done reading PAR header version 4.2, with 220 slices\n",
      "Error: unable to convert /Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SWIp_11_1.PAR\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 110 slices\n",
      "Philips Scaling Values RS:RI:SS = 6.3094:0:0.0784964 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir3275/tmp_basename3451 (160x160x110x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir3275/tmp_basename3451.nii\"\n",
      "Conversion required 0.086288 seconds (0.031795 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Done reading PAR header version 4.2, with 35 slices\n",
      "Philips Scaling Values RS:RI:SS = 5.85739:0:0.0663237 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5448/tmp_basename9667 (512x512x35x1)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5448/tmp_basename9667.nii\"\n",
      "Conversion required 0.176888 seconds (0.085980 for core code).\n",
      "Chris Rorden's dcm2niiX version v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0 (64-bit MacOS)\n",
      "Warning: dcm2niix PAR is not actively supported (hint: use dicm2nii)\n",
      "Warning: Distance between slices reported by slice gap+thick does not match estimate from slice positions (issue 273).\n",
      "Done reading PAR header version 4.2, with 18000 slices\n",
      "Philips Scaling Values RS:RI:SS = 0.79976:0:0.0999688 (see PMC3998685)\n",
      "Convert 1 DICOM as /Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5067/tmp_basename4051 (64x64x45x400)\n",
      "Compress: \"//Users/brac4g/bin/dcm2nii/bin/pigz_mricron\" -b 960 -n -f -6 \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-C10/tmp_dir5067/tmp_basename4051.nii\"\n",
      "Conversion required 2.423482 seconds (0.867346 for core code).\n",
      "Completed sub-C10\n"
     ]
    }
   ],
   "source": [
    "! ./convert_source.py -s \"{sub}\" -o \"{bids}\" -d \"{ddir}\" -c \"{conf}\" -f \"par\" -ses \"{ses}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C10\r\n"
     ]
    }
   ],
   "source": [
    "! echo \"{sub}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "import pydicom\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "import yaml\n",
    "import nibabel as nib\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import third party packages and modules\n",
    "import convert_source_dcm as cdm\n",
    "import convert_source_par as csp\n",
    "import convert_source_nii as csn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = \"/Users/brac4g/Desktop/convsauce/convert_source/config.default.yml\"\n",
    "# conf = \"C:/Users/smart/Desktop/GitProjects/convsauce/ConvertSource/config.default.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_file, verbose = False):\n",
    "    '''\n",
    "    Reads configuration file and creates a dictionary of search terms for \n",
    "    certain modalities provided that BIDS modalities are used as keys. If\n",
    "    exclusions are provided (via the key 'exclude') then an exclusion list is \n",
    "    created. Otherwise, 'exclusion_list' is returned as an empty list. If \n",
    "    additional settings are specified, they should be done so via the key\n",
    "    'metadata' to enable writing of additional metadata. Otherwise, an \n",
    "    empty dictionary is returned.\n",
    "    \n",
    "    Arguments:\n",
    "        config_file (string): file path to yaml configuration file.\n",
    "        verbose (boolean): Prints additional information to screen.\n",
    "    \n",
    "    Returns: \n",
    "        data_map (dict): Nested dictionary of search terms for BIDS modalities\n",
    "        exclusion_list (list): List of exclusion terms\n",
    "        meta_dict (dict): Nested dictionary of metadata terms to write to JSON file(s)\n",
    "    '''\n",
    "    \n",
    "    with open(config_file) as file:\n",
    "        data_map = yaml.safe_load(file)\n",
    "        if verbose:\n",
    "            print(\"Initialized parameters from configuration file\")\n",
    "        \n",
    "    if any(\"exclude\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"exclusion option implemented\")\n",
    "        exclusion_list = data_map[\"exclude\"]\n",
    "        del data_map[\"exclude\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"exclusion option not implemented\")\n",
    "        exclusion_list = list()\n",
    "        \n",
    "    if any(\"metadata\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"implementing additional settings for metadata\")\n",
    "        meta_dict = data_map[\"metadata\"]\n",
    "        del data_map[\"metadata\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"no metadata settings\")\n",
    "        meta_dict = dict()\n",
    "        \n",
    "    return data_map,exclusion_list,meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameters from configuration file\n",
      "exclusion option implemented\n",
      "implementing additional settings for metadata\n"
     ]
    }
   ],
   "source": [
    "search_dict, exclude_list, meta_dict = read_config(conf,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(data_dir, file_ext=\"\", order=\"size\"):\n",
    "    '''\n",
    "    Creates a file list by globbing a directory for a specific file\n",
    "    extension and sorting by some determined order. A file list is \n",
    "    then returned\n",
    "    \n",
    "    Arguments:\n",
    "        data_dir (string): Absolute path to data directory (must be a directory dump of image data)\n",
    "        file_ext (string): File extension to glob. Built-in options include:\n",
    "            - 'par' or 'PAR': Searches for PAR headers\n",
    "            - 'dcm' or 'DICOM': Searches for DICOM directories, then searches for one file from each DICOM directory\n",
    "            - 'nii', or 'Nifti': Searches for nifti files (including gzipped nifti files)\n",
    "        order (string): Order to sort the list. Valid options are: 'size' and 'time':\n",
    "            - 'size': sorts by file size in ascending order (default)\n",
    "            - 'time': sorts by file modification time in ascending order\n",
    "            - 'none': no sorting is applied and the list is generated as the system finds the files\n",
    "    \n",
    "    Returns: \n",
    "        file_list (list): List of filenames, complete with their absolute paths.\n",
    "    '''\n",
    "    \n",
    "    # Check file extension\n",
    "    if file_ext != \"\":\n",
    "        if file_ext.upper() == \"PAR\" or file_ext.upper() == \"REC\":\n",
    "            file_ext = \"PAR\"\n",
    "            file_ext = f\".{file_ext.upper()}\"\n",
    "        elif file_ext.lower() == \"dcm\" or file_ext.upper() == \"DICOM\":\n",
    "            file_ext = \"dcm\"\n",
    "            file_ext = f\".{file_ext.lower()}\"\n",
    "        elif file_ext.lower() == \"nii\" or file_ext.lower() == \"nifti\":\n",
    "            file_ext = \"nii\"\n",
    "            file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "        else:\n",
    "            file_ext = f\".{file_ext}\"\n",
    "    \n",
    "    # Check sort order\n",
    "    if order.lower() == \"size\":\n",
    "        order_key = os.path.getsize\n",
    "    elif order.lower() == \"time\":\n",
    "        order_key = os.path.getmtime\n",
    "    elif order.lower() == \"none\":\n",
    "        order_key=None\n",
    "    else:\n",
    "        order_key = os.path.getsize\n",
    "        print(\"Unrecognized keyword option. Using default.\")\n",
    "    \n",
    "    # Create file list\n",
    "    if file_ext == \".dcm\":\n",
    "        file_list = sorted(cdm.get_dcm_files(data_dir), key=order_key, reverse=False)\n",
    "    elif file_ext != \".dcm\":\n",
    "        file_names = os.path.join(data_dir, f\"*{file_ext}\")\n",
    "        file_list = sorted(glob.glob(file_names, recursive=True), key=order_key, reverse=False)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exclude(file_list, data_dir, exclusion_list = [], verbose = False):\n",
    "    '''\n",
    "    Excludes files from the conversion process by removing filenames\n",
    "    that contain words that match those found in the 'exclusion_list'\n",
    "    from the 'read_config' function - should any files need/want to be \n",
    "    excluded.\n",
    "    \n",
    "    If 'exclusion_list' is empty, then the original 'file_list' is returned.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames\n",
    "        data_dir (string): Absolute path to parent directory that contains the image data\n",
    "        exclusion_list (list): List of words to be matched. Filenames that contain these words will be excluded.\n",
    "        verbose (bool): Boolean - True or False.\n",
    "    \n",
    "    Returns: \n",
    "        currated_list (list): Currated list of filenames, with unwanted filenames removed.\n",
    "    '''\n",
    "            \n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file_list[0]:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'PAR' in file_list[0]:\n",
    "        file_ext = \"PAR\"\n",
    "        file_ext = f\".{file_ext.upper()}\"\n",
    "    elif 'nii' in file_list[0]:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    \n",
    "    # create set of lists\n",
    "    file_set = set(file_list)\n",
    "    \n",
    "    # create empty sets\n",
    "    currated_set = set()\n",
    "    exclusion_set = set()\n",
    "    \n",
    "    if len(exclusion_list) == 0:\n",
    "        currated_set = file_set\n",
    "    else:\n",
    "        for file in exclusion_list:\n",
    "            if file_ext == '.dcm':\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*\",f\"*{file_ext}\")\n",
    "            else:\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*{file_ext}\")\n",
    "            f_names = glob.glob(dir_, recursive=True)        \n",
    "            f_names_set = set(f_names)\n",
    "            if verbose:\n",
    "                if len(f_names_set) != 0:\n",
    "                    print(f\"Excluded files: {f_names_set} \\n\")\n",
    "            exclusion_set.update(f_names_set)\n",
    "            \n",
    "        currated_set = file_set.difference(exclusion_set)\n",
    "\n",
    "    currated_list = list(currated_set)\n",
    "    \n",
    "    return currated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_dir = \"/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003\"\n",
    "par_dir = \"/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC\"\n",
    "nii_dir = \"/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI\"\n",
    "\n",
    "# dcm_dir = \"C:/Users/smart/Desktop/GitProjects/convsauce/IRC287H-8/20171003\"\n",
    "# par_dir = \"C:/Users/smart/Desktop/GitProjects/convsauce/287H_C10/PAR REC\"\n",
    "# nii_dir = \"C:/Users/smart/Desktop/GitProjects/convsauce/287H_C10/NIFTI\"\n",
    "\n",
    "# dcm_dir = \"C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\IRC287H-8\\\\20171003\"\n",
    "# par_dir = \"C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\287H_C10\\\\PAR REC\"\n",
    "# nii_dir = \"C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\287H_C10\\\\NIFTI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_file_list = create_file_list(dcm_dir,'dcm')\n",
    "par_file_list = create_file_list(par_dir,'par')\n",
    "nii_file_list = create_file_list(nii_dir,'nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/1701_WM_SV_PRESS_35_017100311174543840/MR1701000001.dcm'} \n",
      "\n",
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310374358016/PR0000000001.dcm', '/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310463791022/PR0000000001.dcm'} \n",
      "\n",
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_1_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_16_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_2_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_13_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_17_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_14_1.PAR'} \n",
      "\n",
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_isoReg_-_WIP_DTI_6DIR_B800_12_6.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_faReg_-_WIP_DTI_6DIR_B800_12_4.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_Reg_-_WIP_DTI_6DIR_B800_12_2.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_dReg_-_WIP_DTI_6DIR_B800_12_3.PAR'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcm_list_currated = file_exclude(dcm_file_list,dcm_dir,exclude_list,verbose=True)\n",
    "par_list_currated = file_exclude(par_file_list,par_dir,exclude_list,verbose=True)\n",
    "nii_list_currated = file_exclude(nii_file_list,nii_dir,exclude_list,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dcm_list_currated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(par_list_currated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nii_list_currated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# utils.get_metadata(meta_dict,'func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_tech(bids_out_dir, sub, file, search_dict, meta_dict=dict(), ses=1, keep_unknown=True, verbose=False):\n",
    "    '''\n",
    "    Searches DICOM or PAR file header for scan technique/MR modality used in accordance with the search terms provided\n",
    "    by the nested dictionary.\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Output BIDS directory\n",
    "        sub (int or string): Subject ID\n",
    "        file (string): Source image filename with absolute filepath\n",
    "        search_dict (dict): Nested dictionary from the 'read_config' function\n",
    "        meta_dict (dict): Nested metadata dictionary\n",
    "        ses (int or string): Session ID\n",
    "        keep_unknown (bool): Convert modalities/scans which cannot be identified (default: True)\n",
    "        verbose (bool): Prints the scan_type, modality, and search terms used (e.g. func - bold - rest - ['rest', 'FFE'])\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    if not meta_dict:\n",
    "        meta_dict = dict()\n",
    "\n",
    "    converted_files = list()\n",
    "    \n",
    "    # Check file extension in file\n",
    "    # Perform Scanning Techniqe Search\n",
    "    if '.dcm' in file.lower():\n",
    "        converted_files = cdm.get_dcm_scan_tech(bids_out_dir=bids_out_dir, sub=sub, dcm_file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=keep_unknown, verbose=verbose)\n",
    "    elif '.PAR' in file.upper():\n",
    "        converted_files = csp.get_par_scan_tech(bids_out_dir=bids_out_dir, sub=sub, par_file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=keep_unknown, verbose=verbose)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"unknown modality\")\n",
    "        if keep_unknown:\n",
    "            if verbose:\n",
    "                print(\"converting unknown_modality\")\n",
    "            scan_type = 'unknown_modality'\n",
    "            scan = 'unknown'\n",
    "            [com_param_dict, scan_param_dict] = utils.get_metadata(dictionary=meta_dict,scan_type=scan_type)\n",
    "            converted_files = csn.data_to_bids_anat(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_anat=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "        \n",
    "    return converted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_modality(bids_out_dir, sub, file, search_dict, meta_dict=dict(), ses=1, keep_unknown=True, verbose=False):\n",
    "    '''\n",
    "    Converts an image file and extracts information from the filename (such as the modality). \n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    Note: Add support for extra dictionaries\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Output BIDS directory\n",
    "        sub (int or string): Subject ID\n",
    "        file (string): Source image filename with absolute filepath\n",
    "        search_dict (dict): Nested dictionary from the 'read_config' function\n",
    "        meta_dict (dict): Nested metadata dictionary\n",
    "        ses (int or string): Session ID\n",
    "        keep_unknown (bool): Convert modalities/scans which cannot be identified (default: True)\n",
    "        verbose (bool): Prints the scan_type, modality, and search terms used (e.g. func - bold - rest - ['rest', 'FFE'])\n",
    "    \n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "\n",
    "    converted_files = list()\n",
    "    \n",
    "    # Check file type\n",
    "    if 'nii' in file:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'dcm' in file:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "        if not cdm.is_valid_dcm(file,verbose):\n",
    "            sys.exit(f\"Invalid DICOM file. Please check {file}\")\n",
    "    \n",
    "    for key,item in search_dict.items():\n",
    "        for dict_key,dict_item in search_dict[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if utils.list_in_substr(dict_item,file):\n",
    "                    mod_found = True\n",
    "                    if verbose:\n",
    "                        print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    scan_type = key\n",
    "                    scan = dict_key\n",
    "                    [com_param_dict, scan_param_dict] = utils.get_metadata(dictionary=meta_dict,scan_type=scan_type)\n",
    "                    if scan_type.lower() == 'dwi':\n",
    "                        converted_files = csn.data_to_bids_dwi(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_dwi=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                    elif scan_type.lower() == 'fmap':\n",
    "                        converted_files = csn.data_to_bids_fmap(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_fmap=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                    else:\n",
    "                        converted_files = csn.data_to_bids_anat(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_anat=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = search_dict[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if utils.list_in_substr(d_item,file):\n",
    "                        mod_found = True\n",
    "                        if verbose:\n",
    "                            print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        scan_type = key\n",
    "                        scan = dict_key\n",
    "                        task = d_key\n",
    "                        [com_param_dict, scan_param_dict] = utils.get_metadata(dictionary=meta_dict,scan_type=scan_type,task=task)\n",
    "                        if scan_type.lower() == 'func':\n",
    "                            converted_files = csn.data_to_bids_func(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,task=task,meta_dict_com=com_param_dict,meta_dict_func=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        elif scan_type.lower() == 'dwi':\n",
    "                            converted_files = csn.data_to_bids_dwi(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_dwi=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        elif scan_type.lower() == 'fmap':\n",
    "                            converted_files = csn.data_to_bids_fmap(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_fmap=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        else:\n",
    "                            converted_files = csn.data_to_bids_anat(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_anat=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                        \n",
    "    if not mod_found:\n",
    "        converted_files = get_scan_tech(bids_out_dir, sub, file, search_dict, meta_dict=\"\", ses=1, keep_unknown=keep_unknown, verbose=verbose)\n",
    "    \n",
    "    return converted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert(bids_out_dir,sub,file_list, search_dict, meta_dict=dict(), ses=1, keep_unknown=True,verbose=False):\n",
    "    '''\n",
    "    Batch conversion function for image files.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "\n",
    "    Arguments:\n",
    "        bids_out_dir (string): Output BIDS directory\n",
    "        sub (int or string): Subject ID\n",
    "        file (string): Source image filename with absolute filepath\n",
    "        search_dict (dict): Nested dictionary from the 'read_config' function\n",
    "        meta_dict (dict): Nested metadata dictionary\n",
    "        ses (int or string): Session ID\n",
    "        keep_unknown (bool): Convert modalities/scans which cannot be identified (default: True)\n",
    "        verbose (bool): Prints the scan_type, modality, and search terms used (e.g. func - bold - rest - ['rest', 'FFE'])\n",
    "\n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "\n",
    "    converted_files = list()\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            converted_files = convert_modality(bids_out_dir=bids_out_dir, sub=sub, file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=True, verbose=False)\n",
    "        except (SystemExit,FileNotFoundError):\n",
    "            pass\n",
    "    \n",
    "    return converted_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids_dir = \"C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\"\n",
    "bids_dir = \"/Users/brac4g/Desktop/convsauce/BIDS.new\"\n",
    "# sub = 'P08'\n",
    "sub = 'C10'\n",
    "ses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_6_DIR_B0_A_TE88_6DYN_20_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_CORONAL__3_2.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_T2W_TSE_AXIAL_NEONATE_NSA1_15_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SWIp_11_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_SAG_15_5.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_Philips_GRE_Map_SENSE_10_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SAG_T1W_3D_Y_INNER_TI_1100_3_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_AXIAL__4_4.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_SAG_4_5.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_DTI_B2000_A68_FAT_SHIFT_P_MB2_SENSE_2_TE88_21_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_DTI_6DIR_B800_12_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_CORONAL__4_3.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_rsfMRI_NR1_MB3_SENSE_1_fat_shift_P_8_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_6_DIR_B0_A_TE88_SENSE_NO_MB_NO_4DYN_5_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_rsfMRI_NR1_MB3_SENSE_1_fat_shift_A_7_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_AXIAL__15_4.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_36DIR_DTI_B800__P_SENSE_NO__MB_MAX_GRAD_6_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_rsfMRI_400M_MB3_SENSE_1_fat_shift_P_9_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_T2W_TSE_AXIAL_NEONATE_NSA1_4_1.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_CORONAL__15_3.PAR',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_AXIAL__3_3.PAR']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/1101_rsfMRI_MB6_SENSE_1_fat_shift_P_017100310465322437/MR1101027463.dcm',\n",
       " '/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/303_CORONAL_2017100310262626000/MR0303000091.dcm',\n",
       " '/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/201_SAG_T1W_3D_Y_INNER_TI_1100_017100310184810020/MR0201000137.dcm']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcm_list_currated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_AXIAL__15_4.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_CORONAL__4_3.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_WIP_T2W_TSE_AXIAL_NEONATE_NSA1_4_1.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_SAG_15_5.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_CORONAL__15_3.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_AXIAL__4_4.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_CORONAL__3_2.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_WIP_SAG_T1W_3D_Y_INNER_TI_1100_3_1.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_WIP_Philips_GRE_Map_SENSE_10_1.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_AXIAL__3_3.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_SAG_4_5.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI/287H_C10_WIP_T2W_TSE_AXIAL_NEONATE_NSA1_15_1.nii.gz']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii_list_currated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAR REC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DWI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-band reference (`sbref`, or reverse phase encoded (rPE) B$_{0}$) \n",
    "--               \n",
    "Grade: Passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_6_DIR_B0_A_TE88_SENSE_NO_MB_NO_4DYN_5_1.PAR'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csn.data_to_bids_dwi(bids_out_dir=bids_dir,\n",
    "#                  sub=sub,\n",
    "#                  file=par_list_currated[0],\n",
    "#                  ses=ses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwi - dwi: ['diffusion', 'DTI', 'DWI', '6_DIR']\n"
     ]
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[7],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DWI Data\n",
    "--               \n",
    "Grade: Passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_DTI_B2000_A68_FAT_SHIFT_P_MB2_SENSE_2_TE88_21_1.PAR'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwi - dwi: ['diffusion', 'DTI', 'DWI', '6_DIR']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/dwi/sub-P08_ses-001_acq-b2000TE88_dir-PA_run-01_dwi.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/dwi/sub-P08_ses-001_acq-b2000TE88_dir-PA_run-01_dwi.json',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/dwi/sub-P08_ses-001_acq-b2000TE88_dir-PA_run-01_dwi.bval',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/dwi/sub-P08_ses-001_acq-b2000TE88_dir-PA_run-01_dwi.bvec')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[3],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional MR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-band reference (`sbref`) \n",
    "--               \n",
    "Grade: Passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_rsfMRI_NR1_MB3_SENSE_1_fat_shift_P_8_1.PAR'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func - bold - rest: ['rsfMR', 'rest', 'FFE', 'FEEPI']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/func/sub-P08_ses-001_task-rest_dir-PA_run-01_sbref.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/func/sub-P08_ses-001_task-rest_dir-PA_run-01_sbref.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[12],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EPI (`bold`) \n",
    "--               \n",
    "Grade: Passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_rsfMRI_400M_MB3_SENSE_1_fat_shift_P_9_1.PAR'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func - bold - rest: ['rsfMR', 'rest', 'FFE', 'FEEPI']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/func/sub-P08_ses-001_task-rest_dir-PA_run-01_bold.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/func/sub-P08_ses-001_task-rest_dir-PA_run-01_bold.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[-1],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fieldmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fieldmap (`fmap`) \n",
    "--               \n",
    "Grade: Passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_Philips_GRE_Map_SENSE_10_1.PAR'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmap - fmap: ['map']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/fmap/sub-P08_ses-001_run-01_fmap_fieldmap.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/fmap/sub-P08_ses-001_run-01_fmap_magnitude.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/fmap/sub-P08_ses-001_run-01_fmap_fieldmap.json',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/fmap/sub-P08_ses-001_run-01_fmap_magnitude.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[14],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomical Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWI (`swi`) \n",
    "--               \n",
    "Grade: Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SWIp_11_1.PAR'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swi - swi: ['swi']\n",
      "Error: unable to convert /Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SWIp_11_1.PAR\n"
     ]
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[8],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.convert_image_data(par_list_currated[-6],'test','/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/swi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvals = list()\n",
    "bvals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert_modality(bids_out_dir=bids_dir,\n",
    "#                  sub=sub,\n",
    "#                  file=par_list_currated[0],\n",
    "#                  search_dict=search_dict,\n",
    "#                  meta_dict=meta_dict,\n",
    "#                  ses=ses,\n",
    "#                  keep_unknown=True,\n",
    "#                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anat - T2w: ['T2', 'T2w', 'TSE']\n"
     ]
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=par_list_currated[2],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anat - T1w: ['T1', 'T1w', 'TFE']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\\\\sub-P08\\\\ses-001\\\\anat\\\\sub-P08_ses-P08_run-02_T1w.nii.gz',\n",
       " 'C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\\\\sub-P08\\\\ses-001\\\\anat\\\\sub-P08_ses-P08_run-02_T1w.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=dcm_list_currated[0],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown modality\n",
      "converting unknown_modality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\\\\sub-P08\\\\ses-001\\\\unknown_modality\\\\sub-P08_ses-P08_run-01_unknown.nii.gz',\n",
       " 'C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\\\\sub-P08\\\\ses-001\\\\unknown_modality\\\\sub-P08_ses-P08_run-01_unknown.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_modality(bids_out_dir=bids_dir,\n",
    "                 sub=sub,\n",
    "                 file=nii_list_currated[0],\n",
    "                 search_dict=search_dict,\n",
    "                 meta_dict=meta_dict,\n",
    "                 ses=ses,\n",
    "                 keep_unknown=True,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\\\\test.nii.gz',\n",
       " 'C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\BIDS.new\\\\test.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.convert_anat(par_list_currated[0],bids_dir,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.convert_image_data(par_list_currated[0],'test',bids_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\smart\\\\Desktop\\\\GitProjects\\\\convsauce\\\\287H_C10\\\\PAR REC\\\\287H_C10_SAG_15_5.PAR'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list_currated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Convert Test (PAR REC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unable to convert /Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_SWIp_11_1.PAR\n"
     ]
    }
   ],
   "source": [
    "batch_convert(bids_out_dir=bids_dir,\n",
    "              sub='C10',\n",
    "              file_list=par_list_currated,\n",
    "              search_dict=search_dict,\n",
    "              meta_dict=meta_dict,\n",
    "              ses=ses,\n",
    "              keep_unknown=True,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Convert Test (DICOM, Philips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unable to convert /Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/1101_rsfMRI_MB6_SENSE_1_fat_shift_P_017100310465322437/MR1101027463.dcm\n"
     ]
    }
   ],
   "source": [
    "batch_convert(bids_out_dir=bids_dir,\n",
    "              sub='P08',\n",
    "              file_list=dcm_list_currated,\n",
    "              search_dict=search_dict,\n",
    "              meta_dict=meta_dict,\n",
    "              ses=ses,\n",
    "              keep_unknown=True,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Convert Test (NifTi-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/brac4g/Desktop/convsauce/BIDS.new/sub-T10/ses-001/anat/sub-T10_ses-T10_run-02_T2w.nii.gz',\n",
       " '/Users/brac4g/Desktop/convsauce/BIDS.new/sub-T10/ses-001/anat/sub-T10_ses-T10_run-02_T2w.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_convert(bids_out_dir=bids_dir,\n",
    "              sub='T10',\n",
    "              file_list=nii_list_currated,\n",
    "              search_dict=search_dict,\n",
    "              meta_dict=meta_dict,\n",
    "              ses=ses,\n",
    "              keep_unknown=True,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(num):\n",
    "    '''\n",
    "    test function\n",
    "    '''\n",
    "    \n",
    "    test_list = []\n",
    "    \n",
    "    if num == 1:\n",
    "        j = [\"1\"]\n",
    "        test_list = j\n",
    "    elif num == 2:\n",
    "        j = [\"2\",\"1\"]\n",
    "        test_list = j\n",
    "        \n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "jt = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jt = test(2)\n",
    "jt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bids_dwi(bids_out_dir, file, sub, scan='dwi', meta_dict_com=dict(), meta_dict_dwi=dict(), ses=1, scan_type='dwi'):\n",
    "    '''\n",
    "    Renames converted NifTi-2 files to conform with the BIDS naming convension (in the case of diffuion image files).\n",
    "    This function accepts any image file (DICOM, PAR REC, and NifTi-2). If the image file is a raw data file (e.g. DICOM, PAR REC)\n",
    "    it is converted to NifTi first, then renamed. The output BIDS directory need not exist at runtime. If the original\n",
    "    data format is NifTi, bval and bvec files will be copied over should they exist, otherwise, they will not be\n",
    "    generated.\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Path to output BIDS directory. \n",
    "        file (string): Filepath to image file.\n",
    "        sub (int or string): Subject ID\n",
    "        scan (string): Modality (e.g. dwi, dki, etc)\n",
    "        meta_dict_com (dict): Metadata dictionary for common image metadata\n",
    "        meta_dict_dwi (dict): Metadata dictionary for common diffusion image specific metadata\n",
    "        ses (int or string): Session ID\n",
    "        scan_type (string): BIDS sub-directory scan type. Valid options include, but are not limited to: anat, func, fmap, dwi (default), etc.\n",
    "        \n",
    "    Returns:\n",
    "        out_nii (string): Absolute filepath to gzipped output diffusion weighted NifTi-2 file\n",
    "        out_json (string): Absolute filepath to corresponding JSON file\n",
    "        out_bval (string): Absolute filepath to corresponding b-values file\n",
    "        out_bvec (string): Absolute filepath to corresponding b-vectors file\n",
    "    '''\n",
    "\n",
    "    # Create Output Directory Variables\n",
    "    # Zeropad subject ID if possible\n",
    "    try:\n",
    "        ses = '{:03}'.format(int(ses))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # Zeropad session ID if possible\n",
    "    try:\n",
    "        ses = '{:03}'.format(int(ses))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "    # Make output directory\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    # Get absolute filepaths\n",
    "    bids_out_dir = os.path.abspath(bids_out_dir)\n",
    "    out_dir = os.path.abspath(out_dir)\n",
    "    \n",
    "    # Create temporary output names/directories\n",
    "    n = 10000 # maximum N for random number generator\n",
    "    tmp_out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", 'tmp_dir' + str(random.randint(0, n)))\n",
    "    tmp_basename = 'tmp_basename' + str(random.randint(0, n))\n",
    "    \n",
    "    if not os.path.exists(tmp_out_dir):\n",
    "        os.makedirs(tmp_out_dir)\n",
    "\n",
    "    # Convert image file\n",
    "    # Check file extension in file\n",
    "    if '.nii.gz' in file:\n",
    "        nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "        [path,filename,ext] = utils.file_parts(file)\n",
    "        json_file = os.path.join(path,filename + '.json')\n",
    "        bval = os.path.join(path,filename + '.bval*')\n",
    "        bvec = os.path.join(path,filename + '.bvec*')\n",
    "        try:\n",
    "            json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            bval = utils.cp_file(bval, tmp_out_dir, tmp_basename)\n",
    "            bvec = utils.cp_file(bvec, tmp_out_dir, tmp_basename)\n",
    "        except FileNotFoundError:\n",
    "            json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "            bval = os.path.join(tmp_out_dir, tmp_basename + '.bval')\n",
    "            bvec = os.path.join(tmp_out_dir, tmp_basename + '.bvec')\n",
    "            pass\n",
    "    elif '.nii' in file:\n",
    "        nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "        nii_file = utils.gzip_file(nii_file)\n",
    "        [path,filename,ext] = utils.file_parts(file)\n",
    "        json_file = os.path.join(path,filename + '.json')\n",
    "        bval = os.path.join(path,filename + '.bval*')\n",
    "        bvec = os.path.join(path,filename + '.bvec*')\n",
    "        try:\n",
    "            json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            bval = utils.cp_file(bval, tmp_out_dir, tmp_basename)\n",
    "            bvec = utils.cp_file(bvec, tmp_out_dir, tmp_basename)\n",
    "        except FileNotFoundError:\n",
    "            json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "            bval = os.path.join(tmp_out_dir, tmp_basename + '.bval')\n",
    "            bvec = os.path.join(tmp_out_dir, tmp_basename + '.bvec')\n",
    "            pass\n",
    "    elif '.dcm' in file or '.PAR' in file:\n",
    "        [nii_file, json_file, bval, bvec] = utils.convert_dwi(file,tmp_out_dir,tmp_basename)\n",
    "        # Decide if file is DWI or single-band reference\n",
    "        num_frames = get_num_frames(nii_file)\n",
    "        if num_frames == 1:\n",
    "            scan = 'sbref'\n",
    "            bval = \"\"\n",
    "            bvec = \"\"\n",
    "    else:\n",
    "        [nii_file, json_file, bval, bvec] = utils.convert_dwi(file,tmp_out_dir,tmp_basename)\n",
    "        # Decide if file is DWI or single-band reference\n",
    "        num_frames = get_num_frames(nii_file)\n",
    "        if num_frames == 1:\n",
    "            scan = 'sbref'\n",
    "            bval = \"\"\n",
    "            bvec = \"\"\n",
    "    \n",
    "    # Get additional sequence/modality parameters\n",
    "    if os.path.exists(json_file) and os.path.exists(bval):\n",
    "        meta_dict_params = get_data_params(file, json_file, bval)\n",
    "    elif os.path.exists(bval):\n",
    "        tmp_json = \"\"\n",
    "        meta_dict_params = get_data_params(file, tmp_json, bval)\n",
    "    elif os.path.exists(json_file):\n",
    "        tmp_bval = \"\"\n",
    "        meta_dict_params = get_data_params(file, json_file, tmp_bval)\n",
    "    else:\n",
    "        tmp_json = \"\"\n",
    "        tmp_bval = \"\"\n",
    "        meta_dict_params = get_data_params(file, tmp_json, tmp_bval)\n",
    "    \n",
    "    # Update JSON file\n",
    "    info = dict()\n",
    "    info = utils.dict_multi_update(info,**meta_dict_params)\n",
    "    info = utils.dict_multi_update(info,**meta_dict_com)\n",
    "    info = utils.dict_multi_update(info,**meta_dict_dwi)\n",
    "    \n",
    "    json_file = utils.update_json(json_file,info)\n",
    "    \n",
    "    nii_file = os.path.abspath(nii_file)\n",
    "    json_file = os.path.abspath(json_file)\n",
    "    \n",
    "    if bval and bvec:\n",
    "        bval = os.path.abspath(bval)\n",
    "        bvec = os.path.abspath(bvec)\n",
    "\n",
    "    # Query dictionary for acquisition/naming keys\n",
    "    try:\n",
    "        acq = info['acq']\n",
    "    except KeyError:\n",
    "        acq = \"\"\n",
    "        pass\n",
    "    try:\n",
    "        direction = info['dir']\n",
    "    except KeyError:\n",
    "        direction = \"\"\n",
    "        pass\n",
    "    \n",
    "    # Non-standard acquisition/naming keys\n",
    "    # Used in order to differentiate between DWI scans for multiple bvalues\n",
    "    try:\n",
    "        bvals = info['bval']\n",
    "    except KeyError:\n",
    "        bvals = list()\n",
    "        if scan == 'sbref':\n",
    "            bvals = 0\n",
    "        pass\n",
    "    try:\n",
    "        echo_time = info['EchoTime']\n",
    "    except KeyError:\n",
    "        echo_time = \"\"\n",
    "        pass\n",
    "    \n",
    "    # Create output filename    \n",
    "    out_name = f\"sub-{sub}\" + f\"_ses-{ses}\"\n",
    "    name_run_dict = dict()\n",
    "    \n",
    "    if bvals:\n",
    "        vals = \"\"\n",
    "        for val in bvals:\n",
    "            vals = vals + 'b' + str(int(val))\n",
    "    elif bvals == 0:\n",
    "        vals = 'b0'\n",
    "    \n",
    "    if bvals and acq and echo_time:\n",
    "        out_name = out_name + f\"_acq-{acq}{vals}TE{echo_time}\"\n",
    "        tmp_dict = {\"acq\":f\"{acq}{vals}TE{echo_time}\"}\n",
    "    elif bvals and acq:\n",
    "        out_name = out_name + f\"_acq-{acq}{vals}\"\n",
    "        tmp_dict = {\"acq\":f\"{acq}{vals}\"}\n",
    "    elif bvals and echo_time:\n",
    "        out_name = out_name + f\"_acq-{vals}TE{echo_time}\"\n",
    "        tmp_dict = {\"acq\":f\"{vals}TE{echo_time}\"}\n",
    "    elif acq and echo_time:\n",
    "        out_name = out_name + f\"_acq-{acq}TE{echo_time}\"\n",
    "        tmp_dict = {\"acq\":f\"{acq}TE{echo_time}\"}\n",
    "    elif acq:\n",
    "        out_name = out_name + f\"_acq-{acq}\"\n",
    "        tmp_dict = {\"acq\":f\"{acq}\"}\n",
    "    elif bvals:\n",
    "        out_name = out_name + f\"_acq-{vals}\"\n",
    "        tmp_dict = {\"acq\":f\"{vals}\"}\n",
    "    elif echo_time:\n",
    "        out_name = out_name + f\"_acq-TE{echo_time}\"\n",
    "        tmp_dict = {\"acq\":f\"TE{echo_time}\"}\n",
    "    else:\n",
    "        tmp_dict = dict()\n",
    "        \n",
    "    name_run_dict.update(tmp_dict)\n",
    "\n",
    "    if direction:\n",
    "        out_name = out_name + f\"_dir-{direction}\"\n",
    "        tmp_dict = {\"dirs\":f\"{direction}\"}\n",
    "        name_run_dict.update(tmp_dict)\n",
    "        \n",
    "    # Get Run number\n",
    "    run = utils.get_num_runs(out_dir, scan=scan, **name_run_dict)\n",
    "    run = '{:02}'.format(run)\n",
    "\n",
    "    if run:\n",
    "        out_name = out_name + f\"_run-{run}\"\n",
    "\n",
    "    out_name = out_name + f\"_{scan}\"\n",
    "\n",
    "    out_nii = os.path.join(out_dir, out_name + '.nii.gz')\n",
    "    out_json = os.path.join(out_dir, out_name + '.json')\n",
    "    \n",
    "    out_bval = os.path.join(out_dir, out_name + '.bval')\n",
    "    out_bvec = os.path.join(out_dir, out_name + '.bvec')\n",
    "\n",
    "    os.rename(nii_file, out_nii)\n",
    "    os.rename(json_file, out_json)\n",
    "    \n",
    "    if bval:\n",
    "        os.rename(bval,out_bval)\n",
    "        \n",
    "    if bvec:\n",
    "        os.rename(bvec,out_bvec)\n",
    "\n",
    "    # remove temporary directory and leftover files\n",
    "    shutil.rmtree(tmp_out_dir)\n",
    "    \n",
    "    if bval and bvec:\n",
    "        return out_nii,out_json,out_bval,out_bvec\n",
    "    elif not bval and bvec:\n",
    "        return out_nii,out_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dict()\n",
    "scan = 'sbref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bvals = info['bval']\n",
    "except KeyError:\n",
    "    bvals = list()\n",
    "    if scan == 'sbref':\n",
    "        bvals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sbref'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bvals:\n",
    "    vals = \"\"\n",
    "    for val in bvals:\n",
    "        vals = vals + 'b' + str(int(val))\n",
    "elif bvals == 0:\n",
    "    vals = 'b0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0\n"
     ]
    }
   ],
   "source": [
    "if vals:\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if bvals == 0:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvals = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bvals:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvals = 0; scan = 'sbref'; i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo = 0.088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echo = int(echo * 1000)\n",
    "echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/dwi/sub-P08_ses-001_acq-b0_dir-PA_run-01_dwi.json\"\n",
    "j2 = \"/Users/brac4g/Desktop/convsauce/BIDS.new/sub-P08/ses-001/dwi/sub-P08_ses-001_acq-b0_dir-PA_run-01_dwi2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file):\n",
    "    '''\n",
    "    Reads JavaScript Object Notation (JSON) file.\n",
    "    \n",
    "    Arguments:\n",
    "        json_file (string): Input file\n",
    "        \n",
    "    Returns: \n",
    "        data (dict): Dictionary of key mapped items in JSON file\n",
    "    '''\n",
    "    \n",
    "    # Read JSON file\n",
    "    # Try-Except statement has empty exception as JSONDecodeError is not a valid exception to pass, \n",
    "    # thus throwing a name error\n",
    "    try:\n",
    "        with open(json_file) as file:\n",
    "            data = json.load(file)\n",
    "    except:\n",
    "        data = dict()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Manufacturer': 'Philips',\n",
       " 'PatientPosition': 'HFS',\n",
       " 'SeriesDescription': 'ImageMRSERIES',\n",
       " 'ProtocolName': 'WIP6DIRB0A',\n",
       " 'SeriesNumber': 5,\n",
       " 'AcquisitionNumber': 5,\n",
       " 'ImageComments': 'IRC287H',\n",
       " 'ConversionComments': 'y',\n",
       " 'PhilipsRescaleSlope': 2.01465,\n",
       " 'PhilipsRescaleIntercept': 0,\n",
       " 'PhilipsScaleSlope': 0.028553,\n",
       " 'UsePhilipsFloatNotDisplayScaling': 1,\n",
       " 'EchoTime': 0.088,\n",
       " 'RepetitionTime': 15.94,\n",
       " 'ReconMatrixPE': 80,\n",
       " 'ImageOrientationPatientDICOM': [0.982342,\n",
       "  0.0955086,\n",
       "  0.160883,\n",
       "  -0.0999558,\n",
       "  0.994796,\n",
       "  0.0197614],\n",
       " 'ConversionSoftware': 'dcm2niix',\n",
       " 'ConversionSoftwareVersion': 'v1.0.20190720  (JP2:OpenJPEG) (JP-LS:CharLS) Clang8.1.0',\n",
       " 'WaterFatShift': 22.516,\n",
       " 'ParallelAcquisitionTechnique': 'SENSE',\n",
       " 'ParallelReductionFactorInPlane': 1.0,\n",
       " 'MultibandAccelerationFactor': 1,\n",
       " 'EffectiveEchoSpacing': 0.6481812005573276,\n",
       " 'TotalReadoutTime': 0.051206314844028884,\n",
       " 'AcquisitionDuration': 97.8,\n",
       " 'EchoTrainLength': 79,\n",
       " 'SourceDataFormat': 'PAR REC',\n",
       " 'ManufacturersModelName': 'Ingenia',\n",
       " 'MagneticFieldStrength': 3,\n",
       " 'InstitutionName': \"Cincinnati Children's Hospital Medical Center\",\n",
       " 'PhaseEncodingDirection': 'j',\n",
       " 'dir': 'PA'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_json(j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bids_anat(bids_out_dir, file, sub, scan, meta_dict_com=dict(), meta_dict_anat=dict(), ses=1, scan_type='anat'):\n",
    "    '''\n",
    "    Renames converted NifTi-2 files to conform with the BIDS naming convension (in the case of anatomical files).\n",
    "    This function accepts any image file (DICOM, PAR REC, and NifTi-2). If the image file is a raw data file (e.g. DICOM, PAR REC)\n",
    "    it is converted to NifTi first, then renamed. The output BIDS directory need not exist at runtime.\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Path to output BIDS directory. \n",
    "        file (string): Filepath to image file.\n",
    "        sub (int or string): Subject ID\n",
    "        scan (string): Modality (e.g. T1w, T2w, or SWI)\n",
    "        meta_dict_com (dict): Metadata dictionary for common image metadata\n",
    "        meta_dict_anat (dict): Metadata dictionary for common anatomical image specific metadata\n",
    "        ses (int or string): Session ID\n",
    "        scan_type (string): BIDS sub-directory scan type. Valid options include, but are not limited to: anat (default), func, fmap, dwi, etc.\n",
    "        \n",
    "    Returns:\n",
    "        out_nii (string): Absolute filepath to gzipped output NifTi-2 file\n",
    "        out_json (string): Absolute filepath to corresponding JSON file\n",
    "    '''\n",
    "\n",
    "    # Use try-except statement here in the case of invalid/incomplete image files that will throw errors in dcm2niix\n",
    "    try:\n",
    "        # Create Output Directory Variables\n",
    "        # Zeropad subject ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # Zeropad session ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "        # Make output directory\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "\n",
    "        # Get absolute filepaths\n",
    "        bids_out_dir = os.path.abspath(bids_out_dir)\n",
    "        out_dir = os.path.abspath(out_dir)\n",
    "\n",
    "        # Create temporary output names/directories\n",
    "        n = 10000 # maximum N for random number generator\n",
    "        tmp_out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", 'tmp_dir' + str(random.randint(0, n)))\n",
    "        tmp_basename = 'tmp_basename' + str(random.randint(0, n))\n",
    "\n",
    "        if not os.path.exists(tmp_out_dir):\n",
    "            os.makedirs(tmp_out_dir)\n",
    "\n",
    "        # Convert image file\n",
    "        # Check file extension in file\n",
    "        if '.nii.gz' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                pass\n",
    "        elif '.nii' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            nii_file = utils.gzip_file(nii_file)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                pass\n",
    "        elif '.dcm' in file or '.PAR' in file:\n",
    "            [nii_file, json_file] = utils.convert_anat(file,tmp_out_dir,tmp_basename)\n",
    "        else:\n",
    "            [nii_file, json_file] = utils.convert_anat(file,tmp_out_dir,tmp_basename)\n",
    "\n",
    "        # Get additional sequence/modality parameters\n",
    "        if os.path.exists(json_file):\n",
    "            meta_dict_params = get_data_params(file, json_file)\n",
    "        else:\n",
    "            tmp_json = \"\"\n",
    "            meta_dict_params = get_data_params(file, tmp_json)\n",
    "\n",
    "        # Update JSON file\n",
    "        info = dict()\n",
    "        info = utils.dict_multi_update(info,**meta_dict_params)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_com)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_anat)\n",
    "\n",
    "        json_file = utils.update_json(json_file,info)\n",
    "\n",
    "        nii_file = os.path.abspath(nii_file)\n",
    "        json_file = os.path.abspath(json_file)\n",
    "\n",
    "        info = dict()\n",
    "        info = utils.read_json(json_file)\n",
    "\n",
    "        # Append w to T1/T2 if not already done\n",
    "        if scan in 'T1' or scan in 'T2':\n",
    "            scan = scan + 'w'\n",
    "\n",
    "        # Query dictionary for acquisition/naming keys\n",
    "        try:\n",
    "            acq = info['acq']\n",
    "        except KeyError:\n",
    "            acq = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            ce = info['ce']\n",
    "        except KeyError:\n",
    "            ce = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            rec = info['rec']\n",
    "        except KeyError:\n",
    "            rec = \"\"\n",
    "            pass\n",
    "\n",
    "        # Create output filename\n",
    "        out_name = f\"sub-{sub}\" + f\"_ses-{sub}\"\n",
    "        name_run_dict = dict()\n",
    "\n",
    "        if acq:\n",
    "            out_name = out_name + f\"_acq-{acq}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if ce:\n",
    "            out_name = out_name + f\"_ce-{ce}\"\n",
    "            tmp_dict = {\"ce\":f\"{ce}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if rec:\n",
    "            out_name = out_name + f\"_rec-{rec}\"\n",
    "            tmp_dict = {\"rec\":f\"{rec}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        # Get Run number\n",
    "        run = utils.get_num_runs(out_dir, scan=scan, **name_run_dict)\n",
    "        run = '{:02}'.format(run)\n",
    "\n",
    "        if run:\n",
    "            out_name = out_name + f\"_run-{run}\"\n",
    "\n",
    "        out_name = out_name + f\"_{scan}\"\n",
    "\n",
    "\n",
    "        out_nii = os.path.join(out_dir, out_name + '.nii.gz')\n",
    "        out_json = os.path.join(out_dir, out_name + '.json')\n",
    "\n",
    "        os.rename(nii_file, out_nii)\n",
    "        os.rename(json_file, out_json)\n",
    "\n",
    "        # remove temporary directory and leftover files\n",
    "        shutil.rmtree(tmp_out_dir)\n",
    "\n",
    "        return out_nii,out_json\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: unable to convert {file}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bids_func(bids_out_dir, file, sub, scan, task = 'rest', meta_dict_com=dict(), meta_dict_func=dict(), ses=1, scan_type='func'):\n",
    "    '''\n",
    "    Renames converted NifTi-2 files to conform with the BIDS naming convension (in the case of functional files).\n",
    "    This function accepts any image file (DICOM, PAR REC, and NifTi-2). If the image file is a raw data file (e.g. DICOM, PAR REC)\n",
    "    it is converted to NifTi first, then renamed. The output BIDS directory need not exist at runtime.\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Path to output BIDS directory. \n",
    "        file (string): Filepath to image file.\n",
    "        sub (int or string): Subject ID\n",
    "        scan (string): Modality (e.g. bold or cbv)\n",
    "        task (string): Task for the fMR image data\n",
    "        meta_dict_com (dict): Metadata dictionary for common image metadata\n",
    "        meta_dict_func (dict): Metadata dictionary for common functional image specific metadata\n",
    "        ses (int or string): Session ID\n",
    "        scan_type (string): BIDS sub-directory scan type. Valid options include, but are not limited to: anat, func (default), fmap, dwi, etc.\n",
    "        \n",
    "    Returns:\n",
    "        out_nii (string): Absolute filepath to gzipped output 4D NifTi-2 file\n",
    "        out_json (string): Absolute filepath to corresponding JSON file\n",
    "    '''\n",
    "\n",
    "    # Use try-except statement here in the case of invalid/incomplete image files that will throw errors in dcm2niix\n",
    "    try:\n",
    "        # Create Output Directory Variables\n",
    "        # Zeropad subject ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # Zeropad session ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "        # Make output directory\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "\n",
    "        # Get absolute filepaths\n",
    "        bids_out_dir = os.path.abspath(bids_out_dir)\n",
    "        out_dir = os.path.abspath(out_dir)\n",
    "\n",
    "        # Create temporary output names/directories\n",
    "        n = 10000 # maximum N for random number generator\n",
    "        tmp_out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", 'tmp_dir' + str(random.randint(0, n)))\n",
    "        tmp_basename = 'tmp_basename' + str(random.randint(0, n))\n",
    "\n",
    "        if not os.path.exists(tmp_out_dir):\n",
    "            os.makedirs(tmp_out_dir)\n",
    "\n",
    "        # Convert image file\n",
    "        # Check file extension in file\n",
    "        if '.nii.gz' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                pass\n",
    "        elif '.nii' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            nii_file = utils.gzip_file(nii_file)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                pass\n",
    "        elif '.dcm' in file or '.PAR' in file:\n",
    "            [nii_file, json_file] = utils.convert_anat(file,tmp_out_dir,tmp_basename)\n",
    "        else:\n",
    "            [nii_file, json_file] = utils.convert_anat(file,tmp_out_dir,tmp_basename)\n",
    "\n",
    "        # Get additional sequence/modality parameters\n",
    "        if os.path.exists(json_file):\n",
    "            meta_dict_params = get_data_params(file, json_file)\n",
    "        else:\n",
    "            tmp_json = \"\"\n",
    "            meta_dict_params = get_data_params(file, tmp_json)\n",
    "\n",
    "        # Update JSON file\n",
    "        info = dict()\n",
    "        info = utils.dict_multi_update(info,**meta_dict_params)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_com)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_func)\n",
    "\n",
    "        json_file = utils.update_json(json_file,info)\n",
    "\n",
    "        nii_file = os.path.abspath(nii_file)\n",
    "        json_file = os.path.abspath(json_file)\n",
    "\n",
    "        info = dict()\n",
    "        info = utils.read_json(json_file)\n",
    "\n",
    "        # Decide if file is 4D timeseries or single-band reference\n",
    "        num_frames = get_num_frames(nii_file)\n",
    "        if num_frames == 1:\n",
    "            scan = 'sbref'\n",
    "\n",
    "        # Query dictionary for acquisition/naming keys\n",
    "        try:\n",
    "            acq = info['acq']\n",
    "        except KeyError:\n",
    "            acq = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            ce = info['ce']\n",
    "        except KeyError:\n",
    "            ce = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            direction = info['dir']\n",
    "        except KeyError:\n",
    "            direction = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            rec = info['rec']\n",
    "        except KeyError:\n",
    "            rec = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            echo = info['echo']\n",
    "        except KeyError:\n",
    "            echo = \"\"\n",
    "            pass\n",
    "\n",
    "        # Create output filename    \n",
    "        out_name = f\"sub-{sub}\" + f\"_ses-{ses}\" + f\"_task-{task}\"\n",
    "\n",
    "        name_run_dict = dict()\n",
    "        tmp_dict = {\"task\":f\"{task}\"}\n",
    "        name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if acq:\n",
    "            out_name = out_name + f\"_acq-{acq}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if ce:\n",
    "            out_name = out_name + f\"_ce-{ce}\"\n",
    "            tmp_dict = {\"ce\":f\"{ce}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if direction:\n",
    "            out_name = out_name + f\"_dir-{direction}\"\n",
    "            tmp_dict = {\"dirs\":f\"{direction}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if rec:\n",
    "            out_name = out_name + f\"_rec-{rec}\"\n",
    "            tmp_dict = {\"rec\":f\"{rec}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if echo:\n",
    "            tmp_dict = {\"echo\":f\"{echo}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        # Get Run number\n",
    "        run = utils.get_num_runs(out_dir, scan=scan, **name_run_dict)\n",
    "        run = '{:02}'.format(run)\n",
    "\n",
    "        if run:\n",
    "            out_name = out_name + f\"_run-{run}\"\n",
    "\n",
    "        if echo:\n",
    "            out_name = out_name + f\"_echo-{echo}\"\n",
    "\n",
    "        out_name = out_name + f\"_{scan}\"\n",
    "\n",
    "\n",
    "        out_nii = os.path.join(out_dir, out_name + '.nii.gz')\n",
    "        out_json = os.path.join(out_dir, out_name + '.json')\n",
    "\n",
    "        os.rename(nii_file, out_nii)\n",
    "        os.rename(json_file, out_json)\n",
    "\n",
    "        # remove temporary directory and leftover files\n",
    "        shutil.rmtree(tmp_out_dir)\n",
    "\n",
    "        return out_nii,out_json\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: unable to convert {file}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bids_fmap(bids_out_dir, file, sub, scan='fieldmap', meta_dict_com=dict(), meta_dict_fmap=dict(), ses=1, scan_type='fmap'):\n",
    "    '''\n",
    "    Renames converted NifTi-2 files to conform with the BIDS naming convension (in the case of fieldmap files).\n",
    "    This function accepts any image file (DICOM, PAR REC, and NifTi-2). If the image file is a raw data file (e.g. DICOM, PAR REC)\n",
    "    it is converted to NifTi first, then renamed. The output BIDS directory need not exist at runtime.\n",
    "    \n",
    "    N.B.: This function is mainly designed to handle fieldmap data case 3 from bids-specifications document. Furhter support for \n",
    "    the additional cases requires test/validation data. \n",
    "    BIDS-specifications document located here: \n",
    "    https://github.com/bids-standard/bids-specification/blob/master/src/04-modality-specific-files/01-magnetic-resonance-imaging-data.md\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Path to output BIDS directory. \n",
    "        file (string): Filepath to image file.\n",
    "        sub (int or string): Subject ID\n",
    "        scan (string): Modality (e.g. fieldmap, magnitude, or phasediff)\n",
    "        meta_dict_com (dict): Metadata dictionary for common image metadata\n",
    "        meta_dict_fmap (dict): Metadata dictionary for common fieldmap image specific metadata\n",
    "        ses (int or string): Session ID\n",
    "        scan_type (string): BIDS sub-directory scan type. Valid options include, but are not limited to: anat, func, fmap (default), dwi, etc.\n",
    "        \n",
    "    Returns:\n",
    "        out_nii_fmap (string): Absolute filepath to gzipped output NifTi-2 fieldmap image file\n",
    "        out_nii_mag (string): Absolute filepath to gzipped output NifTi-2 magnitude image file\n",
    "        out_json_fmap (string): Absolute filepath to correspond fieldmap image JSON sidecare\n",
    "        out_json_mag (string): Absolute filepath to correspond magnitude image JSON sidecare\n",
    "    '''\n",
    "\n",
    "    # Use try-except statement here in the case of invalid/incomplete image files that will throw errors in dcm2niix\n",
    "    try:\n",
    "        # Create Output Directory Variables\n",
    "        # Zeropad subject ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # Zeropad session ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "        # Make output directory\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "\n",
    "        # Get absolute filepaths\n",
    "        bids_out_dir = os.path.abspath(bids_out_dir)\n",
    "        out_dir = os.path.abspath(out_dir)\n",
    "\n",
    "        # Create temporary output names/directories\n",
    "        n = 10000 # maximum N for random number generator\n",
    "        tmp_out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", 'tmp_dir' + str(random.randint(0, n)))\n",
    "        tmp_basename = 'tmp_basename' + str(random.randint(0, n))\n",
    "\n",
    "        if not os.path.exists(tmp_out_dir):\n",
    "            os.makedirs(tmp_out_dir)\n",
    "\n",
    "        # Convert image file\n",
    "        # Check file extension in file\n",
    "        if '.nii.gz' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                pass\n",
    "        elif '.nii' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            nii_file = utils.gzip_file(nii_file)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                pass\n",
    "        elif '.dcm' in file or '.PAR' in file:\n",
    "            [nii_fmap, json_fmap, nii_mag, json_mag] = utils.convert_fmap(file,tmp_out_dir,tmp_basename)\n",
    "        else:\n",
    "            [nii_fmap, json_fmap, nii_mag, json_mag] = utils.convert_fmap(file,tmp_out_dir,tmp_basename)\n",
    "\n",
    "        # Get additional sequence/modality parameters\n",
    "        if os.path.exists(json_fmap):\n",
    "            meta_dict_params = get_data_params(file, json_fmap)\n",
    "        else:\n",
    "            tmp_json = \"\"\n",
    "            meta_dict_params = get_data_params(file, tmp_json)\n",
    "\n",
    "        # Update JSON file\n",
    "        info = dict()\n",
    "        info = utils.dict_multi_update(info,**meta_dict_params)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_com)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_fmap)\n",
    "\n",
    "        json_fmap = utils.update_json(json_fmap,info)\n",
    "        json_mag = utils.update_json(json_mag,info)\n",
    "\n",
    "        nii_fmap = os.path.abspath(nii_fmap)\n",
    "        nii_mag = os.path.abspath(nii_mag)\n",
    "\n",
    "        json_fmap = os.path.abspath(json_fmap)\n",
    "        json_mag = os.path.abspath(json_mag)\n",
    "\n",
    "        info = dict()\n",
    "        info = utils.read_json(json_fmap)\n",
    "\n",
    "        # Query dictionary for acquisition/naming keys\n",
    "        try:\n",
    "            acq = info['acq']\n",
    "        except KeyError:\n",
    "            acq = \"\"\n",
    "            pass\n",
    "\n",
    "        # Create output filename    \n",
    "        out_name = f\"sub-{sub}\" + f\"_ses-{ses}\"\n",
    "        name_run_dict = dict()\n",
    "\n",
    "        if acq:\n",
    "            out_name = out_name + f\"_acq-{acq}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        # Get Run number\n",
    "        run = utils.get_num_runs(out_dir, scan=scan, **name_run_dict)\n",
    "        run = '{:02}'.format(run)\n",
    "\n",
    "        if run:\n",
    "            out_name = out_name + f\"_run-{run}\"\n",
    "\n",
    "        out_name = out_name + f\"_{scan}\"\n",
    "\n",
    "        out_nii_fmap = os.path.join(out_dir, out_name + '_fieldmap' + '.nii.gz')\n",
    "        out_nii_mag = os.path.join(out_dir, out_name + '_magnitude' + '.nii.gz')\n",
    "\n",
    "        out_json_fmap = os.path.join(out_dir, out_name + '_fieldmap' + '.json')\n",
    "        out_json_mag = os.path.join(out_dir, out_name + '_magnitude' + '.json')\n",
    "\n",
    "        os.rename(nii_fmap, out_nii_fmap)\n",
    "        os.rename(nii_mag, out_nii_mag)\n",
    "\n",
    "        os.rename(json_fmap, out_json_fmap)\n",
    "        os.rename(json_mag, out_json_mag)\n",
    "\n",
    "        # Remove temporary directory and leftover files\n",
    "        shutil.rmtree(tmp_out_dir)\n",
    "\n",
    "        return out_nii_fmap, out_nii_mag, out_json_fmap, out_json_mag\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: unable to convert {file}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_bids_dwi(bids_out_dir, file, sub, scan='dwi', meta_dict_com=dict(), meta_dict_dwi=dict(), ses=1, scan_type='dwi'):\n",
    "    '''\n",
    "    Renames converted NifTi-2 files to conform with the BIDS naming convension (in the case of diffuion image files).\n",
    "    This function accepts any image file (DICOM, PAR REC, and NifTi-2). If the image file is a raw data file (e.g. DICOM, PAR REC)\n",
    "    it is converted to NifTi first, then renamed. The output BIDS directory need not exist at runtime. If the original\n",
    "    data format is NifTi, bval and bvec files will be copied over should they exist, otherwise, they will not be\n",
    "    generated.\n",
    "    \n",
    "    Arguments:\n",
    "        bids_out_dir (string): Path to output BIDS directory. \n",
    "        file (string): Filepath to image file.\n",
    "        sub (int or string): Subject ID\n",
    "        scan (string): Modality (e.g. dwi, dki, etc)\n",
    "        meta_dict_com (dict): Metadata dictionary for common image metadata\n",
    "        meta_dict_dwi (dict): Metadata dictionary for common diffusion image specific metadata\n",
    "        ses (int or string): Session ID\n",
    "        scan_type (string): BIDS sub-directory scan type. Valid options include, but are not limited to: anat, func, fmap, dwi (default), etc.\n",
    "        \n",
    "    Returns:\n",
    "        out_nii (string): Absolute filepath to gzipped output diffusion weighted NifTi-2 file\n",
    "        out_json (string): Absolute filepath to corresponding JSON file\n",
    "        out_bval (string): Absolute filepath to corresponding b-values file\n",
    "        out_bvec (string): Absolute filepath to corresponding b-vectors file\n",
    "    '''\n",
    "\n",
    "    # Use try-except statement here in the case of invalid/incomplete image files that will throw errors in dcm2niix\n",
    "    try:\n",
    "        # Create Output Directory Variables\n",
    "        # Zeropad subject ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # Zeropad session ID if possible\n",
    "        try:\n",
    "            ses = '{:03}'.format(int(ses))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", f\"ses-{ses}\", f\"{scan_type}\")\n",
    "\n",
    "        # Make output directory\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "\n",
    "        # Get absolute filepaths\n",
    "        bids_out_dir = os.path.abspath(bids_out_dir)\n",
    "        out_dir = os.path.abspath(out_dir)\n",
    "\n",
    "        # Create temporary output names/directories\n",
    "        n = 10000 # maximum N for random number generator\n",
    "        tmp_out_dir = os.path.join(bids_out_dir, f\"sub-{sub}\", 'tmp_dir' + str(random.randint(0, n)))\n",
    "        tmp_basename = 'tmp_basename' + str(random.randint(0, n))\n",
    "\n",
    "        if not os.path.exists(tmp_out_dir):\n",
    "            os.makedirs(tmp_out_dir)\n",
    "\n",
    "        # Convert image file\n",
    "        # Check file extension in file\n",
    "        if '.nii.gz' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            bval = os.path.join(path,filename + '.bval*')\n",
    "            bvec = os.path.join(path,filename + '.bvec*')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "                # Decide if file is DWI or single-band reference\n",
    "                num_frames = get_num_frames(nii_file)\n",
    "                if num_frames == 1:\n",
    "                    scan = 'sbref'; bval = \"\"; bvec = \"\"\n",
    "                else:\n",
    "                    bval = utils.cp_file(bval, tmp_out_dir, tmp_basename)\n",
    "                    bvec = utils.cp_file(bvec, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                bval = os.path.join(tmp_out_dir, tmp_basename + '.bval')\n",
    "                bvec = os.path.join(tmp_out_dir, tmp_basename + '.bvec')\n",
    "                # Decide if file is DWI or single-band reference\n",
    "                num_frames = get_num_frames(nii_file)\n",
    "                if num_frames == 1:\n",
    "                    scan = 'sbref'; bval = \"\"; bvec = \"\"\n",
    "                pass\n",
    "        elif '.nii' in file:\n",
    "            nii_file = utils.cp_file(file, tmp_out_dir, tmp_basename)\n",
    "            nii_file = utils.gzip_file(nii_file)\n",
    "            [path,filename,ext] = utils.file_parts(file)\n",
    "            json_file = os.path.join(path,filename + '.json')\n",
    "            bval = os.path.join(path,filename + '.bval*')\n",
    "            bvec = os.path.join(path,filename + '.bvec*')\n",
    "            try:\n",
    "                json_file = utils.cp_file(json_file, tmp_out_dir, tmp_basename)\n",
    "                # Decide if file is DWI or single-band reference\n",
    "                num_frames = get_num_frames(nii_file)\n",
    "                if num_frames == 1:\n",
    "                    scan = 'sbref'; bval = \"\"; bvec = \"\"\n",
    "                else:\n",
    "                    bval = utils.cp_file(bval, tmp_out_dir, tmp_basename)\n",
    "                    bvec = utils.cp_file(bvec, tmp_out_dir, tmp_basename)\n",
    "            except FileNotFoundError:\n",
    "                json_file = os.path.join(tmp_out_dir, tmp_basename + '.json')\n",
    "                bval = os.path.join(tmp_out_dir, tmp_basename + '.bval')\n",
    "                bvec = os.path.join(tmp_out_dir, tmp_basename + '.bvec')\n",
    "                # Decide if file is DWI or single-band reference\n",
    "                num_frames = get_num_frames(nii_file)\n",
    "                if num_frames == 1:\n",
    "                    scan = 'sbref'; bval = \"\"; bvec = \"\"\n",
    "                pass\n",
    "        elif '.dcm' in file or '.PAR' in file:\n",
    "            [nii_file, json_file, bval, bvec] = utils.convert_dwi(file,tmp_out_dir,tmp_basename)\n",
    "            # Decide if file is DWI or single-band reference\n",
    "            num_frames = get_num_frames(nii_file)\n",
    "            if num_frames == 1:\n",
    "                scan = 'sbref'; bval = \"\"; bvec = \"\"\n",
    "        else:\n",
    "            [nii_file, json_file, bval, bvec] = utils.convert_dwi(file,tmp_out_dir,tmp_basename)\n",
    "            # Decide if file is DWI or single-band reference\n",
    "            num_frames = get_num_frames(nii_file)\n",
    "            if num_frames == 1:\n",
    "                scan = 'sbref'; bval = \"\"; bvec = \"\"\n",
    "\n",
    "        # Get additional sequence/modality parameters\n",
    "        if os.path.exists(json_file) and os.path.exists(bval):\n",
    "            meta_dict_params = get_data_params(file, json_file, bval)\n",
    "        elif os.path.exists(bval):\n",
    "            tmp_json = \"\"\n",
    "            meta_dict_params = get_data_params(file, tmp_json, bval)\n",
    "        elif os.path.exists(json_file):\n",
    "            tmp_bval = \"\"\n",
    "            meta_dict_params = get_data_params(file, json_file, tmp_bval)\n",
    "        else:\n",
    "            tmp_json = \"\"\n",
    "            tmp_bval = \"\"\n",
    "            meta_dict_params = get_data_params(file, tmp_json, tmp_bval)\n",
    "\n",
    "        # Update JSON file\n",
    "        info = dict()\n",
    "        info = utils.dict_multi_update(info,**meta_dict_params)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_com)\n",
    "        info = utils.dict_multi_update(info,**meta_dict_dwi)\n",
    "\n",
    "        json_file = utils.update_json(json_file,info)\n",
    "\n",
    "        nii_file = os.path.abspath(nii_file)\n",
    "        json_file = os.path.abspath(json_file)\n",
    "\n",
    "        info = dict()\n",
    "        info = utils.read_json(json_file)\n",
    "\n",
    "        if bval and bvec:\n",
    "            bval = os.path.abspath(bval)\n",
    "            bvec = os.path.abspath(bvec)\n",
    "\n",
    "        # Query dictionary for acquisition/naming keys\n",
    "        try:\n",
    "            acq = info['acq']\n",
    "        except KeyError:\n",
    "            acq = \"\"\n",
    "            pass\n",
    "        try:\n",
    "            direction = info['dir']\n",
    "        except KeyError:\n",
    "            direction = \"\"\n",
    "            pass\n",
    "\n",
    "        # Non-standard acquisition/naming keys\n",
    "        # Used in order to differentiate between DWI scans for multiple bvalues\n",
    "        try:\n",
    "            bvals = info['bval']\n",
    "        except KeyError:\n",
    "            bvals = list()\n",
    "            pass\n",
    "        try:\n",
    "            echo_time = info['EchoTime']\n",
    "            echo_time = int(echo_time * 1000)\n",
    "        except KeyError:\n",
    "            echo_time = \"\"\n",
    "            pass\n",
    "\n",
    "        # Create output filename    \n",
    "        out_name = f\"sub-{sub}\" + f\"_ses-{ses}\"\n",
    "        name_run_dict = dict()\n",
    "\n",
    "        if bvals:\n",
    "            vals = \"\"\n",
    "            for val in bvals:\n",
    "                vals = vals + 'b' + str(int(val))\n",
    "        else:\n",
    "            vals = 'b0'\n",
    "\n",
    "        if vals and acq and echo_time:\n",
    "            out_name = out_name + f\"_acq-{acq}{vals}TE{echo_time}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}{vals}TE{echo_time}\"}\n",
    "        elif vals and acq:\n",
    "            out_name = out_name + f\"_acq-{acq}{vals}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}{vals}\"}\n",
    "        elif vals and echo_time:\n",
    "            out_name = out_name + f\"_acq-{vals}TE{echo_time}\"\n",
    "            tmp_dict = {\"acq\":f\"{vals}TE{echo_time}\"}\n",
    "        elif acq and echo_time:\n",
    "            out_name = out_name + f\"_acq-{acq}TE{echo_time}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}TE{echo_time}\"}\n",
    "        elif acq:\n",
    "            out_name = out_name + f\"_acq-{acq}\"\n",
    "            tmp_dict = {\"acq\":f\"{acq}\"}\n",
    "        elif vals:\n",
    "            out_name = out_name + f\"_acq-{vals}\"\n",
    "            tmp_dict = {\"acq\":f\"{vals}\"}\n",
    "        elif echo_time:\n",
    "            out_name = out_name + f\"_acq-TE{echo_time}\"\n",
    "            tmp_dict = {\"acq\":f\"TE{echo_time}\"}\n",
    "        else:\n",
    "            tmp_dict = dict()\n",
    "\n",
    "        name_run_dict.update(tmp_dict)\n",
    "\n",
    "        if direction:\n",
    "            out_name = out_name + f\"_dir-{direction}\"\n",
    "            tmp_dict = {\"dirs\":f\"{direction}\"}\n",
    "            name_run_dict.update(tmp_dict)\n",
    "\n",
    "        # Get Run number\n",
    "        run = utils.get_num_runs(out_dir, scan=scan, **name_run_dict)\n",
    "        run = '{:02}'.format(run)\n",
    "\n",
    "        if run:\n",
    "            out_name = out_name + f\"_run-{run}\"\n",
    "\n",
    "        out_name = out_name + f\"_{scan}\"\n",
    "\n",
    "        out_nii = os.path.join(out_dir, out_name + '.nii.gz')\n",
    "        out_json = os.path.join(out_dir, out_name + '.json')\n",
    "\n",
    "        out_bval = os.path.join(out_dir, out_name + '.bval')\n",
    "        out_bvec = os.path.join(out_dir, out_name + '.bvec')\n",
    "\n",
    "        os.rename(nii_file, out_nii)\n",
    "        os.rename(json_file, out_json)\n",
    "\n",
    "        if bval:\n",
    "            os.rename(bval,out_bval)\n",
    "\n",
    "        if bvec:\n",
    "            os.rename(bvec,out_bvec)\n",
    "\n",
    "        # remove temporary directory and leftover files\n",
    "        shutil.rmtree(tmp_out_dir)\n",
    "\n",
    "        if bval and bvec:\n",
    "            return out_nii,out_json,out_bval,out_bvec\n",
    "        elif not bval and bvec:\n",
    "            return out_nii,out_json\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: unable to convert {file}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Feature Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert(bids_out_dir,sub,file_list, search_dict, meta_dict=dict(), ses=1, keep_unknown=True,verbose=False):\n",
    "    '''\n",
    "    Batch conversion function for image files.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "\n",
    "    Arguments:\n",
    "        bids_out_dir (string): Output BIDS directory\n",
    "        sub (int or string): Subject ID\n",
    "        file (string): Source image filename with absolute filepath\n",
    "        search_dict (dict): Nested dictionary from the 'read_config' function\n",
    "        meta_dict (dict): Nested metadata dictionary\n",
    "        ses (int or string): Session ID\n",
    "        keep_unknown (bool): Convert modalities/scans which cannot be identified (default: True)\n",
    "        verbose (bool): Prints the scan_type, modality, and search terms used (e.g. func - bold - rest - ['rest', 'FFE'])\n",
    "\n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "\n",
    "    converted_files = list()\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            converted_files = convert_modality(bids_out_dir=bids_out_dir, sub=sub, file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=True, verbose=False)\n",
    "        except (SystemExit,FileNotFoundError):\n",
    "            pass\n",
    "    \n",
    "    return converted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for PAR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = os.path.join('/Users/brac4g/Desktop/convsauce/pat_dir','*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ext = '.dcm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8',\n",
       " '/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list = glob.glob(dir_,recursive=True)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8\n",
      "['20171003']\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003\n",
      "['0_DEFAULT_PS_SERIES_2017100310374358016', '303_CORONAL_2017100310262626000', '0_DEFAULT_PS_SERIES_2017100310463791022', '1701_WM_SV_PRESS_35_017100311174543840', '201_SAG_T1W_3D_Y_INNER_TI_1100_017100310184810020', '1101_rsfMRI_MB6_SENSE_1_fat_shift_P_017100310465322437']\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310374358016\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/303_CORONAL_2017100310262626000\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310463791022\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/1701_WM_SV_PRESS_35_017100311174543840\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/201_SAG_T1W_3D_Y_INNER_TI_1100_017100310184810020\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/1101_rsfMRI_MB6_SENSE_1_fat_shift_P_017100310465322437\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10\n",
      "['NIFTI', 'PHYSIO', 'PAR REC', 'SPAR SDAT']\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10/NIFTI\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10/PHYSIO\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10/PAR REC\n",
      "[]\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10/SPAR SDAT\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in dir_list:\n",
    "    for root,dirs,files in os.walk(i):\n",
    "        print(root)\n",
    "        print(dirs)\n",
    "        # print(files)\n",
    "#         if files:\n",
    "#             print(root,dirs,files[0])\n",
    "#             break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk2(top, topdown=True, onerror=None, followlinks=False, maxdepth=None):\n",
    "    \n",
    "    import os\n",
    "    import os.path as path\n",
    "    \n",
    "    islink, join, isdir = path.islink, path.join, path.isdir\n",
    "\n",
    "\n",
    "    try:\n",
    "        names = os.listdir(top)\n",
    "    except(OSError, err):\n",
    "        if onerror is not None:\n",
    "            onerror(err)\n",
    "        return\n",
    "\n",
    "    dirs, nondirs = [], []\n",
    "    for name in names:\n",
    "        if isdir(join(top, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            nondirs.append(name)\n",
    "\n",
    "    if topdown:\n",
    "        yield top, dirs, nondirs\n",
    "\n",
    "    if maxdepth is None or maxdepth > 1:\n",
    "        for name in dirs:\n",
    "            new_path = join(top, name)\n",
    "            if followlinks or not islink(new_path):\n",
    "                for x in walk2(new_path, topdown, onerror, followlinks, None if maxdepth is None else maxdepth-1):\n",
    "                    yield x\n",
    "    if not topdown:\n",
    "        yield top, dirs, nondirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brac4g/Desktop/convsauce/pat_dir/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310374358016 [] PR0000000001.dcm\n",
      "/Users/brac4g/Desktop/convsauce/pat_dir/287H_C10/NIFTI [] 287H_C10_SAG_4_5.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for i in dir_list:\n",
    "    for root,dirs,files in walk2(i,maxdepth=5):\n",
    "        # print(root)\n",
    "        # print(dirs)\n",
    "        # print(files)\n",
    "        if files:\n",
    "            print(root,dirs,files[0])\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
