{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "import pydicom\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "import yaml\n",
    "import nibabel as nib\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import third party packages and modules\n",
    "import convert_source_dcm as cdm\n",
    "import convert_source_par as csp\n",
    "import convert_source_nii as csn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = \"/Users/brac4g/Desktop/convsauce/ConvertSource/config.default.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_file, verbose = False):\n",
    "    '''\n",
    "    Reads configuration file and creates a dictionary of search terms for \n",
    "    certain modalities provided that BIDS modalities are used as keys. If\n",
    "    exclusions are provided (via the key 'exclude') then an exclusion list is \n",
    "    created. Otherwise, 'exclusion_list' is returned as an empty list. If \n",
    "    additional settings are specified, they should be done so via the key\n",
    "    'metadata' to enable writing of additional metadata. Otherwise, an \n",
    "    empty dictionary is returned.\n",
    "    \n",
    "    Arguments:\n",
    "        config_file (string): file path to yaml configuration file.\n",
    "        verbose (boolean): Prints additional information to screen.\n",
    "    \n",
    "    Returns: \n",
    "        data_map (dict): Nested dictionary of search terms for BIDS modalities\n",
    "        exclusion_list (list): List of exclusion terms\n",
    "        meta_dict (dict): Nested dictionary of metadata terms to write to JSON file(s)\n",
    "    '''\n",
    "    \n",
    "    with open(config_file) as file:\n",
    "        data_map = yaml.safe_load(file)\n",
    "        if verbose:\n",
    "            print(\"Initialized parameters from configuration file\")\n",
    "        \n",
    "    if any(\"exclude\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"exclusion option implemented\")\n",
    "        exclusion_list = data_map[\"exclude\"]\n",
    "        del data_map[\"exclude\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"exclusion option not implemented\")\n",
    "        exclusion_list = list()\n",
    "        \n",
    "    if any(\"metadata\" in data_map for element in data_map):\n",
    "        if verbose:\n",
    "            print(\"implementing additional settings for metadata\")\n",
    "        meta_dict = data_map[\"metadata\"]\n",
    "        del data_map[\"metadata\"]\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"no metadata settings\")\n",
    "        meta_dict = dict()\n",
    "        \n",
    "    return data_map,exclusion_list,meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized parameters from configuration file\n",
      "exclusion option implemented\n",
      "implementing additional settings for metadata\n"
     ]
    }
   ],
   "source": [
    "search_dict, exclude_list, meta_dict = read_config(conf,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(data_dir, file_ext=\"\", order=\"size\"):\n",
    "    '''\n",
    "    Creates a file list by globbing a directory for a specific file\n",
    "    extension and sorting by some determined order. A file list is \n",
    "    then returned\n",
    "    \n",
    "    Arguments:\n",
    "        data_dir (string): Absolute path to data directory (must be a directory dump of image data)\n",
    "        file_ext (string): File extension to glob. Built-in options include:\n",
    "            - 'par' or 'PAR': Searches for PAR headers\n",
    "            - 'dcm' or 'DICOM': Searches for DICOM directories, then searches for one file from each DICOM directory\n",
    "            - 'nii', or 'Nifti': Searches for nifti files (including gzipped nifti files)\n",
    "        order (string): Order to sort the list. Valid options are: 'size' and 'time':\n",
    "            - 'size': sorts by file size in ascending order (default)\n",
    "            - 'time': sorts by file modification time in ascending order\n",
    "            - 'none': no sorting is applied and the list is generated as the system finds the files\n",
    "    \n",
    "    Returns: \n",
    "        file_list (list): List of filenames, complete with their absolute paths.\n",
    "    '''\n",
    "    \n",
    "    # Check file extension\n",
    "    if file_ext != \"\":\n",
    "        if file_ext.upper() == \"PAR\" or file_ext.upper() == \"REC\":\n",
    "            file_ext = \"PAR\"\n",
    "            file_ext = f\".{file_ext.upper()}\"\n",
    "        elif file_ext.lower() == \"dcm\" or file_ext.upper() == \"DICOM\":\n",
    "            file_ext = \"dcm\"\n",
    "            file_ext = f\".{file_ext.lower()}\"\n",
    "        elif file_ext.lower() == \"nii\" or file_ext.lower() == \"nifti\":\n",
    "            file_ext = \"nii\"\n",
    "            file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "        else:\n",
    "            file_ext = f\".{file_ext}\"\n",
    "    \n",
    "    # Check sort order\n",
    "    if order.lower() == \"size\":\n",
    "        order_key = os.path.getsize\n",
    "    elif order.lower() == \"time\":\n",
    "        order_key = os.path.getmtime\n",
    "    elif order.lower() == \"none\":\n",
    "        order_key=None\n",
    "    else:\n",
    "        order_key = os.path.getsize\n",
    "        print(\"Unrecognized keyword option. Using default.\")\n",
    "    \n",
    "    # Create file list\n",
    "    if file_ext == \".dcm\":\n",
    "        file_list = sorted(cdm.get_dcm_files(data_dir), key=order_key, reverse=False)\n",
    "    elif file_ext != \".dcm\":\n",
    "        file_names = os.path.join(data_dir, f\"*{file_ext}\")\n",
    "        file_list = sorted(glob.glob(file_names, recursive=True), key=order_key, reverse=False)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exclude(file_list, data_dir, exclusion_list = [], verbose = False):\n",
    "    '''\n",
    "    Excludes files from the conversion process by removing filenames\n",
    "    that contain words that match those found in the 'exclusion_list'\n",
    "    from the 'read_config' function - should any files need/want to be \n",
    "    excluded.\n",
    "    \n",
    "    If 'exclusion_list' is empty, then the original 'file_list' is returned.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames\n",
    "        data_dir (string): Absolute path to parent directory that contains the image data\n",
    "        exclusion_list (list): List of words to be matched. Filenames that contain these words will be excluded.\n",
    "        verbose (bool): Boolean - True or False.\n",
    "    \n",
    "    Returns: \n",
    "        currated_list (list): Currated list of filenames, with unwanted filenames removed.\n",
    "    '''\n",
    "            \n",
    "    # Check file extension in file list\n",
    "    if 'dcm' in file_list[0]:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'PAR' in file_list[0]:\n",
    "        file_ext = \"PAR\"\n",
    "        file_ext = f\".{file_ext.upper()}\"\n",
    "    elif 'nii' in file_list[0]:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}*\" # Add wildcard for globbling gzipped files\n",
    "    else:\n",
    "        file_ext = \"\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    \n",
    "    # create set of lists\n",
    "    file_set = set(file_list)\n",
    "    \n",
    "    # create empty sets\n",
    "    currated_set = set()\n",
    "    exclusion_set = set()\n",
    "    \n",
    "    if len(exclusion_list) == 0:\n",
    "        currated_set = file_set\n",
    "    else:\n",
    "        for file in exclusion_list:\n",
    "            if file_ext == '.dcm':\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*\",f\"*{file_ext}\")\n",
    "            else:\n",
    "                dir_ = os.path.join(data_dir, f\"*{file}*{file_ext}\")\n",
    "            f_names = glob.glob(dir_, recursive=True)        \n",
    "            f_names_set = set(f_names)\n",
    "            if verbose:\n",
    "                if len(f_names_set) != 0:\n",
    "                    print(f\"Excluded files: {f_names_set} \\n\")\n",
    "            exclusion_set.update(f_names_set)\n",
    "            \n",
    "        currated_set = file_set.difference(exclusion_set)\n",
    "\n",
    "    currated_list = list(currated_set)\n",
    "    \n",
    "    return currated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_dir = \"/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003\"\n",
    "par_dir = \"/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC\"\n",
    "nii_dir = \"/Users/brac4g/Desktop/convsauce/287H_C10/NIFTI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_file_list = create_file_list(dcm_dir,'dcm')\n",
    "par_file_list = create_file_list(par_dir,'par')\n",
    "nii_file_list = create_file_list(nii_dir,'nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/1701_WM_SV_PRESS_35_017100311174543840/MR1701000001.dcm'} \n",
      "\n",
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310463791022/PR0000000001.dcm', '/Users/brac4g/Desktop/convsauce/IRC287H-8/20171003/0_DEFAULT_PS_SERIES_2017100310374358016/PR0000000001.dcm'} \n",
      "\n",
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_2_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_13_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_17_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_14_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_1_1.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_WIP_NEONATAL_SURVEY_16_1.PAR'} \n",
      "\n",
      "Excluded files: {'/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_Reg_-_WIP_DTI_6DIR_B800_12_2.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_isoReg_-_WIP_DTI_6DIR_B800_12_6.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_faReg_-_WIP_DTI_6DIR_B800_12_4.PAR', '/Users/brac4g/Desktop/convsauce/287H_C10/PAR REC/287H_C10_dReg_-_WIP_DTI_6DIR_B800_12_3.PAR'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcm_list_currated = file_exclude(dcm_file_list,dcm_dir,exclude_list,verbose=True)\n",
    "par_list_currated = file_exclude(par_file_list,par_dir,exclude_list,verbose=True)\n",
    "nii_list_currated = file_exclude(nii_file_list,nii_dir,exclude_list,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Manufacturer': 'Philips',\n",
       "  'ManufacturersModelName': 'Ingenia',\n",
       "  'MagneticFieldStrength': 3,\n",
       "  'InstitutionName': \"Cincinnati Children's Hospital Medical Center\"},\n",
       " {'rest': {'ParallelAcquisitionTechnique': 'SENSE',\n",
       "   'PhaseEncodingDirection': 'j',\n",
       "   'MultibandAccelerationFactor': 6,\n",
       "   'TaskName': 'Resting State',\n",
       "   'dir': 'PA',\n",
       "   'NumberOfVolumesDiscardedByScanner': 4},\n",
       "  'visualstrobe': {'PhaseEncodingDirection': 'j',\n",
       "   'TaskName': 'Visual (Strobe) Task',\n",
       "   'NumberOfVolumesDiscardedByScanner': 4}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_metadata(meta_dict,'func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scan_tech(bids_out_dir, sub, file, search_dict, meta_dict=\"\", ses=1, keep_unknown=True, verbose=False):\n",
    "    '''\n",
    "    Searches DICOM or PAR file header for scan technique/MR modality used in accordance with the search terms provided\n",
    "    by the nested dictionary.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    Note: accomodate extra dictionaries passed as arguments\n",
    "    \n",
    "    Arguments:\n",
    "        search_dict (dict): Nested dictionary from the 'read_config' function\n",
    "        dcm_file (string): Source image filename with absolute filepath\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    if not meta_dict:\n",
    "        meta_dict = dict()\n",
    "    \n",
    "    # Check file extension in file\n",
    "    # Perform Scanning Techniqe Search\n",
    "    if '.dcm' in file.lower():\n",
    "        cdm.get_dcm_scan_tech(bids_out_dir=bids_out_dir, sub=sub, dcm_file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=keep_unknown, verbose=verbose)\n",
    "    elif '.PAR' in file.upper():\n",
    "        csp.get_par_scan_tech(bids_out_dir=bids_out_dir, sub=sub, par_file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=keep_unknown, verbose=verbose)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"unknown modality\")\n",
    "        if keep_unknown:\n",
    "            if verbose:\n",
    "                print(\"converting unknown_modality\")\n",
    "            scan_type = 'unknown_modality'\n",
    "            scan = 'unknown'\n",
    "            [com_param_dict, scan_param_dict] = utils.get_metadata(dictionary=meta_dict,scan_type=scan_type)\n",
    "            csn.data_to_bids_anat(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_anat=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_modality(bids_out_dir, sub, file, search_dict, meta_dict=\"\", ses=1, keep_unknown=True, verbose=False):\n",
    "    '''\n",
    "    Converts an image file and extracts information from the filename (such as the modality). \n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    Note: Add support for extra dictionaries\n",
    "    \n",
    "    Arguments:\n",
    "        search_dict (dict): Nested dictionary from the 'read_config' function\n",
    "        file (string): Filename with absolute filepath\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    mod_found = False\n",
    "    \n",
    "    # Check file type\n",
    "    if 'nii' in file:\n",
    "        file_ext = \"nii\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "    elif 'dcm' in file:\n",
    "        file_ext = \"dcm\"\n",
    "        file_ext = f\".{file_ext.lower()}\"\n",
    "        if not is_valid_dcm(file,verbose):\n",
    "            sys.exit(f\"Invalid DICOM file. Please check {file}\")\n",
    "    \n",
    "    for key,item in search_dict.items():\n",
    "        for dict_key,dict_item in search_dict[key].items():\n",
    "            if isinstance(dict_item,list):\n",
    "                if utils.list_in_substr(dict_item,file):\n",
    "                    mod_found = True\n",
    "                    if verbose:\n",
    "                        print(f\"{key} - {dict_key}: {dict_item}\")\n",
    "                    scan_type = key\n",
    "                    scan = dict_key\n",
    "                    [com_param_dict, scan_param_dict] = utils.get_metadata(dictionary=meta_dict,scan_type=scan_type)\n",
    "                    if scan_type.lower() == 'dwi':\n",
    "                        csn.data_to_bids_dwi(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_dwi=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                    elif scan_type.lower() == 'fmap':\n",
    "                        csn.data_to_bids_fmap(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_fmap=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                    else:\n",
    "                        csn.data_to_bids_anat(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_anat=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                    if mod_found:\n",
    "                        break\n",
    "            elif isinstance(dict_item,dict):\n",
    "                tmp_dict = search_dict[key]\n",
    "                for d_key,d_item in tmp_dict[dict_key].items():\n",
    "                    if utils.list_in_substr(d_item,file):\n",
    "                        mod_found = True\n",
    "                        if verbose:\n",
    "                            print(f\"{key} - {dict_key} - {d_key}: {d_item}\")\n",
    "                        scan_type = key\n",
    "                        scan = dict_key\n",
    "                        task = d_key\n",
    "                        [com_param_dict, scan_param_dict] = utils.get_metadata(dictionary=meta_dict,scan_type=scan_type,task=task)\n",
    "                        if scan_type.lower() == 'func':\n",
    "                            csn.data_to_bids_func(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,task=task,meta_dict_com=com_param_dict,meta_dict_func=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        elif scan_type.lower() == 'dwi':\n",
    "                            csn.data_to_bids_dwi(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_dwi=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        elif scan_type.lower() == 'fmap':\n",
    "                            csn.data_to_bids_fmap(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_fmap=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        else:\n",
    "                            csn.data_to_bids_anat(bids_out_dir=bids_out_dir,file=file,sub=sub,scan=scan,meta_dict_com=com_param_dict,meta_dict_anat=scan_param_dict,ses=ses,scan_type=scan_type)\n",
    "                        if mod_found:\n",
    "                            break\n",
    "                        \n",
    "    if not mod_found:\n",
    "        get_scan_tech(bids_out_dir, sub, file, search_dict, meta_dict=\"\", ses=1, keep_unknown=keep_unknown, verbose=verbose)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert(bids_out_dir,sub,file_list, search_dict, meta_dict={}, ses=1, keep_unknown=True,verbose=False):\n",
    "    '''\n",
    "    Batch conversion function for image files.\n",
    "    \n",
    "    Note: This function is still undergoing active development.\n",
    "    \n",
    "    Arguments:\n",
    "        file_list (list): List of filenames with absolute filepaths\n",
    "        dictionary (dict): Nested dictionary from the 'read_config' function\n",
    "        verbose (boolean): Enable verbosity\n",
    "    \n",
    "    Returns: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    for file in file_list:\n",
    "        try:\n",
    "            convert_modality(bids_out_dir=bids_out_dir, sub=sub, file=file, search_dict=search_dict, meta_dict=meta_dict, ses=1, keep_unknown=True, verbose=False)\n",
    "        except SystemExit:\n",
    "            pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
